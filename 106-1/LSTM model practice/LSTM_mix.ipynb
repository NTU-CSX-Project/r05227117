{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from pandas import to_datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "from numpy import array\n",
    "from numpy import concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline(LSTM1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "\tdf = DataFrame(data)\n",
    "\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n",
    "\tcolumns.append(df)\n",
    "\tdf = concat(columns, axis=1)\n",
    "\tdf.fillna(0, inplace=True)\n",
    "\treturn df\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = numpy.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "\tX, y = train[:, 0:-1], train[:, -1]\n",
    "\tX = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\tfor i in range(nb_epoch):\n",
    "\t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "\t\tmodel.reset_states()\n",
    "\treturn model\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, 1, len(X))\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ts</th>\n",
       "      <th>cpu_ghz</th>\n",
       "      <th>cpu_usage</th>\n",
       "      <th>cpu_idle</th>\n",
       "      <th>cpu_total</th>\n",
       "      <th>memory_free_mb</th>\n",
       "      <th>memory_usage</th>\n",
       "      <th>memory_total</th>\n",
       "      <th>period</th>\n",
       "      <th>weekday_tag</th>\n",
       "      <th>workday_tag</th>\n",
       "      <th>cpu_usage_tag</th>\n",
       "      <th>memory_usage_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-04 07:09:00</td>\n",
       "      <td>1.622994</td>\n",
       "      <td>0.058949</td>\n",
       "      <td>7229.349138</td>\n",
       "      <td>7626.006979</td>\n",
       "      <td>73703.339671</td>\n",
       "      <td>0.171460</td>\n",
       "      <td>85762.997397</td>\n",
       "      <td>night</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2017-08-04 07:10:00</td>\n",
       "      <td>1.565744</td>\n",
       "      <td>0.051145</td>\n",
       "      <td>7436.343501</td>\n",
       "      <td>7808.899014</td>\n",
       "      <td>73678.012357</td>\n",
       "      <td>0.171868</td>\n",
       "      <td>85762.997397</td>\n",
       "      <td>night</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2017-08-04 07:11:00</td>\n",
       "      <td>1.532764</td>\n",
       "      <td>0.050431</td>\n",
       "      <td>7266.985222</td>\n",
       "      <td>7628.050287</td>\n",
       "      <td>73679.538946</td>\n",
       "      <td>0.171852</td>\n",
       "      <td>85762.997397</td>\n",
       "      <td>night</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2017-08-04 07:12:00</td>\n",
       "      <td>1.537919</td>\n",
       "      <td>0.055125</td>\n",
       "      <td>7251.151273</td>\n",
       "      <td>7645.735222</td>\n",
       "      <td>73662.632567</td>\n",
       "      <td>0.171941</td>\n",
       "      <td>85762.997397</td>\n",
       "      <td>night</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2017-08-04 07:13:00</td>\n",
       "      <td>1.535036</td>\n",
       "      <td>0.049197</td>\n",
       "      <td>7272.412151</td>\n",
       "      <td>7618.750821</td>\n",
       "      <td>73644.415185</td>\n",
       "      <td>0.172063</td>\n",
       "      <td>85762.997397</td>\n",
       "      <td>night</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   ts   cpu_ghz  cpu_usage     cpu_idle  \\\n",
       "0           1  2017-08-04 07:09:00  1.622994   0.058949  7229.349138   \n",
       "1           2  2017-08-04 07:10:00  1.565744   0.051145  7436.343501   \n",
       "2           3  2017-08-04 07:11:00  1.532764   0.050431  7266.985222   \n",
       "3           4  2017-08-04 07:12:00  1.537919   0.055125  7251.151273   \n",
       "4           5  2017-08-04 07:13:00  1.535036   0.049197  7272.412151   \n",
       "\n",
       "     cpu_total  memory_free_mb  memory_usage  memory_total period  \\\n",
       "0  7626.006979    73703.339671      0.171460  85762.997397  night   \n",
       "1  7808.899014    73678.012357      0.171868  85762.997397  night   \n",
       "2  7628.050287    73679.538946      0.171852  85762.997397  night   \n",
       "3  7645.735222    73662.632567      0.171941  85762.997397  night   \n",
       "4  7618.750821    73644.415185      0.172063  85762.997397  night   \n",
       "\n",
       "   weekday_tag  workday_tag  cpu_usage_tag  memory_usage_tag  \n",
       "0            5            0              0                -3  \n",
       "1            5            0             -2                -3  \n",
       "2            5            0             -2                -3  \n",
       "3            5            0             -1                -3  \n",
       "4            5            0             -2                -3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_csv('cm_all_1.csv', header=0, squeeze=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>cpu_ghz</th>\n",
       "      <th>cpu_usage</th>\n",
       "      <th>cpu_idle</th>\n",
       "      <th>cpu_total</th>\n",
       "      <th>memory_free_mb</th>\n",
       "      <th>memory_usage</th>\n",
       "      <th>memory_total</th>\n",
       "      <th>period</th>\n",
       "      <th>weekday_tag</th>\n",
       "      <th>workday_tag</th>\n",
       "      <th>cpu_usage_tag</th>\n",
       "      <th>memory_usage_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-04 07:09:00</td>\n",
       "      <td>1.622994</td>\n",
       "      <td>0.058949</td>\n",
       "      <td>7229.349138</td>\n",
       "      <td>7626.006979</td>\n",
       "      <td>73703.339671</td>\n",
       "      <td>0.171460</td>\n",
       "      <td>85762.997397</td>\n",
       "      <td>night</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-04 07:10:00</td>\n",
       "      <td>1.565744</td>\n",
       "      <td>0.051145</td>\n",
       "      <td>7436.343501</td>\n",
       "      <td>7808.899014</td>\n",
       "      <td>73678.012357</td>\n",
       "      <td>0.171868</td>\n",
       "      <td>85762.997397</td>\n",
       "      <td>night</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ts   cpu_ghz  cpu_usage     cpu_idle    cpu_total  \\\n",
       "0  2017-08-04 07:09:00  1.622994   0.058949  7229.349138  7626.006979   \n",
       "1  2017-08-04 07:10:00  1.565744   0.051145  7436.343501  7808.899014   \n",
       "\n",
       "   memory_free_mb  memory_usage  memory_total period  weekday_tag  \\\n",
       "0    73703.339671      0.171460  85762.997397  night            5   \n",
       "1    73678.012357      0.171868  85762.997397  night            5   \n",
       "\n",
       "   workday_tag  cpu_usage_tag  memory_usage_tag  \n",
       "0            0              0                -3  \n",
       "1            0             -2                -3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(df.columns[0],axis=1)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpu_ghz</th>\n",
       "      <th>cpu_usage</th>\n",
       "      <th>cpu_idle</th>\n",
       "      <th>cpu_total</th>\n",
       "      <th>memory_free_mb</th>\n",
       "      <th>memory_usage</th>\n",
       "      <th>memory_total</th>\n",
       "      <th>period</th>\n",
       "      <th>weekday_tag</th>\n",
       "      <th>workday_tag</th>\n",
       "      <th>cpu_usage_tag</th>\n",
       "      <th>memory_usage_tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ts</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-04 07:09:00</th>\n",
       "      <td>1.622994</td>\n",
       "      <td>0.058949</td>\n",
       "      <td>7229.349138</td>\n",
       "      <td>7626.006979</td>\n",
       "      <td>73703.339671</td>\n",
       "      <td>0.171460</td>\n",
       "      <td>85762.997397</td>\n",
       "      <td>night</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 07:10:00</th>\n",
       "      <td>1.565744</td>\n",
       "      <td>0.051145</td>\n",
       "      <td>7436.343501</td>\n",
       "      <td>7808.899014</td>\n",
       "      <td>73678.012357</td>\n",
       "      <td>0.171868</td>\n",
       "      <td>85762.997397</td>\n",
       "      <td>night</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 07:11:00</th>\n",
       "      <td>1.532764</td>\n",
       "      <td>0.050431</td>\n",
       "      <td>7266.985222</td>\n",
       "      <td>7628.050287</td>\n",
       "      <td>73679.538946</td>\n",
       "      <td>0.171852</td>\n",
       "      <td>85762.997397</td>\n",
       "      <td>night</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      cpu_ghz  cpu_usage     cpu_idle    cpu_total  \\\n",
       "ts                                                                   \n",
       "2017-08-04 07:09:00  1.622994   0.058949  7229.349138  7626.006979   \n",
       "2017-08-04 07:10:00  1.565744   0.051145  7436.343501  7808.899014   \n",
       "2017-08-04 07:11:00  1.532764   0.050431  7266.985222  7628.050287   \n",
       "\n",
       "                     memory_free_mb  memory_usage  memory_total period  \\\n",
       "ts                                                                       \n",
       "2017-08-04 07:09:00    73703.339671      0.171460  85762.997397  night   \n",
       "2017-08-04 07:10:00    73678.012357      0.171868  85762.997397  night   \n",
       "2017-08-04 07:11:00    73679.538946      0.171852  85762.997397  night   \n",
       "\n",
       "                     weekday_tag  workday_tag  cpu_usage_tag  memory_usage_tag  \n",
       "ts                                                                              \n",
       "2017-08-04 07:09:00            5            0              0                -3  \n",
       "2017-08-04 07:10:00            5            0             -2                -3  \n",
       "2017-08-04 07:11:00            5            0             -2                -3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ts = to_datetime(df.ts)\n",
    "df = df.set_index(['ts'])\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 5499 entries, 2017-08-04 07:09:00 to 2017-08-08 02:47:00\n",
      "Data columns (total 12 columns):\n",
      "cpu_ghz             5499 non-null float64\n",
      "cpu_usage           5499 non-null float64\n",
      "cpu_idle            5499 non-null float64\n",
      "cpu_total           5499 non-null float64\n",
      "memory_free_mb      5499 non-null float64\n",
      "memory_usage        5499 non-null float64\n",
      "memory_total        5499 non-null float64\n",
      "period              5499 non-null object\n",
      "weekday_tag         5499 non-null int64\n",
      "workday_tag         5499 non-null int64\n",
      "cpu_usage_tag       5499 non-null int64\n",
      "memory_usage_tag    5499 non-null int64\n",
      "dtypes: float64(7), int64(4), object(1)\n",
      "memory usage: 558.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series = df[\"cpu_usage_tag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts\n",
       "2017-08-04 07:09:00    0\n",
       "2017-08-04 07:10:00   -2\n",
       "2017-08-04 07:11:00   -2\n",
       "2017-08-04 07:12:00   -1\n",
       "2017-08-04 07:13:00   -2\n",
       "2017-08-04 07:14:00   -2\n",
       "2017-08-04 07:15:00    0\n",
       "2017-08-04 07:16:00    0\n",
       "2017-08-04 07:17:00   -1\n",
       "2017-08-04 07:18:00   -2\n",
       "2017-08-04 07:19:00   -3\n",
       "2017-08-04 07:20:00   -3\n",
       "2017-08-04 07:21:00   -3\n",
       "2017-08-04 07:22:00   -2\n",
       "2017-08-04 07:23:00   -3\n",
       "2017-08-04 07:24:00   -1\n",
       "2017-08-04 07:25:00    4\n",
       "2017-08-04 07:26:00    3\n",
       "2017-08-04 07:27:00   -2\n",
       "2017-08-04 07:28:00    0\n",
       "2017-08-04 07:29:00    0\n",
       "2017-08-04 07:30:00   -3\n",
       "2017-08-04 07:31:00   -3\n",
       "2017-08-04 07:32:00   -3\n",
       "2017-08-04 07:33:00   -3\n",
       "2017-08-04 07:34:00   -3\n",
       "2017-08-04 07:35:00   -3\n",
       "2017-08-04 07:36:00    0\n",
       "2017-08-04 07:37:00    0\n",
       "2017-08-04 07:38:00   -1\n",
       "                      ..\n",
       "2017-08-08 02:18:00   -1\n",
       "2017-08-08 02:19:00   -1\n",
       "2017-08-08 02:20:00   -2\n",
       "2017-08-08 02:21:00   -1\n",
       "2017-08-08 02:22:00   -1\n",
       "2017-08-08 02:23:00    0\n",
       "2017-08-08 02:24:00    0\n",
       "2017-08-08 02:25:00    1\n",
       "2017-08-08 02:26:00   -1\n",
       "2017-08-08 02:27:00   -1\n",
       "2017-08-08 02:28:00   -2\n",
       "2017-08-08 02:29:00   -1\n",
       "2017-08-08 02:30:00    0\n",
       "2017-08-08 02:31:00    1\n",
       "2017-08-08 02:32:00    0\n",
       "2017-08-08 02:33:00    0\n",
       "2017-08-08 02:34:00   -1\n",
       "2017-08-08 02:35:00   -2\n",
       "2017-08-08 02:36:00   -1\n",
       "2017-08-08 02:37:00   -1\n",
       "2017-08-08 02:38:00    0\n",
       "2017-08-08 02:39:00    1\n",
       "2017-08-08 02:40:00    0\n",
       "2017-08-08 02:41:00   -1\n",
       "2017-08-08 02:42:00   -1\n",
       "2017-08-08 02:43:00   -1\n",
       "2017-08-08 02:44:00   -1\n",
       "2017-08-08 02:45:00   -1\n",
       "2017-08-08 02:46:00    0\n",
       "2017-08-08 02:47:00    1\n",
       "Name: cpu_usage_tag, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform data to be stationary\n",
    "raw_values = series.values\n",
    "diff_values = difference(raw_values, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform data to be supervised learning\n",
    "supervised = timeseries_to_supervised(diff_values, 1)\n",
    "supervised_values = supervised.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_number = round(len(supervised_values) * 0.2)\n",
    "train_data_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data into train and test-sets\n",
    "train, test = supervised_values[:train_data_number], supervised_values[train_data_number:]\n",
    "\n",
    "# transform the scale of the data\n",
    "scaler, train_scaled, test_scaled = scale(train, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeats\n",
      "1) Test RMSE: 1.084\n",
      "repeats\n",
      "2) Test RMSE: 0.857\n",
      "repeats\n",
      "3) Test RMSE: 1.361\n",
      "repeats\n",
      "4) Test RMSE: 3.222\n",
      "repeats\n",
      "5) Test RMSE: 6.935\n",
      "repeats\n",
      "6) Test RMSE: 0.852\n",
      "repeats\n",
      "7) Test RMSE: 0.863\n",
      "repeats\n",
      "8) Test RMSE: 0.949\n",
      "repeats\n",
      "9) Test RMSE: 16.218\n",
      "repeats\n",
      "10) Test RMSE: 1.038\n",
      "repeats\n",
      "11) Test RMSE: 0.831\n",
      "repeats\n",
      "12) Test RMSE: 0.883\n",
      "repeats\n",
      "13) Test RMSE: 0.938\n",
      "repeats\n",
      "14) Test RMSE: 1.105\n",
      "repeats\n",
      "15) Test RMSE: 1.728\n",
      "repeats\n",
      "16) Test RMSE: 0.843\n",
      "repeats\n",
      "17) Test RMSE: 0.845\n",
      "repeats\n",
      "18) Test RMSE: 0.942\n",
      "repeats\n",
      "19) Test RMSE: 1.260\n",
      "repeats\n",
      "20) Test RMSE: 0.760\n",
      "repeats\n",
      "21) Test RMSE: 6.573\n",
      "repeats\n",
      "22) Test RMSE: 1.022\n",
      "repeats\n",
      "23) Test RMSE: 1.019\n",
      "repeats\n",
      "24) Test RMSE: 0.945\n",
      "repeats\n",
      "25) Test RMSE: 1.522\n",
      "repeats\n",
      "26) Test RMSE: 0.898\n",
      "repeats\n",
      "27) Test RMSE: 0.798\n",
      "repeats\n",
      "28) Test RMSE: 0.787\n",
      "repeats\n",
      "29) Test RMSE: 0.937\n",
      "repeats\n",
      "30) Test RMSE: 2.053\n"
     ]
    }
   ],
   "source": [
    "# repeat experiment\n",
    "repeats = 30\n",
    "error_scores = list()\n",
    "for r in range(repeats):\n",
    "\tprint(\"repeats\")\n",
    "\t# fit the model\n",
    "\tlstm_model = fit_lstm(train_scaled, 1, 60, 4)\n",
    "\t# forecast the entire training dataset to build up state for forecasting\n",
    "\ttrain_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n",
    "\tlstm_model.predict(train_reshaped, batch_size=1)\n",
    "\t# walk-forward validation on the test data\n",
    "\tpredictions = list()\n",
    "\tfor i in range(len(test_scaled)):     \n",
    "\t\t# make one-step forecast\n",
    "\t\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\t# invert scaling\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t# invert differencing\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\t# store forecast\n",
    "\t\tpredictions.append(yhat)\n",
    "\t# report performance\n",
    "\trmse = sqrt(mean_squared_error(raw_values[train_data_number+1:], predictions))\n",
    "\tprint('%d) Test RMSE: %.3f' % (r+1, rmse))\n",
    "\terror_scores.append(rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            rmse\n",
      "count  30.000000\n",
      "mean    2.002247\n",
      "std     3.080020\n",
      "min     0.759843\n",
      "25%     0.858611\n",
      "50%     0.946818\n",
      "75%     1.335993\n",
      "max    16.217533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:5: FutureWarning: \n",
      "The default value for 'return_type' will change to 'axes' in a future release.\n",
      " To use the future behavior now, set return_type='axes'.\n",
      " To keep the previous behavior and silence this warning, set return_type='dict'.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfwAAAFkCAYAAADFZ4k9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nC1+SpAr4/zw4RWmhrCCSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f57d818d908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize results\n",
    "results = DataFrame()\n",
    "results['rmse'] = error_scores\n",
    "print(results.describe())\n",
    "results.boxplot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Lstm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpu_ghz</th>\n",
       "      <th>cpu_usage</th>\n",
       "      <th>cpu_idle</th>\n",
       "      <th>cpu_total</th>\n",
       "      <th>memory_free_mb</th>\n",
       "      <th>memory_usage</th>\n",
       "      <th>memory_total</th>\n",
       "      <th>period</th>\n",
       "      <th>weekday_tag</th>\n",
       "      <th>workday_tag</th>\n",
       "      <th>cpu_usage_tag</th>\n",
       "      <th>memory_usage_tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ts</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-04 07:09:00</th>\n",
       "      <td>1.622994</td>\n",
       "      <td>0.058949</td>\n",
       "      <td>7229.349138</td>\n",
       "      <td>7626.006979</td>\n",
       "      <td>73703.339671</td>\n",
       "      <td>0.171460</td>\n",
       "      <td>85762.997397</td>\n",
       "      <td>night</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 07:10:00</th>\n",
       "      <td>1.565744</td>\n",
       "      <td>0.051145</td>\n",
       "      <td>7436.343501</td>\n",
       "      <td>7808.899014</td>\n",
       "      <td>73678.012357</td>\n",
       "      <td>0.171868</td>\n",
       "      <td>85762.997397</td>\n",
       "      <td>night</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      cpu_ghz  cpu_usage     cpu_idle    cpu_total  \\\n",
       "ts                                                                   \n",
       "2017-08-04 07:09:00  1.622994   0.058949  7229.349138  7626.006979   \n",
       "2017-08-04 07:10:00  1.565744   0.051145  7436.343501  7808.899014   \n",
       "\n",
       "                     memory_free_mb  memory_usage  memory_total period  \\\n",
       "ts                                                                       \n",
       "2017-08-04 07:09:00    73703.339671      0.171460  85762.997397  night   \n",
       "2017-08-04 07:10:00    73678.012357      0.171868  85762.997397  night   \n",
       "\n",
       "                     weekday_tag  workday_tag  cpu_usage_tag  memory_usage_tag  \n",
       "ts                                                                              \n",
       "2017-08-04 07:09:00            5            0              0                -3  \n",
       "2017-08-04 07:10:00            5            0             -2                -3  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_csv('cm_all_1.csv', header=0, squeeze=True)\n",
    "df = df.drop(df.columns[0],axis=1)\n",
    "df.ts = to_datetime(df.ts)\n",
    "df = df.set_index(['ts'])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# integer encode direction\n",
    "# tu: transform all your tag \n",
    "encoder = LabelEncoder()\n",
    "values[:,-1] = encoder.fit_transform(values[:,-1])\n",
    "values[:,-2] = encoder.fit_transform(values[:,-2])\n",
    "values[:,-3] = encoder.fit_transform(values[:,-2])\n",
    "values[:,-4] = encoder.fit_transform(values[:,-2])\n",
    "values[:,-5] = encoder.fit_transform(values[:,-5])\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify the number of lag hours\n",
    "# tu : n_min =set time lag how earlier data will you use to predict current data\n",
    "n_min = 3\n",
    "n_features = len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5496, 48)\n"
     ]
    }
   ],
   "source": [
    "# frame as supervised learning\n",
    "# series_to_supervised function is used to produce earlier data\n",
    "reframed = series_to_supervised(scaled, n_min, 1)\n",
    "print(reframed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-3)</th>\n",
       "      <th>var2(t-3)</th>\n",
       "      <th>var3(t-3)</th>\n",
       "      <th>var4(t-3)</th>\n",
       "      <th>var5(t-3)</th>\n",
       "      <th>var6(t-3)</th>\n",
       "      <th>var7(t-3)</th>\n",
       "      <th>var8(t-3)</th>\n",
       "      <th>var9(t-3)</th>\n",
       "      <th>var10(t-3)</th>\n",
       "      <th>...</th>\n",
       "      <th>var3(t)</th>\n",
       "      <th>var4(t)</th>\n",
       "      <th>var5(t)</th>\n",
       "      <th>var6(t)</th>\n",
       "      <th>var7(t)</th>\n",
       "      <th>var8(t)</th>\n",
       "      <th>var9(t)</th>\n",
       "      <th>var10(t)</th>\n",
       "      <th>var11(t)</th>\n",
       "      <th>var12(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.675438</td>\n",
       "      <td>0.178166</td>\n",
       "      <td>0.746099</td>\n",
       "      <td>0.141518</td>\n",
       "      <td>0.824924</td>\n",
       "      <td>0.226678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771196</td>\n",
       "      <td>0.216026</td>\n",
       "      <td>0.810045</td>\n",
       "      <td>0.243593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.384414</td>\n",
       "      <td>0.070833</td>\n",
       "      <td>0.984388</td>\n",
       "      <td>0.832260</td>\n",
       "      <td>0.815670</td>\n",
       "      <td>0.241034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795671</td>\n",
       "      <td>0.114113</td>\n",
       "      <td>0.803387</td>\n",
       "      <td>0.247914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.216763</td>\n",
       "      <td>0.061021</td>\n",
       "      <td>0.789425</td>\n",
       "      <td>0.149235</td>\n",
       "      <td>0.816225</td>\n",
       "      <td>0.240459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792730</td>\n",
       "      <td>0.112547</td>\n",
       "      <td>0.806696</td>\n",
       "      <td>0.244091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.242970</td>\n",
       "      <td>0.125575</td>\n",
       "      <td>0.771196</td>\n",
       "      <td>0.216026</td>\n",
       "      <td>0.810045</td>\n",
       "      <td>0.243593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710845</td>\n",
       "      <td>0.128136</td>\n",
       "      <td>0.811136</td>\n",
       "      <td>0.238269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.228314</td>\n",
       "      <td>0.044047</td>\n",
       "      <td>0.795671</td>\n",
       "      <td>0.114113</td>\n",
       "      <td>0.803387</td>\n",
       "      <td>0.247914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687066</td>\n",
       "      <td>0.091911</td>\n",
       "      <td>0.807299</td>\n",
       "      <td>0.240543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-3)  var2(t-3)  var3(t-3)  var4(t-3)  var5(t-3)  var6(t-3)  \\\n",
       "3   0.675438   0.178166   0.746099   0.141518   0.824924   0.226678   \n",
       "4   0.384414   0.070833   0.984388   0.832260   0.815670   0.241034   \n",
       "5   0.216763   0.061021   0.789425   0.149235   0.816225   0.240459   \n",
       "6   0.242970   0.125575   0.771196   0.216026   0.810045   0.243593   \n",
       "7   0.228314   0.044047   0.795671   0.114113   0.803387   0.247914   \n",
       "\n",
       "   var7(t-3)  var8(t-3)  var9(t-3)  var10(t-3)    ...      var3(t)   var4(t)  \\\n",
       "3        0.0       0.75   0.428571    0.428571    ...     0.771196  0.216026   \n",
       "4        0.0       0.75   0.142857    0.142857    ...     0.795671  0.114113   \n",
       "5        0.0       0.75   0.142857    0.142857    ...     0.792730  0.112547   \n",
       "6        0.0       0.75   0.285714    0.285714    ...     0.710845  0.128136   \n",
       "7        0.0       0.75   0.142857    0.142857    ...     0.687066  0.091911   \n",
       "\n",
       "    var5(t)   var6(t)  var7(t)  var8(t)   var9(t)  var10(t)  var11(t)  \\\n",
       "3  0.810045  0.243593      0.0     0.75  0.285714  0.285714  0.285714   \n",
       "4  0.803387  0.247914      0.0     0.75  0.142857  0.142857  0.142857   \n",
       "5  0.806696  0.244091      0.0     0.75  0.142857  0.142857  0.142857   \n",
       "6  0.811136  0.238269      0.0     0.75  0.428571  0.428571  0.428571   \n",
       "7  0.807299  0.240543      0.0     0.75  0.428571  0.428571  0.428571   \n",
       "\n",
       "   var12(t)  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "5       0.0  \n",
       "6       0.0  \n",
       "7       0.0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check dataframe processed by series_to_supervised function\n",
    "reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preserve original data, this dataframe will be used to calculate RMSE \n",
    "#between y_prediction and y_realdata in the last two code cells\n",
    "\n",
    "original_data = reframed[reframed.columns[n_features*n_min:]]\n",
    "len(original_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set list used to preserve only data what you want to predict\n",
    "# what to predict is the remove one is this list\n",
    "\n",
    "unused_col = [(\"var%d(t)\"%i) for i in range(1,n_features+1)]\n",
    "unused_col.remove('var11(t)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-3)</th>\n",
       "      <th>var2(t-3)</th>\n",
       "      <th>var3(t-3)</th>\n",
       "      <th>var4(t-3)</th>\n",
       "      <th>var5(t-3)</th>\n",
       "      <th>var6(t-3)</th>\n",
       "      <th>var7(t-3)</th>\n",
       "      <th>var8(t-3)</th>\n",
       "      <th>var9(t-3)</th>\n",
       "      <th>var10(t-3)</th>\n",
       "      <th>...</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var8(t-1)</th>\n",
       "      <th>var9(t-1)</th>\n",
       "      <th>var10(t-1)</th>\n",
       "      <th>var11(t-1)</th>\n",
       "      <th>var12(t-1)</th>\n",
       "      <th>var11(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.675438</td>\n",
       "      <td>0.178166</td>\n",
       "      <td>0.746099</td>\n",
       "      <td>0.141518</td>\n",
       "      <td>0.824924</td>\n",
       "      <td>0.226678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149235</td>\n",
       "      <td>0.816225</td>\n",
       "      <td>0.240459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.384414</td>\n",
       "      <td>0.070833</td>\n",
       "      <td>0.984388</td>\n",
       "      <td>0.832260</td>\n",
       "      <td>0.815670</td>\n",
       "      <td>0.241034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216026</td>\n",
       "      <td>0.810045</td>\n",
       "      <td>0.243593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.216763</td>\n",
       "      <td>0.061021</td>\n",
       "      <td>0.789425</td>\n",
       "      <td>0.149235</td>\n",
       "      <td>0.816225</td>\n",
       "      <td>0.240459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114113</td>\n",
       "      <td>0.803387</td>\n",
       "      <td>0.247914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.242970</td>\n",
       "      <td>0.125575</td>\n",
       "      <td>0.771196</td>\n",
       "      <td>0.216026</td>\n",
       "      <td>0.810045</td>\n",
       "      <td>0.243593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112547</td>\n",
       "      <td>0.806696</td>\n",
       "      <td>0.244091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.228314</td>\n",
       "      <td>0.044047</td>\n",
       "      <td>0.795671</td>\n",
       "      <td>0.114113</td>\n",
       "      <td>0.803387</td>\n",
       "      <td>0.247914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128136</td>\n",
       "      <td>0.811136</td>\n",
       "      <td>0.238269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-3)  var2(t-3)  var3(t-3)  var4(t-3)  var5(t-3)  var6(t-3)  \\\n",
       "3   0.675438   0.178166   0.746099   0.141518   0.824924   0.226678   \n",
       "4   0.384414   0.070833   0.984388   0.832260   0.815670   0.241034   \n",
       "5   0.216763   0.061021   0.789425   0.149235   0.816225   0.240459   \n",
       "6   0.242970   0.125575   0.771196   0.216026   0.810045   0.243593   \n",
       "7   0.228314   0.044047   0.795671   0.114113   0.803387   0.247914   \n",
       "\n",
       "   var7(t-3)  var8(t-3)  var9(t-3)  var10(t-3)    ...     var4(t-1)  \\\n",
       "3        0.0       0.75   0.428571    0.428571    ...      0.149235   \n",
       "4        0.0       0.75   0.142857    0.142857    ...      0.216026   \n",
       "5        0.0       0.75   0.142857    0.142857    ...      0.114113   \n",
       "6        0.0       0.75   0.285714    0.285714    ...      0.112547   \n",
       "7        0.0       0.75   0.142857    0.142857    ...      0.128136   \n",
       "\n",
       "   var5(t-1)  var6(t-1)  var7(t-1)  var8(t-1)  var9(t-1)  var10(t-1)  \\\n",
       "3   0.816225   0.240459        0.0       0.75   0.142857    0.142857   \n",
       "4   0.810045   0.243593        0.0       0.75   0.285714    0.285714   \n",
       "5   0.803387   0.247914        0.0       0.75   0.142857    0.142857   \n",
       "6   0.806696   0.244091        0.0       0.75   0.142857    0.142857   \n",
       "7   0.811136   0.238269        0.0       0.75   0.428571    0.428571   \n",
       "\n",
       "   var11(t-1)  var12(t-1)  var11(t)  \n",
       "3    0.142857         0.0  0.285714  \n",
       "4    0.285714         0.0  0.142857  \n",
       "5    0.142857         0.0  0.142857  \n",
       "6    0.142857         0.0  0.428571  \n",
       "7    0.428571         0.0  0.428571  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use drop code to delete other current data except what you want to predict\n",
    "reframed1 = reframed.drop(unused_col,axis =1)\n",
    "reframed1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "values = reframed1.values\n",
    "train_data_number = 1100 #set number as lstm1\n",
    "train = values[:train_data_number, :]\n",
    "test = values[train_data_number:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100, 36) 1100 (1100, 1)\n"
     ]
    }
   ],
   "source": [
    "n_obs = n_min * n_features\n",
    "train_X, train_y = train[:, :n_obs], train[:,n_obs:]\n",
    "test_X, test_y = test[:, :n_obs], test[:,n_obs:]\n",
    "print(train_X.shape, len(train_X), train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100, 3, 12) (1100, 1) (4396, 3, 12) (4396, 1)\n"
     ]
    }
   ],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_min, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_min, n_features))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "16s - loss: 0.0977 - val_loss: 0.1125\n",
      "Epoch 2/60\n",
      "17s - loss: 0.0964 - val_loss: 0.1122\n",
      "Epoch 3/60\n",
      "13s - loss: 0.0954 - val_loss: 0.1096\n",
      "Epoch 4/60\n",
      "13s - loss: 0.0942 - val_loss: 0.1019\n",
      "Epoch 5/60\n",
      "12s - loss: 0.0930 - val_loss: 0.1046\n",
      "Epoch 6/60\n",
      "14s - loss: 0.0916 - val_loss: 0.1132\n",
      "Epoch 7/60\n",
      "12s - loss: 0.0898 - val_loss: 0.1088\n",
      "Epoch 8/60\n",
      "13s - loss: 0.0881 - val_loss: 0.0970\n",
      "Epoch 9/60\n",
      "12s - loss: 0.0851 - val_loss: 0.1078\n",
      "Epoch 10/60\n",
      "13s - loss: 0.0834 - val_loss: 0.0963\n",
      "Epoch 11/60\n",
      "14s - loss: 0.0819 - val_loss: 0.1124\n",
      "Epoch 12/60\n",
      "14s - loss: 0.0810 - val_loss: 0.0855\n",
      "Epoch 13/60\n",
      "15s - loss: 0.0798 - val_loss: 0.0899\n",
      "Epoch 14/60\n",
      "14s - loss: 0.0785 - val_loss: 0.0894\n",
      "Epoch 15/60\n",
      "13s - loss: 0.0770 - val_loss: 0.0820\n",
      "Epoch 16/60\n",
      "14s - loss: 0.0762 - val_loss: 0.0825\n",
      "Epoch 17/60\n",
      "14s - loss: 0.0747 - val_loss: 0.0798\n",
      "Epoch 18/60\n",
      "12s - loss: 0.0738 - val_loss: 0.0800\n",
      "Epoch 19/60\n",
      "14s - loss: 0.0733 - val_loss: 0.0806\n",
      "Epoch 20/60\n",
      "12s - loss: 0.0724 - val_loss: 0.0826\n",
      "Epoch 21/60\n",
      "14s - loss: 0.0711 - val_loss: 0.0736\n",
      "Epoch 22/60\n",
      "13s - loss: 0.0705 - val_loss: 0.0791\n",
      "Epoch 23/60\n",
      "15s - loss: 0.0700 - val_loss: 0.0735\n",
      "Epoch 24/60\n",
      "17s - loss: 0.0685 - val_loss: 0.0769\n",
      "Epoch 25/60\n",
      "18s - loss: 0.0682 - val_loss: 0.0757\n",
      "Epoch 26/60\n",
      "14s - loss: 0.0672 - val_loss: 0.0749\n",
      "Epoch 27/60\n",
      "12s - loss: 0.0665 - val_loss: 0.0888\n",
      "Epoch 28/60\n",
      "12s - loss: 0.0661 - val_loss: 0.0851\n",
      "Epoch 29/60\n",
      "12s - loss: 0.0657 - val_loss: 0.0794\n",
      "Epoch 30/60\n",
      "12s - loss: 0.0655 - val_loss: 0.0808\n",
      "Epoch 31/60\n",
      "13s - loss: 0.0648 - val_loss: 0.0809\n",
      "Epoch 32/60\n",
      "13s - loss: 0.0644 - val_loss: 0.0879\n",
      "Epoch 33/60\n",
      "13s - loss: 0.0641 - val_loss: 0.0835\n",
      "Epoch 34/60\n",
      "12s - loss: 0.0635 - val_loss: 0.0793\n",
      "Epoch 35/60\n",
      "13s - loss: 0.0629 - val_loss: 0.0916\n",
      "Epoch 36/60\n",
      "13s - loss: 0.0620 - val_loss: 0.0852\n",
      "Epoch 37/60\n",
      "13s - loss: 0.0624 - val_loss: 0.0874\n",
      "Epoch 38/60\n",
      "14s - loss: 0.0618 - val_loss: 0.0785\n",
      "Epoch 39/60\n",
      "14s - loss: 0.0615 - val_loss: 0.0795\n",
      "Epoch 40/60\n",
      "13s - loss: 0.0609 - val_loss: 0.0829\n",
      "Epoch 41/60\n",
      "13s - loss: 0.0609 - val_loss: 0.0806\n",
      "Epoch 42/60\n",
      "15s - loss: 0.0605 - val_loss: 0.0819\n",
      "Epoch 43/60\n",
      "14s - loss: 0.0598 - val_loss: 0.0821\n",
      "Epoch 44/60\n",
      "14s - loss: 0.0599 - val_loss: 0.0818\n",
      "Epoch 45/60\n",
      "12s - loss: 0.0591 - val_loss: 0.0786\n",
      "Epoch 46/60\n",
      "13s - loss: 0.0590 - val_loss: 0.0857\n",
      "Epoch 47/60\n",
      "13s - loss: 0.0595 - val_loss: 0.0867\n",
      "Epoch 48/60\n",
      "16s - loss: 0.0579 - val_loss: 0.0861\n",
      "Epoch 49/60\n",
      "14s - loss: 0.0581 - val_loss: 0.0776\n",
      "Epoch 50/60\n",
      "13s - loss: 0.0581 - val_loss: 0.0791\n",
      "Epoch 51/60\n",
      "13s - loss: 0.0578 - val_loss: 0.0759\n",
      "Epoch 52/60\n",
      "13s - loss: 0.0574 - val_loss: 0.0815\n",
      "Epoch 53/60\n",
      "13s - loss: 0.0573 - val_loss: 0.0815\n",
      "Epoch 54/60\n",
      "13s - loss: 0.0571 - val_loss: 0.0813\n",
      "Epoch 55/60\n",
      "13s - loss: 0.0570 - val_loss: 0.0730\n",
      "Epoch 56/60\n",
      "13s - loss: 0.0565 - val_loss: 0.0841\n",
      "Epoch 57/60\n",
      "13s - loss: 0.0564 - val_loss: 0.0813\n",
      "Epoch 58/60\n",
      "12s - loss: 0.0558 - val_loss: 0.0831\n",
      "Epoch 59/60\n",
      "13s - loss: 0.0561 - val_loss: 0.0756\n",
      "Epoch 60/60\n",
      "13s - loss: 0.0555 - val_loss: 0.0823\n",
      "1) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "13s - loss: 0.0556 - val_loss: 0.0770\n",
      "Epoch 2/60\n",
      "13s - loss: 0.0547 - val_loss: 0.0752\n",
      "Epoch 3/60\n",
      "13s - loss: 0.0553 - val_loss: 0.0881\n",
      "Epoch 4/60\n",
      "13s - loss: 0.0548 - val_loss: 0.0803\n",
      "Epoch 5/60\n",
      "13s - loss: 0.0541 - val_loss: 0.0932\n",
      "Epoch 6/60\n",
      "13s - loss: 0.0544 - val_loss: 0.0773\n",
      "Epoch 7/60\n",
      "13s - loss: 0.0541 - val_loss: 0.0865\n",
      "Epoch 8/60\n",
      "13s - loss: 0.0540 - val_loss: 0.0796\n",
      "Epoch 9/60\n",
      "13s - loss: 0.0534 - val_loss: 0.0902\n",
      "Epoch 10/60\n",
      "13s - loss: 0.0532 - val_loss: 0.0794\n",
      "Epoch 11/60\n",
      "13s - loss: 0.0532 - val_loss: 0.0928\n",
      "Epoch 12/60\n",
      "13s - loss: 0.0528 - val_loss: 0.0819\n",
      "Epoch 13/60\n",
      "13s - loss: 0.0532 - val_loss: 0.0822\n",
      "Epoch 14/60\n",
      "12s - loss: 0.0525 - val_loss: 0.0805\n",
      "Epoch 15/60\n",
      "13s - loss: 0.0525 - val_loss: 0.0797\n",
      "Epoch 16/60\n",
      "14s - loss: 0.0521 - val_loss: 0.0836\n",
      "Epoch 17/60\n",
      "18s - loss: 0.0525 - val_loss: 0.0849\n",
      "Epoch 18/60\n",
      "14s - loss: 0.0516 - val_loss: 0.0905\n",
      "Epoch 19/60\n",
      "14s - loss: 0.0512 - val_loss: 0.0838\n",
      "Epoch 20/60\n",
      "15s - loss: 0.0511 - val_loss: 0.0872\n",
      "Epoch 21/60\n",
      "14s - loss: 0.0521 - val_loss: 0.0797\n",
      "Epoch 22/60\n",
      "15s - loss: 0.0509 - val_loss: 0.0826\n",
      "Epoch 23/60\n",
      "15s - loss: 0.0506 - val_loss: 0.0805\n",
      "Epoch 24/60\n",
      "16s - loss: 0.0512 - val_loss: 0.0776\n",
      "Epoch 25/60\n",
      "15s - loss: 0.0501 - val_loss: 0.0784\n",
      "Epoch 26/60\n",
      "16s - loss: 0.0503 - val_loss: 0.0779\n",
      "Epoch 27/60\n",
      "16s - loss: 0.0498 - val_loss: 0.0816\n",
      "Epoch 28/60\n",
      "16s - loss: 0.0503 - val_loss: 0.0778\n",
      "Epoch 29/60\n",
      "16s - loss: 0.0491 - val_loss: 0.0817\n",
      "Epoch 30/60\n",
      "16s - loss: 0.0494 - val_loss: 0.0710\n",
      "Epoch 31/60\n",
      "11s - loss: 0.0489 - val_loss: 0.0822\n",
      "Epoch 32/60\n",
      "13s - loss: 0.0494 - val_loss: 0.0765\n",
      "Epoch 33/60\n",
      "12s - loss: 0.0502 - val_loss: 0.0752\n",
      "Epoch 34/60\n",
      "12s - loss: 0.0485 - val_loss: 0.0742\n",
      "Epoch 35/60\n",
      "12s - loss: 0.0481 - val_loss: 0.0747\n",
      "Epoch 36/60\n",
      "12s - loss: 0.0483 - val_loss: 0.0751\n",
      "Epoch 37/60\n",
      "12s - loss: 0.0483 - val_loss: 0.0738\n",
      "Epoch 38/60\n",
      "18s - loss: 0.0485 - val_loss: 0.0774\n",
      "Epoch 39/60\n",
      "14s - loss: 0.0484 - val_loss: 0.0773\n",
      "Epoch 40/60\n",
      "12s - loss: 0.0477 - val_loss: 0.0747\n",
      "Epoch 41/60\n",
      "12s - loss: 0.0476 - val_loss: 0.0766\n",
      "Epoch 42/60\n",
      "14s - loss: 0.0473 - val_loss: 0.0825\n",
      "Epoch 43/60\n",
      "14s - loss: 0.0475 - val_loss: 0.0776\n",
      "Epoch 44/60\n",
      "22s - loss: 0.0465 - val_loss: 0.0759\n",
      "Epoch 45/60\n",
      "14s - loss: 0.0470 - val_loss: 0.0759\n",
      "Epoch 46/60\n",
      "12s - loss: 0.0470 - val_loss: 0.0779\n",
      "Epoch 47/60\n",
      "12s - loss: 0.0462 - val_loss: 0.0779\n",
      "Epoch 48/60\n",
      "12s - loss: 0.0471 - val_loss: 0.0781\n",
      "Epoch 49/60\n",
      "14s - loss: 0.0458 - val_loss: 0.0782\n",
      "Epoch 50/60\n",
      "12s - loss: 0.0457 - val_loss: 0.0758\n",
      "Epoch 51/60\n",
      "12s - loss: 0.0457 - val_loss: 0.0749\n",
      "Epoch 52/60\n",
      "12s - loss: 0.0449 - val_loss: 0.0798\n",
      "Epoch 53/60\n",
      "14s - loss: 0.0468 - val_loss: 0.0808\n",
      "Epoch 54/60\n",
      "14s - loss: 0.0456 - val_loss: 0.0760\n",
      "Epoch 55/60\n",
      "12s - loss: 0.0455 - val_loss: 0.0786\n",
      "Epoch 56/60\n",
      "12s - loss: 0.0451 - val_loss: 0.0804\n",
      "Epoch 57/60\n",
      "13s - loss: 0.0449 - val_loss: 0.0784\n",
      "Epoch 58/60\n",
      "12s - loss: 0.0447 - val_loss: 0.0767\n",
      "Epoch 59/60\n",
      "10s - loss: 0.0452 - val_loss: 0.0796\n",
      "Epoch 60/60\n",
      "12s - loss: 0.0445 - val_loss: 0.0773\n",
      "2) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "12s - loss: 0.0445 - val_loss: 0.0792\n",
      "Epoch 2/60\n",
      "10s - loss: 0.0447 - val_loss: 0.0811\n",
      "Epoch 3/60\n",
      "14s - loss: 0.0448 - val_loss: 0.0797\n",
      "Epoch 4/60\n",
      "13s - loss: 0.0452 - val_loss: 0.0785\n",
      "Epoch 5/60\n",
      "12s - loss: 0.0436 - val_loss: 0.0778\n",
      "Epoch 6/60\n",
      "12s - loss: 0.0438 - val_loss: 0.0794\n",
      "Epoch 7/60\n",
      "12s - loss: 0.0438 - val_loss: 0.0768\n",
      "Epoch 8/60\n",
      "15s - loss: 0.0439 - val_loss: 0.0790\n",
      "Epoch 9/60\n",
      "15s - loss: 0.0438 - val_loss: 0.0769\n",
      "Epoch 10/60\n",
      "15s - loss: 0.0439 - val_loss: 0.0782\n",
      "Epoch 11/60\n",
      "12s - loss: 0.0439 - val_loss: 0.0796\n",
      "Epoch 12/60\n",
      "13s - loss: 0.0429 - val_loss: 0.0808\n",
      "Epoch 13/60\n",
      "12s - loss: 0.0437 - val_loss: 0.0801\n",
      "Epoch 14/60\n",
      "13s - loss: 0.0437 - val_loss: 0.0803\n",
      "Epoch 15/60\n",
      "15s - loss: 0.0429 - val_loss: 0.0789\n",
      "Epoch 16/60\n",
      "14s - loss: 0.0434 - val_loss: 0.0774\n",
      "Epoch 17/60\n",
      "13s - loss: 0.0424 - val_loss: 0.0770\n",
      "Epoch 18/60\n",
      "12s - loss: 0.0428 - val_loss: 0.0808\n",
      "Epoch 19/60\n",
      "12s - loss: 0.0430 - val_loss: 0.0816\n",
      "Epoch 20/60\n",
      "13s - loss: 0.0433 - val_loss: 0.0799\n",
      "Epoch 21/60\n",
      "12s - loss: 0.0414 - val_loss: 0.0817\n",
      "Epoch 22/60\n",
      "12s - loss: 0.0439 - val_loss: 0.0798\n",
      "Epoch 23/60\n",
      "12s - loss: 0.0422 - val_loss: 0.0797\n",
      "Epoch 24/60\n",
      "12s - loss: 0.0423 - val_loss: 0.0797\n",
      "Epoch 25/60\n",
      "12s - loss: 0.0417 - val_loss: 0.0797\n",
      "Epoch 26/60\n",
      "12s - loss: 0.0417 - val_loss: 0.0763\n",
      "Epoch 27/60\n",
      "13s - loss: 0.0419 - val_loss: 0.0803\n",
      "Epoch 28/60\n",
      "13s - loss: 0.0428 - val_loss: 0.0811\n",
      "Epoch 29/60\n",
      "12s - loss: 0.0415 - val_loss: 0.0787\n",
      "Epoch 30/60\n",
      "12s - loss: 0.0412 - val_loss: 0.0809\n",
      "Epoch 31/60\n",
      "12s - loss: 0.0410 - val_loss: 0.0809\n",
      "Epoch 32/60\n",
      "16s - loss: 0.0408 - val_loss: 0.0820\n",
      "Epoch 33/60\n",
      "13s - loss: 0.0422 - val_loss: 0.0812\n",
      "Epoch 34/60\n",
      "12s - loss: 0.0405 - val_loss: 0.0815\n",
      "Epoch 35/60\n",
      "13s - loss: 0.0406 - val_loss: 0.0810\n",
      "Epoch 36/60\n",
      "13s - loss: 0.0412 - val_loss: 0.0833\n",
      "Epoch 37/60\n",
      "13s - loss: 0.0410 - val_loss: 0.0784\n",
      "Epoch 38/60\n",
      "12s - loss: 0.0407 - val_loss: 0.0772\n",
      "Epoch 39/60\n",
      "12s - loss: 0.0405 - val_loss: 0.0781\n",
      "Epoch 40/60\n",
      "12s - loss: 0.0403 - val_loss: 0.0808\n",
      "Epoch 41/60\n",
      "13s - loss: 0.0404 - val_loss: 0.0805\n",
      "Epoch 42/60\n",
      "12s - loss: 0.0402 - val_loss: 0.0789\n",
      "Epoch 43/60\n",
      "12s - loss: 0.0405 - val_loss: 0.0800\n",
      "Epoch 44/60\n",
      "12s - loss: 0.0401 - val_loss: 0.0826\n",
      "Epoch 45/60\n",
      "12s - loss: 0.0398 - val_loss: 0.0812\n",
      "Epoch 46/60\n",
      "12s - loss: 0.0404 - val_loss: 0.0779\n",
      "Epoch 47/60\n",
      "12s - loss: 0.0397 - val_loss: 0.0823\n",
      "Epoch 48/60\n",
      "12s - loss: 0.0398 - val_loss: 0.0837\n",
      "Epoch 49/60\n",
      "12s - loss: 0.0398 - val_loss: 0.0848\n",
      "Epoch 50/60\n",
      "12s - loss: 0.0385 - val_loss: 0.0824\n",
      "Epoch 51/60\n",
      "12s - loss: 0.0394 - val_loss: 0.0810\n",
      "Epoch 52/60\n",
      "12s - loss: 0.0397 - val_loss: 0.0789\n",
      "Epoch 53/60\n",
      "11s - loss: 0.0394 - val_loss: 0.0811\n",
      "Epoch 54/60\n",
      "18s - loss: 0.0389 - val_loss: 0.0850\n",
      "Epoch 55/60\n",
      "15s - loss: 0.0395 - val_loss: 0.0785\n",
      "Epoch 56/60\n",
      "12s - loss: 0.0385 - val_loss: 0.0819\n",
      "Epoch 57/60\n",
      "9s - loss: 0.0392 - val_loss: 0.0797\n",
      "Epoch 58/60\n",
      "8s - loss: 0.0383 - val_loss: 0.0800\n",
      "Epoch 59/60\n",
      "7s - loss: 0.0398 - val_loss: 0.0800\n",
      "Epoch 60/60\n",
      "7s - loss: 0.0390 - val_loss: 0.0843\n",
      "3) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "7s - loss: 0.0391 - val_loss: 0.0826\n",
      "Epoch 2/60\n",
      "8s - loss: 0.0393 - val_loss: 0.0810\n",
      "Epoch 3/60\n",
      "8s - loss: 0.0387 - val_loss: 0.0804\n",
      "Epoch 4/60\n",
      "8s - loss: 0.0384 - val_loss: 0.0856\n",
      "Epoch 5/60\n",
      "7s - loss: 0.0371 - val_loss: 0.0793\n",
      "Epoch 6/60\n",
      "7s - loss: 0.0388 - val_loss: 0.0811\n",
      "Epoch 7/60\n",
      "8s - loss: 0.0379 - val_loss: 0.0813\n",
      "Epoch 8/60\n",
      "10s - loss: 0.0384 - val_loss: 0.0822\n",
      "Epoch 9/60\n",
      "11s - loss: 0.0378 - val_loss: 0.0840\n",
      "Epoch 10/60\n",
      "11s - loss: 0.0371 - val_loss: 0.0841\n",
      "Epoch 11/60\n",
      "8s - loss: 0.0373 - val_loss: 0.0869\n",
      "Epoch 12/60\n",
      "8s - loss: 0.0382 - val_loss: 0.0855\n",
      "Epoch 13/60\n",
      "8s - loss: 0.0380 - val_loss: 0.0857\n",
      "Epoch 14/60\n",
      "7s - loss: 0.0380 - val_loss: 0.0815\n",
      "Epoch 15/60\n",
      "7s - loss: 0.0370 - val_loss: 0.0861\n",
      "Epoch 16/60\n",
      "7s - loss: 0.0374 - val_loss: 0.0866\n",
      "Epoch 17/60\n",
      "9s - loss: 0.0378 - val_loss: 0.0856\n",
      "Epoch 18/60\n",
      "9s - loss: 0.0379 - val_loss: 0.0835\n",
      "Epoch 19/60\n",
      "10s - loss: 0.0373 - val_loss: 0.0859\n",
      "Epoch 20/60\n",
      "14s - loss: 0.0365 - val_loss: 0.0885\n",
      "Epoch 21/60\n",
      "10s - loss: 0.0365 - val_loss: 0.0870\n",
      "Epoch 22/60\n",
      "9s - loss: 0.0367 - val_loss: 0.0873\n",
      "Epoch 23/60\n",
      "9s - loss: 0.0369 - val_loss: 0.0856\n",
      "Epoch 24/60\n",
      "9s - loss: 0.0364 - val_loss: 0.0860\n",
      "Epoch 25/60\n",
      "8s - loss: 0.0362 - val_loss: 0.0883\n",
      "Epoch 26/60\n",
      "8s - loss: 0.0360 - val_loss: 0.0874\n",
      "Epoch 27/60\n",
      "8s - loss: 0.0369 - val_loss: 0.0870\n",
      "Epoch 28/60\n",
      "8s - loss: 0.0361 - val_loss: 0.0891\n",
      "Epoch 29/60\n",
      "8s - loss: 0.0365 - val_loss: 0.0921\n",
      "Epoch 30/60\n",
      "8s - loss: 0.0369 - val_loss: 0.0854\n",
      "Epoch 31/60\n",
      "8s - loss: 0.0357 - val_loss: 0.0996\n",
      "Epoch 32/60\n",
      "11s - loss: 0.0364 - val_loss: 0.0858\n",
      "Epoch 33/60\n",
      "9s - loss: 0.0370 - val_loss: 0.0927\n",
      "Epoch 34/60\n",
      "7s - loss: 0.0361 - val_loss: 0.0985\n",
      "Epoch 35/60\n",
      "7s - loss: 0.0355 - val_loss: 0.0878\n",
      "Epoch 36/60\n",
      "7s - loss: 0.0362 - val_loss: 0.0835\n",
      "Epoch 37/60\n",
      "8s - loss: 0.0356 - val_loss: 0.0837\n",
      "Epoch 38/60\n",
      "8s - loss: 0.0350 - val_loss: 0.0836\n",
      "Epoch 39/60\n",
      "8s - loss: 0.0352 - val_loss: 0.0877\n",
      "Epoch 40/60\n",
      "8s - loss: 0.0359 - val_loss: 0.0853\n",
      "Epoch 41/60\n",
      "7s - loss: 0.0363 - val_loss: 0.0865\n",
      "Epoch 42/60\n",
      "7s - loss: 0.0363 - val_loss: 0.0854\n",
      "Epoch 43/60\n",
      "7s - loss: 0.0350 - val_loss: 0.0884\n",
      "Epoch 44/60\n",
      "7s - loss: 0.0361 - val_loss: 0.0898\n",
      "Epoch 45/60\n",
      "7s - loss: 0.0355 - val_loss: 0.0854\n",
      "Epoch 46/60\n",
      "8s - loss: 0.0346 - val_loss: 0.0906\n",
      "Epoch 47/60\n",
      "7s - loss: 0.0351 - val_loss: 0.0882\n",
      "Epoch 48/60\n",
      "7s - loss: 0.0354 - val_loss: 0.0865\n",
      "Epoch 49/60\n",
      "7s - loss: 0.0347 - val_loss: 0.0922\n",
      "Epoch 50/60\n",
      "6s - loss: 0.0351 - val_loss: 0.0906\n",
      "Epoch 51/60\n",
      "7s - loss: 0.0344 - val_loss: 0.0946\n",
      "Epoch 52/60\n",
      "7s - loss: 0.0343 - val_loss: 0.0905\n",
      "Epoch 53/60\n",
      "6s - loss: 0.0352 - val_loss: 0.0907\n",
      "Epoch 54/60\n",
      "6s - loss: 0.0348 - val_loss: 0.0850\n",
      "Epoch 55/60\n",
      "7s - loss: 0.0350 - val_loss: 0.0919\n",
      "Epoch 56/60\n",
      "7s - loss: 0.0345 - val_loss: 0.0908\n",
      "Epoch 57/60\n",
      "7s - loss: 0.0342 - val_loss: 0.0887\n",
      "Epoch 58/60\n",
      "7s - loss: 0.0349 - val_loss: 0.0867\n",
      "Epoch 59/60\n",
      "6s - loss: 0.0346 - val_loss: 0.0840\n",
      "Epoch 60/60\n",
      "7s - loss: 0.0352 - val_loss: 0.0935\n",
      "4) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "7s - loss: 0.0343 - val_loss: 0.0899\n",
      "Epoch 2/60\n",
      "6s - loss: 0.0344 - val_loss: 0.0910\n",
      "Epoch 3/60\n",
      "7s - loss: 0.0336 - val_loss: 0.0963\n",
      "Epoch 4/60\n",
      "6s - loss: 0.0340 - val_loss: 0.0906\n",
      "Epoch 5/60\n",
      "6s - loss: 0.0339 - val_loss: 0.0865\n",
      "Epoch 6/60\n",
      "6s - loss: 0.0336 - val_loss: 0.0932\n",
      "Epoch 7/60\n",
      "6s - loss: 0.0345 - val_loss: 0.0912\n",
      "Epoch 8/60\n",
      "6s - loss: 0.0347 - val_loss: 0.0907\n",
      "Epoch 9/60\n",
      "6s - loss: 0.0334 - val_loss: 0.0897\n",
      "Epoch 10/60\n",
      "6s - loss: 0.0341 - val_loss: 0.0922\n",
      "Epoch 11/60\n",
      "6s - loss: 0.0327 - val_loss: 0.0924\n",
      "Epoch 12/60\n",
      "6s - loss: 0.0332 - val_loss: 0.0927\n",
      "Epoch 13/60\n",
      "6s - loss: 0.0337 - val_loss: 0.0891\n",
      "Epoch 14/60\n",
      "6s - loss: 0.0327 - val_loss: 0.0917\n",
      "Epoch 15/60\n",
      "6s - loss: 0.0335 - val_loss: 0.0945\n",
      "Epoch 16/60\n",
      "6s - loss: 0.0331 - val_loss: 0.0869\n",
      "Epoch 17/60\n",
      "6s - loss: 0.0328 - val_loss: 0.0933\n",
      "Epoch 18/60\n",
      "10s - loss: 0.0330 - val_loss: 0.0931\n",
      "Epoch 19/60\n",
      "8s - loss: 0.0332 - val_loss: 0.0862\n",
      "Epoch 20/60\n",
      "7s - loss: 0.0333 - val_loss: 0.0939\n",
      "Epoch 21/60\n",
      "7s - loss: 0.0316 - val_loss: 0.0937\n",
      "Epoch 22/60\n",
      "6s - loss: 0.0326 - val_loss: 0.0891\n",
      "Epoch 23/60\n",
      "6s - loss: 0.0331 - val_loss: 0.0934\n",
      "Epoch 24/60\n",
      "6s - loss: 0.0337 - val_loss: 0.0956\n",
      "Epoch 25/60\n",
      "7s - loss: 0.0325 - val_loss: 0.0894\n",
      "Epoch 26/60\n",
      "6s - loss: 0.0325 - val_loss: 0.0887\n",
      "Epoch 27/60\n",
      "6s - loss: 0.0324 - val_loss: 0.0844\n",
      "Epoch 28/60\n",
      "7s - loss: 0.0317 - val_loss: 0.0885\n",
      "Epoch 29/60\n",
      "7s - loss: 0.0319 - val_loss: 0.0900\n",
      "Epoch 30/60\n",
      "7s - loss: 0.0318 - val_loss: 0.0973\n",
      "Epoch 31/60\n",
      "11s - loss: 0.0319 - val_loss: 0.0897\n",
      "Epoch 32/60\n",
      "8s - loss: 0.0316 - val_loss: 0.0965\n",
      "Epoch 33/60\n",
      "7s - loss: 0.0330 - val_loss: 0.0875\n",
      "Epoch 34/60\n",
      "10s - loss: 0.0326 - val_loss: 0.0884\n",
      "Epoch 35/60\n",
      "4368s - loss: 0.0318 - val_loss: 0.0937\n",
      "Epoch 36/60\n",
      "9s - loss: 0.0311 - val_loss: 0.0922\n",
      "Epoch 37/60\n",
      "9s - loss: 0.0321 - val_loss: 0.0911\n",
      "Epoch 38/60\n",
      "9s - loss: 0.0314 - val_loss: 0.0904\n",
      "Epoch 39/60\n",
      "11s - loss: 0.0322 - val_loss: 0.0853\n",
      "Epoch 40/60\n",
      "11s - loss: 0.0319 - val_loss: 0.0882\n",
      "Epoch 41/60\n",
      "11s - loss: 0.0313 - val_loss: 0.0914\n",
      "Epoch 42/60\n",
      "7s - loss: 0.0312 - val_loss: 0.0889\n",
      "Epoch 43/60\n",
      "7s - loss: 0.0308 - val_loss: 0.0856\n",
      "Epoch 44/60\n",
      "7s - loss: 0.0308 - val_loss: 0.0869\n",
      "Epoch 45/60\n",
      "7s - loss: 0.0315 - val_loss: 0.0927\n",
      "Epoch 46/60\n",
      "7s - loss: 0.0310 - val_loss: 0.0900\n",
      "Epoch 47/60\n",
      "7s - loss: 0.0312 - val_loss: 0.0917\n",
      "Epoch 48/60\n",
      "7s - loss: 0.0322 - val_loss: 0.0889\n",
      "Epoch 49/60\n",
      "7s - loss: 0.0302 - val_loss: 0.0932\n",
      "Epoch 50/60\n",
      "7s - loss: 0.0309 - val_loss: 0.0875\n",
      "Epoch 51/60\n",
      "7s - loss: 0.0303 - val_loss: 0.0888\n",
      "Epoch 52/60\n",
      "7s - loss: 0.0314 - val_loss: 0.0893\n",
      "Epoch 53/60\n",
      "7s - loss: 0.0309 - val_loss: 0.0874\n",
      "Epoch 54/60\n",
      "7s - loss: 0.0309 - val_loss: 0.0890\n",
      "Epoch 55/60\n",
      "7s - loss: 0.0310 - val_loss: 0.0858\n",
      "Epoch 56/60\n",
      "7s - loss: 0.0306 - val_loss: 0.0876\n",
      "Epoch 57/60\n",
      "8s - loss: 0.0305 - val_loss: 0.0880\n",
      "Epoch 58/60\n",
      "9s - loss: 0.0303 - val_loss: 0.0847\n",
      "Epoch 59/60\n",
      "7s - loss: 0.0299 - val_loss: 0.0855\n",
      "Epoch 60/60\n",
      "7s - loss: 0.0298 - val_loss: 0.0928\n",
      "5) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "7s - loss: 0.0305 - val_loss: 0.0883\n",
      "Epoch 2/60\n",
      "7s - loss: 0.0299 - val_loss: 0.0873\n",
      "Epoch 3/60\n",
      "10s - loss: 0.0304 - val_loss: 0.0903\n",
      "Epoch 4/60\n",
      "7s - loss: 0.0303 - val_loss: 0.0906\n",
      "Epoch 5/60\n",
      "7s - loss: 0.0299 - val_loss: 0.0905\n",
      "Epoch 6/60\n",
      "7s - loss: 0.0305 - val_loss: 0.0855\n",
      "Epoch 7/60\n",
      "7s - loss: 0.0303 - val_loss: 0.0942\n",
      "Epoch 8/60\n",
      "6s - loss: 0.0295 - val_loss: 0.0993\n",
      "Epoch 9/60\n",
      "7s - loss: 0.0303 - val_loss: 0.0913\n",
      "Epoch 10/60\n",
      "7s - loss: 0.0298 - val_loss: 0.0910\n",
      "Epoch 11/60\n",
      "7s - loss: 0.0295 - val_loss: 0.0909\n",
      "Epoch 12/60\n",
      "7s - loss: 0.0285 - val_loss: 0.0926\n",
      "Epoch 13/60\n",
      "7s - loss: 0.0298 - val_loss: 0.0889\n",
      "Epoch 14/60\n",
      "7s - loss: 0.0290 - val_loss: 0.0977\n",
      "Epoch 15/60\n",
      "7s - loss: 0.0292 - val_loss: 0.0883\n",
      "Epoch 16/60\n",
      "7s - loss: 0.0298 - val_loss: 0.1007\n",
      "Epoch 17/60\n",
      "6s - loss: 0.0298 - val_loss: 0.0885\n",
      "Epoch 18/60\n",
      "7s - loss: 0.0293 - val_loss: 0.0851\n",
      "Epoch 19/60\n",
      "8s - loss: 0.0294 - val_loss: 0.0863\n",
      "Epoch 20/60\n",
      "8s - loss: 0.0288 - val_loss: 0.0957\n",
      "Epoch 21/60\n",
      "7s - loss: 0.0296 - val_loss: 0.0969\n",
      "Epoch 22/60\n",
      "7s - loss: 0.0294 - val_loss: 0.0969\n",
      "Epoch 23/60\n",
      "7s - loss: 0.0281 - val_loss: 0.0931\n",
      "Epoch 24/60\n",
      "7s - loss: 0.0281 - val_loss: 0.0940\n",
      "Epoch 25/60\n",
      "7s - loss: 0.0294 - val_loss: 0.0984\n",
      "Epoch 26/60\n",
      "7s - loss: 0.0286 - val_loss: 0.0917\n",
      "Epoch 27/60\n",
      "7s - loss: 0.0288 - val_loss: 0.0916\n",
      "Epoch 28/60\n",
      "7s - loss: 0.0285 - val_loss: 0.0964\n",
      "Epoch 29/60\n",
      "7s - loss: 0.0291 - val_loss: 0.0861\n",
      "Epoch 30/60\n",
      "7s - loss: 0.0292 - val_loss: 0.0887\n",
      "Epoch 31/60\n",
      "7s - loss: 0.0277 - val_loss: 0.0930\n",
      "Epoch 32/60\n",
      "7s - loss: 0.0285 - val_loss: 0.0903\n",
      "Epoch 33/60\n",
      "7s - loss: 0.0286 - val_loss: 0.0891\n",
      "Epoch 34/60\n",
      "7s - loss: 0.0274 - val_loss: 0.0928\n",
      "Epoch 35/60\n",
      "7s - loss: 0.0290 - val_loss: 0.0871\n",
      "Epoch 36/60\n",
      "7s - loss: 0.0287 - val_loss: 0.0931\n",
      "Epoch 37/60\n",
      "10s - loss: 0.0284 - val_loss: 0.0957\n",
      "Epoch 38/60\n",
      "9s - loss: 0.0280 - val_loss: 0.0910\n",
      "Epoch 39/60\n",
      "9s - loss: 0.0272 - val_loss: 0.0972\n",
      "Epoch 40/60\n",
      "7s - loss: 0.0280 - val_loss: 0.0912\n",
      "Epoch 41/60\n",
      "7s - loss: 0.0286 - val_loss: 0.1001\n",
      "Epoch 42/60\n",
      "7s - loss: 0.0288 - val_loss: 0.0908\n",
      "Epoch 43/60\n",
      "7s - loss: 0.0278 - val_loss: 0.0890\n",
      "Epoch 44/60\n",
      "7s - loss: 0.0275 - val_loss: 0.0976\n",
      "Epoch 45/60\n",
      "7s - loss: 0.0275 - val_loss: 0.0921\n",
      "Epoch 46/60\n",
      "7s - loss: 0.0280 - val_loss: 0.1006\n",
      "Epoch 47/60\n",
      "7s - loss: 0.0274 - val_loss: 0.0922\n",
      "Epoch 48/60\n",
      "7s - loss: 0.0274 - val_loss: 0.0983\n",
      "Epoch 49/60\n",
      "7s - loss: 0.0274 - val_loss: 0.0982\n",
      "Epoch 50/60\n",
      "7s - loss: 0.0284 - val_loss: 0.0922\n",
      "Epoch 51/60\n",
      "7s - loss: 0.0268 - val_loss: 0.0898\n",
      "Epoch 52/60\n",
      "7s - loss: 0.0276 - val_loss: 0.0872\n",
      "Epoch 53/60\n",
      "7s - loss: 0.0283 - val_loss: 0.0949\n",
      "Epoch 54/60\n",
      "7s - loss: 0.0278 - val_loss: 0.0925\n",
      "Epoch 55/60\n",
      "9s - loss: 0.0271 - val_loss: 0.0943\n",
      "Epoch 56/60\n",
      "4s - loss: 0.0270 - val_loss: 0.0930\n",
      "Epoch 57/60\n",
      "7s - loss: 0.0268 - val_loss: 0.0866\n",
      "Epoch 58/60\n",
      "7s - loss: 0.0270 - val_loss: 0.0944\n",
      "Epoch 59/60\n",
      "7s - loss: 0.0270 - val_loss: 0.0899\n",
      "Epoch 60/60\n",
      "7s - loss: 0.0275 - val_loss: 0.0939\n",
      "6) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "7s - loss: 0.0275 - val_loss: 0.0956\n",
      "Epoch 2/60\n",
      "7s - loss: 0.0264 - val_loss: 0.0982\n",
      "Epoch 3/60\n",
      "7s - loss: 0.0276 - val_loss: 0.1002\n",
      "Epoch 4/60\n",
      "7s - loss: 0.0268 - val_loss: 0.0993\n",
      "Epoch 5/60\n",
      "7s - loss: 0.0274 - val_loss: 0.0924\n",
      "Epoch 6/60\n",
      "7s - loss: 0.0262 - val_loss: 0.0952\n",
      "Epoch 7/60\n",
      "7s - loss: 0.0263 - val_loss: 0.0917\n",
      "Epoch 8/60\n",
      "7s - loss: 0.0265 - val_loss: 0.0958\n",
      "Epoch 9/60\n",
      "8s - loss: 0.0262 - val_loss: 0.0919\n",
      "Epoch 10/60\n",
      "10s - loss: 0.0261 - val_loss: 0.0999\n",
      "Epoch 11/60\n",
      "8s - loss: 0.0269 - val_loss: 0.0996\n",
      "Epoch 12/60\n",
      "7s - loss: 0.0261 - val_loss: 0.0965\n",
      "Epoch 13/60\n",
      "11s - loss: 0.0268 - val_loss: 0.1006\n",
      "Epoch 14/60\n",
      "7s - loss: 0.0259 - val_loss: 0.0993\n",
      "Epoch 15/60\n",
      "7s - loss: 0.0262 - val_loss: 0.0897\n",
      "Epoch 16/60\n",
      "7s - loss: 0.0267 - val_loss: 0.0932\n",
      "Epoch 17/60\n",
      "7s - loss: 0.0268 - val_loss: 0.0949\n",
      "Epoch 18/60\n",
      "7s - loss: 0.0262 - val_loss: 0.0902\n",
      "Epoch 19/60\n",
      "7s - loss: 0.0264 - val_loss: 0.0922\n",
      "Epoch 20/60\n",
      "7s - loss: 0.0268 - val_loss: 0.0919\n",
      "Epoch 21/60\n",
      "7s - loss: 0.0262 - val_loss: 0.0898\n",
      "Epoch 22/60\n",
      "7s - loss: 0.0260 - val_loss: 0.0912\n",
      "Epoch 23/60\n",
      "7s - loss: 0.0265 - val_loss: 0.0864\n",
      "Epoch 24/60\n",
      "7s - loss: 0.0264 - val_loss: 0.0933\n",
      "Epoch 25/60\n",
      "7s - loss: 0.0269 - val_loss: 0.0962\n",
      "Epoch 26/60\n",
      "7s - loss: 0.0255 - val_loss: 0.0933\n",
      "Epoch 27/60\n",
      "7s - loss: 0.0256 - val_loss: 0.0883\n",
      "Epoch 28/60\n",
      "7s - loss: 0.0264 - val_loss: 0.0962\n",
      "Epoch 29/60\n",
      "7s - loss: 0.0262 - val_loss: 0.0913\n",
      "Epoch 30/60\n",
      "7s - loss: 0.0259 - val_loss: 0.0917\n",
      "Epoch 31/60\n",
      "7s - loss: 0.0257 - val_loss: 0.1012\n",
      "Epoch 32/60\n",
      "7s - loss: 0.0260 - val_loss: 0.0936\n",
      "Epoch 33/60\n",
      "7s - loss: 0.0259 - val_loss: 0.0916\n",
      "Epoch 34/60\n",
      "7s - loss: 0.0260 - val_loss: 0.0942\n",
      "Epoch 35/60\n",
      "7s - loss: 0.0259 - val_loss: 0.0967\n",
      "Epoch 36/60\n",
      "7s - loss: 0.0264 - val_loss: 0.0919\n",
      "Epoch 37/60\n",
      "9s - loss: 0.0251 - val_loss: 0.0953\n",
      "Epoch 38/60\n",
      "7s - loss: 0.0259 - val_loss: 0.0912\n",
      "Epoch 39/60\n",
      "7s - loss: 0.0251 - val_loss: 0.0913\n",
      "Epoch 40/60\n",
      "7s - loss: 0.0253 - val_loss: 0.0917\n",
      "Epoch 41/60\n",
      "7s - loss: 0.0261 - val_loss: 0.0932\n",
      "Epoch 42/60\n",
      "7s - loss: 0.0259 - val_loss: 0.0950\n",
      "Epoch 43/60\n",
      "7s - loss: 0.0255 - val_loss: 0.0973\n",
      "Epoch 44/60\n",
      "7s - loss: 0.0255 - val_loss: 0.0921\n",
      "Epoch 45/60\n",
      "7s - loss: 0.0257 - val_loss: 0.0926\n",
      "Epoch 46/60\n",
      "7s - loss: 0.0254 - val_loss: 0.0884\n",
      "Epoch 47/60\n",
      "7s - loss: 0.0250 - val_loss: 0.0908\n",
      "Epoch 48/60\n",
      "7s - loss: 0.0244 - val_loss: 0.0936\n",
      "Epoch 49/60\n",
      "7s - loss: 0.0248 - val_loss: 0.0910\n",
      "Epoch 50/60\n",
      "7s - loss: 0.0250 - val_loss: 0.0949\n",
      "Epoch 51/60\n",
      "7s - loss: 0.0256 - val_loss: 0.0969\n",
      "Epoch 52/60\n",
      "7s - loss: 0.0249 - val_loss: 0.0975\n",
      "Epoch 53/60\n",
      "8s - loss: 0.0244 - val_loss: 0.0909\n",
      "Epoch 54/60\n",
      "8s - loss: 0.0245 - val_loss: 0.0954\n",
      "Epoch 55/60\n",
      "7s - loss: 0.0244 - val_loss: 0.0881\n",
      "Epoch 56/60\n",
      "6s - loss: 0.0253 - val_loss: 0.0907\n",
      "Epoch 57/60\n",
      "6s - loss: 0.0244 - val_loss: 0.0905\n",
      "Epoch 58/60\n",
      "6s - loss: 0.0248 - val_loss: 0.0897\n",
      "Epoch 59/60\n",
      "6s - loss: 0.0243 - val_loss: 0.0888\n",
      "Epoch 60/60\n",
      "7s - loss: 0.0244 - val_loss: 0.0869\n",
      "7) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "6s - loss: 0.0252 - val_loss: 0.0900\n",
      "Epoch 2/60\n",
      "7s - loss: 0.0246 - val_loss: 0.0971\n",
      "Epoch 3/60\n",
      "7s - loss: 0.0238 - val_loss: 0.0929\n",
      "Epoch 4/60\n",
      "7s - loss: 0.0250 - val_loss: 0.1020\n",
      "Epoch 5/60\n",
      "7s - loss: 0.0243 - val_loss: 0.0936\n",
      "Epoch 6/60\n",
      "7s - loss: 0.0248 - val_loss: 0.0930\n",
      "Epoch 7/60\n",
      "7s - loss: 0.0242 - val_loss: 0.1007\n",
      "Epoch 8/60\n",
      "6s - loss: 0.0250 - val_loss: 0.0969\n",
      "Epoch 9/60\n",
      "7s - loss: 0.0241 - val_loss: 0.0893\n",
      "Epoch 10/60\n",
      "6s - loss: 0.0249 - val_loss: 0.0933\n",
      "Epoch 11/60\n",
      "7s - loss: 0.0240 - val_loss: 0.0944\n",
      "Epoch 12/60\n",
      "7s - loss: 0.0248 - val_loss: 0.0911\n",
      "Epoch 13/60\n",
      "7s - loss: 0.0246 - val_loss: 0.0933\n",
      "Epoch 14/60\n",
      "7s - loss: 0.0244 - val_loss: 0.0983\n",
      "Epoch 15/60\n",
      "7s - loss: 0.0241 - val_loss: 0.0949\n",
      "Epoch 16/60\n",
      "9s - loss: 0.0247 - val_loss: 0.0971\n",
      "Epoch 17/60\n",
      "8s - loss: 0.0244 - val_loss: 0.0945\n",
      "Epoch 18/60\n",
      "6s - loss: 0.0239 - val_loss: 0.0971\n",
      "Epoch 19/60\n",
      "6s - loss: 0.0235 - val_loss: 0.0932\n",
      "Epoch 20/60\n",
      "6s - loss: 0.0235 - val_loss: 0.0995\n",
      "Epoch 21/60\n",
      "6s - loss: 0.0229 - val_loss: 0.0989\n",
      "Epoch 22/60\n",
      "6s - loss: 0.0234 - val_loss: 0.0895\n",
      "Epoch 23/60\n",
      "6s - loss: 0.0240 - val_loss: 0.0931\n",
      "Epoch 24/60\n",
      "6s - loss: 0.0245 - val_loss: 0.0948\n",
      "Epoch 25/60\n",
      "6s - loss: 0.0236 - val_loss: 0.0912\n",
      "Epoch 26/60\n",
      "6s - loss: 0.0242 - val_loss: 0.0914\n",
      "Epoch 27/60\n",
      "7s - loss: 0.0231 - val_loss: 0.0914\n",
      "Epoch 28/60\n",
      "6s - loss: 0.0250 - val_loss: 0.0878\n",
      "Epoch 29/60\n",
      "7s - loss: 0.0228 - val_loss: 0.0910\n",
      "Epoch 30/60\n",
      "7s - loss: 0.0232 - val_loss: 0.0875\n",
      "Epoch 31/60\n",
      "6s - loss: 0.0241 - val_loss: 0.0882\n",
      "Epoch 32/60\n",
      "7s - loss: 0.0230 - val_loss: 0.0925\n",
      "Epoch 33/60\n",
      "7s - loss: 0.0236 - val_loss: 0.0902\n",
      "Epoch 34/60\n",
      "6s - loss: 0.0232 - val_loss: 0.0900\n",
      "Epoch 35/60\n",
      "7s - loss: 0.0239 - val_loss: 0.0937\n",
      "Epoch 36/60\n",
      "6s - loss: 0.0236 - val_loss: 0.0900\n",
      "Epoch 37/60\n",
      "7s - loss: 0.0237 - val_loss: 0.0906\n",
      "Epoch 38/60\n",
      "6s - loss: 0.0224 - val_loss: 0.0969\n",
      "Epoch 39/60\n",
      "6s - loss: 0.0231 - val_loss: 0.0984\n",
      "Epoch 40/60\n",
      "7s - loss: 0.0236 - val_loss: 0.0970\n",
      "Epoch 41/60\n",
      "7s - loss: 0.0229 - val_loss: 0.0909\n",
      "Epoch 42/60\n",
      "7s - loss: 0.0232 - val_loss: 0.0874\n",
      "Epoch 43/60\n",
      "6s - loss: 0.0233 - val_loss: 0.0902\n",
      "Epoch 44/60\n",
      "6s - loss: 0.0239 - val_loss: 0.0915\n",
      "Epoch 45/60\n",
      "7s - loss: 0.0232 - val_loss: 0.0910\n",
      "Epoch 46/60\n",
      "7s - loss: 0.0225 - val_loss: 0.0877\n",
      "Epoch 47/60\n",
      "7s - loss: 0.0230 - val_loss: 0.0937\n",
      "Epoch 48/60\n",
      "6s - loss: 0.0229 - val_loss: 0.0911\n",
      "Epoch 49/60\n",
      "6s - loss: 0.0229 - val_loss: 0.0933\n",
      "Epoch 50/60\n",
      "6s - loss: 0.0229 - val_loss: 0.0936\n",
      "Epoch 51/60\n",
      "6s - loss: 0.0232 - val_loss: 0.0946\n",
      "Epoch 52/60\n",
      "7s - loss: 0.0236 - val_loss: 0.0913\n",
      "Epoch 53/60\n",
      "6s - loss: 0.0221 - val_loss: 0.0913\n",
      "Epoch 54/60\n",
      "6s - loss: 0.0227 - val_loss: 0.1052\n",
      "Epoch 55/60\n",
      "7s - loss: 0.0227 - val_loss: 0.0963\n",
      "Epoch 56/60\n",
      "7s - loss: 0.0228 - val_loss: 0.0911\n",
      "Epoch 57/60\n",
      "6s - loss: 0.0229 - val_loss: 0.0967\n",
      "Epoch 58/60\n",
      "6s - loss: 0.0222 - val_loss: 0.0916\n",
      "Epoch 59/60\n",
      "7s - loss: 0.0226 - val_loss: 0.0918\n",
      "Epoch 60/60\n",
      "6s - loss: 0.0227 - val_loss: 0.0943\n",
      "8) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "7s - loss: 0.0222 - val_loss: 0.0966\n",
      "Epoch 2/60\n",
      "7s - loss: 0.0221 - val_loss: 0.0981\n",
      "Epoch 3/60\n",
      "6s - loss: 0.0220 - val_loss: 0.0943\n",
      "Epoch 4/60\n",
      "6s - loss: 0.0234 - val_loss: 0.0928\n",
      "Epoch 5/60\n",
      "6s - loss: 0.0225 - val_loss: 0.0953\n",
      "Epoch 6/60\n",
      "6s - loss: 0.0221 - val_loss: 0.0946\n",
      "Epoch 7/60\n",
      "6s - loss: 0.0218 - val_loss: 0.0941\n",
      "Epoch 8/60\n",
      "7s - loss: 0.0223 - val_loss: 0.0976\n",
      "Epoch 9/60\n",
      "6s - loss: 0.0236 - val_loss: 0.0927\n",
      "Epoch 10/60\n",
      "6s - loss: 0.0215 - val_loss: 0.0906\n",
      "Epoch 11/60\n",
      "6s - loss: 0.0227 - val_loss: 0.0944\n",
      "Epoch 12/60\n",
      "6s - loss: 0.0226 - val_loss: 0.0899\n",
      "Epoch 13/60\n",
      "6s - loss: 0.0220 - val_loss: 0.0900\n",
      "Epoch 14/60\n",
      "7s - loss: 0.0224 - val_loss: 0.0902\n",
      "Epoch 15/60\n",
      "6s - loss: 0.0226 - val_loss: 0.0869\n",
      "Epoch 16/60\n",
      "7s - loss: 0.0218 - val_loss: 0.0907\n",
      "Epoch 17/60\n",
      "7s - loss: 0.0221 - val_loss: 0.0881\n",
      "Epoch 18/60\n",
      "6s - loss: 0.0221 - val_loss: 0.0935\n",
      "Epoch 19/60\n",
      "7s - loss: 0.0216 - val_loss: 0.0880\n",
      "Epoch 20/60\n",
      "6s - loss: 0.0218 - val_loss: 0.0965\n",
      "Epoch 21/60\n",
      "6s - loss: 0.0227 - val_loss: 0.0927\n",
      "Epoch 22/60\n",
      "7s - loss: 0.0220 - val_loss: 0.0922\n",
      "Epoch 23/60\n",
      "6s - loss: 0.0224 - val_loss: 0.0902\n",
      "Epoch 24/60\n",
      "7s - loss: 0.0219 - val_loss: 0.0929\n",
      "Epoch 25/60\n",
      "7s - loss: 0.0217 - val_loss: 0.0923\n",
      "Epoch 26/60\n",
      "7s - loss: 0.0218 - val_loss: 0.0959\n",
      "Epoch 27/60\n",
      "6s - loss: 0.0214 - val_loss: 0.0936\n",
      "Epoch 28/60\n",
      "6s - loss: 0.0217 - val_loss: 0.0898\n",
      "Epoch 29/60\n",
      "6s - loss: 0.0217 - val_loss: 0.0873\n",
      "Epoch 30/60\n",
      "6s - loss: 0.0217 - val_loss: 0.0948\n",
      "Epoch 31/60\n",
      "6s - loss: 0.0224 - val_loss: 0.0892\n",
      "Epoch 32/60\n",
      "7s - loss: 0.0211 - val_loss: 0.0882\n",
      "Epoch 33/60\n",
      "6s - loss: 0.0224 - val_loss: 0.0875\n",
      "Epoch 34/60\n",
      "7s - loss: 0.0221 - val_loss: 0.0848\n",
      "Epoch 35/60\n",
      "6s - loss: 0.0211 - val_loss: 0.0873\n",
      "Epoch 36/60\n",
      "7s - loss: 0.0213 - val_loss: 0.0866\n",
      "Epoch 37/60\n",
      "6s - loss: 0.0211 - val_loss: 0.0892\n",
      "Epoch 38/60\n",
      "6s - loss: 0.0218 - val_loss: 0.0864\n",
      "Epoch 39/60\n",
      "6s - loss: 0.0211 - val_loss: 0.0884\n",
      "Epoch 40/60\n",
      "7s - loss: 0.0211 - val_loss: 0.0893\n",
      "Epoch 41/60\n",
      "6s - loss: 0.0219 - val_loss: 0.0918\n",
      "Epoch 42/60\n",
      "6s - loss: 0.0216 - val_loss: 0.0901\n",
      "Epoch 43/60\n",
      "6s - loss: 0.0212 - val_loss: 0.0879\n",
      "Epoch 44/60\n",
      "6s - loss: 0.0210 - val_loss: 0.0930\n",
      "Epoch 45/60\n",
      "6s - loss: 0.0210 - val_loss: 0.0862\n",
      "Epoch 46/60\n",
      "7s - loss: 0.0215 - val_loss: 0.0924\n",
      "Epoch 47/60\n",
      "8s - loss: 0.0216 - val_loss: 0.0916\n",
      "Epoch 48/60\n",
      "9s - loss: 0.0211 - val_loss: 0.0920\n",
      "Epoch 49/60\n",
      "12s - loss: 0.0212 - val_loss: 0.0913\n",
      "Epoch 50/60\n",
      "7s - loss: 0.0211 - val_loss: 0.0895\n",
      "Epoch 51/60\n",
      "7s - loss: 0.0212 - val_loss: 0.0900\n",
      "Epoch 52/60\n",
      "7s - loss: 0.0211 - val_loss: 0.0902\n",
      "Epoch 53/60\n",
      "6s - loss: 0.0212 - val_loss: 0.0874\n",
      "Epoch 54/60\n",
      "6s - loss: 0.0210 - val_loss: 0.0890\n",
      "Epoch 55/60\n",
      "6s - loss: 0.0211 - val_loss: 0.0874\n",
      "Epoch 56/60\n",
      "6s - loss: 0.0215 - val_loss: 0.0878\n",
      "Epoch 57/60\n",
      "6s - loss: 0.0215 - val_loss: 0.0892\n",
      "Epoch 58/60\n",
      "7s - loss: 0.0210 - val_loss: 0.0919\n",
      "Epoch 59/60\n",
      "6s - loss: 0.0213 - val_loss: 0.0923\n",
      "Epoch 60/60\n",
      "6s - loss: 0.0207 - val_loss: 0.0902\n",
      "9) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "7s - loss: 0.0211 - val_loss: 0.0992\n",
      "Epoch 2/60\n",
      "6s - loss: 0.0212 - val_loss: 0.0915\n",
      "Epoch 3/60\n",
      "6s - loss: 0.0210 - val_loss: 0.0942\n",
      "Epoch 4/60\n",
      "6s - loss: 0.0205 - val_loss: 0.0914\n",
      "Epoch 5/60\n",
      "6s - loss: 0.0214 - val_loss: 0.0872\n",
      "Epoch 6/60\n",
      "6s - loss: 0.0217 - val_loss: 0.0927\n",
      "Epoch 7/60\n",
      "7s - loss: 0.0204 - val_loss: 0.0926\n",
      "Epoch 8/60\n",
      "7s - loss: 0.0202 - val_loss: 0.0949\n",
      "Epoch 9/60\n",
      "8s - loss: 0.0207 - val_loss: 0.0938\n",
      "Epoch 10/60\n",
      "8s - loss: 0.0203 - val_loss: 0.0904\n",
      "Epoch 11/60\n",
      "7s - loss: 0.0210 - val_loss: 0.0899\n",
      "Epoch 12/60\n",
      "7s - loss: 0.0205 - val_loss: 0.0919\n",
      "Epoch 13/60\n",
      "6s - loss: 0.0211 - val_loss: 0.0902\n",
      "Epoch 14/60\n",
      "7s - loss: 0.0205 - val_loss: 0.0880\n",
      "Epoch 15/60\n",
      "6s - loss: 0.0196 - val_loss: 0.0926\n",
      "Epoch 16/60\n",
      "6s - loss: 0.0212 - val_loss: 0.0904\n",
      "Epoch 17/60\n",
      "7s - loss: 0.0208 - val_loss: 0.0883\n",
      "Epoch 18/60\n",
      "6s - loss: 0.0208 - val_loss: 0.0944\n",
      "Epoch 19/60\n",
      "6s - loss: 0.0203 - val_loss: 0.0898\n",
      "Epoch 20/60\n",
      "7s - loss: 0.0196 - val_loss: 0.0872\n",
      "Epoch 21/60\n",
      "7s - loss: 0.0209 - val_loss: 0.0870\n",
      "Epoch 22/60\n",
      "6s - loss: 0.0207 - val_loss: 0.0885\n",
      "Epoch 23/60\n",
      "6s - loss: 0.0206 - val_loss: 0.0910\n",
      "Epoch 24/60\n",
      "6s - loss: 0.0201 - val_loss: 0.0901\n",
      "Epoch 25/60\n",
      "6s - loss: 0.0202 - val_loss: 0.0854\n",
      "Epoch 26/60\n",
      "7s - loss: 0.0203 - val_loss: 0.0869\n",
      "Epoch 27/60\n",
      "8s - loss: 0.0206 - val_loss: 0.0939\n",
      "Epoch 28/60\n",
      "9s - loss: 0.0208 - val_loss: 0.0901\n",
      "Epoch 29/60\n",
      "10s - loss: 0.0204 - val_loss: 0.0877\n",
      "Epoch 30/60\n",
      "9s - loss: 0.0207 - val_loss: 0.0879\n",
      "Epoch 31/60\n",
      "12s - loss: 0.0205 - val_loss: 0.0911\n",
      "Epoch 32/60\n",
      "7s - loss: 0.0206 - val_loss: 0.0910\n",
      "Epoch 33/60\n",
      "6s - loss: 0.0202 - val_loss: 0.0883\n",
      "Epoch 34/60\n",
      "6s - loss: 0.0199 - val_loss: 0.0936\n",
      "Epoch 35/60\n",
      "6s - loss: 0.0197 - val_loss: 0.0894\n",
      "Epoch 36/60\n",
      "6s - loss: 0.0203 - val_loss: 0.0895\n",
      "Epoch 37/60\n",
      "6s - loss: 0.0206 - val_loss: 0.0918\n",
      "Epoch 38/60\n",
      "6s - loss: 0.0203 - val_loss: 0.0898\n",
      "Epoch 39/60\n",
      "6s - loss: 0.0202 - val_loss: 0.0865\n",
      "Epoch 40/60\n",
      "7s - loss: 0.0200 - val_loss: 0.0881\n",
      "Epoch 41/60\n",
      "6s - loss: 0.0202 - val_loss: 0.0908\n",
      "Epoch 42/60\n",
      "6s - loss: 0.0200 - val_loss: 0.0930\n",
      "Epoch 43/60\n",
      "6s - loss: 0.0207 - val_loss: 0.0873\n",
      "Epoch 44/60\n",
      "6s - loss: 0.0198 - val_loss: 0.0897\n",
      "Epoch 45/60\n",
      "6s - loss: 0.0199 - val_loss: 0.0887\n",
      "Epoch 46/60\n",
      "7s - loss: 0.0204 - val_loss: 0.0855\n",
      "Epoch 47/60\n",
      "6s - loss: 0.0199 - val_loss: 0.0870\n",
      "Epoch 48/60\n",
      "7s - loss: 0.0200 - val_loss: 0.0903\n",
      "Epoch 49/60\n",
      "6s - loss: 0.0199 - val_loss: 0.0918\n",
      "Epoch 50/60\n",
      "6s - loss: 0.0193 - val_loss: 0.0876\n",
      "Epoch 51/60\n",
      "6s - loss: 0.0200 - val_loss: 0.0915\n",
      "Epoch 52/60\n",
      "6s - loss: 0.0197 - val_loss: 0.0916\n",
      "Epoch 53/60\n",
      "6s - loss: 0.0195 - val_loss: 0.0913\n",
      "Epoch 54/60\n",
      "6s - loss: 0.0198 - val_loss: 0.0866\n",
      "Epoch 55/60\n",
      "6s - loss: 0.0190 - val_loss: 0.0906\n",
      "Epoch 56/60\n",
      "6s - loss: 0.0200 - val_loss: 0.0896\n",
      "Epoch 57/60\n",
      "6s - loss: 0.0200 - val_loss: 0.0913\n",
      "Epoch 58/60\n",
      "6s - loss: 0.0192 - val_loss: 0.0899\n",
      "Epoch 59/60\n",
      "6s - loss: 0.0202 - val_loss: 0.0887\n",
      "Epoch 60/60\n",
      "6s - loss: 0.0193 - val_loss: 0.0915\n",
      "10) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "6s - loss: 0.0196 - val_loss: 0.0937\n",
      "Epoch 2/60\n",
      "6s - loss: 0.0190 - val_loss: 0.0897\n",
      "Epoch 3/60\n",
      "6s - loss: 0.0193 - val_loss: 0.0910\n",
      "Epoch 4/60\n",
      "6s - loss: 0.0196 - val_loss: 0.0916\n",
      "Epoch 5/60\n",
      "6s - loss: 0.0196 - val_loss: 0.0853\n",
      "Epoch 6/60\n",
      "6s - loss: 0.0195 - val_loss: 0.0901\n",
      "Epoch 7/60\n",
      "6s - loss: 0.0197 - val_loss: 0.0918\n",
      "Epoch 8/60\n",
      "7s - loss: 0.0196 - val_loss: 0.0932\n",
      "Epoch 9/60\n",
      "6s - loss: 0.0194 - val_loss: 0.0919\n",
      "Epoch 10/60\n",
      "6s - loss: 0.0189 - val_loss: 0.0928\n",
      "Epoch 11/60\n",
      "6s - loss: 0.0196 - val_loss: 0.0902\n",
      "Epoch 12/60\n",
      "6s - loss: 0.0192 - val_loss: 0.0892\n",
      "Epoch 13/60\n",
      "9s - loss: 0.0196 - val_loss: 0.0948\n",
      "Epoch 14/60\n",
      "6s - loss: 0.0188 - val_loss: 0.0922\n",
      "Epoch 15/60\n",
      "7s - loss: 0.0197 - val_loss: 0.0993\n",
      "Epoch 16/60\n",
      "9s - loss: 0.0194 - val_loss: 0.0947\n",
      "Epoch 17/60\n",
      "6s - loss: 0.0193 - val_loss: 0.0921\n",
      "Epoch 18/60\n",
      "6s - loss: 0.0188 - val_loss: 0.0914\n",
      "Epoch 19/60\n",
      "6s - loss: 0.0191 - val_loss: 0.0915\n",
      "Epoch 20/60\n",
      "6s - loss: 0.0186 - val_loss: 0.0927\n",
      "Epoch 21/60\n",
      "7s - loss: 0.0191 - val_loss: 0.0880\n",
      "Epoch 22/60\n",
      "7s - loss: 0.0193 - val_loss: 0.0899\n",
      "Epoch 23/60\n",
      "7s - loss: 0.0188 - val_loss: 0.0903\n",
      "Epoch 24/60\n",
      "6s - loss: 0.0190 - val_loss: 0.0921\n",
      "Epoch 25/60\n",
      "6s - loss: 0.0193 - val_loss: 0.0919\n",
      "Epoch 26/60\n",
      "6s - loss: 0.0190 - val_loss: 0.0937\n",
      "Epoch 27/60\n",
      "7s - loss: 0.0194 - val_loss: 0.0879\n",
      "Epoch 28/60\n",
      "7s - loss: 0.0188 - val_loss: 0.0889\n",
      "Epoch 29/60\n",
      "9s - loss: 0.0190 - val_loss: 0.0913\n",
      "Epoch 30/60\n",
      "4s - loss: 0.0189 - val_loss: 0.0939\n",
      "Epoch 31/60\n",
      "7s - loss: 0.0194 - val_loss: 0.0941\n",
      "Epoch 32/60\n",
      "6s - loss: 0.0191 - val_loss: 0.0916\n",
      "Epoch 33/60\n",
      "7s - loss: 0.0197 - val_loss: 0.0915\n",
      "Epoch 34/60\n",
      "7s - loss: 0.0186 - val_loss: 0.0882\n",
      "Epoch 35/60\n",
      "7s - loss: 0.0191 - val_loss: 0.0908\n",
      "Epoch 36/60\n",
      "7s - loss: 0.0188 - val_loss: 0.0924\n",
      "Epoch 37/60\n",
      "6s - loss: 0.0187 - val_loss: 0.0914\n",
      "Epoch 38/60\n",
      "6s - loss: 0.0197 - val_loss: 0.0927\n",
      "Epoch 39/60\n",
      "7s - loss: 0.0192 - val_loss: 0.0894\n",
      "Epoch 40/60\n",
      "7s - loss: 0.0189 - val_loss: 0.0965\n",
      "Epoch 41/60\n",
      "6s - loss: 0.0184 - val_loss: 0.0943\n",
      "Epoch 42/60\n",
      "7s - loss: 0.0194 - val_loss: 0.0924\n",
      "Epoch 43/60\n",
      "6s - loss: 0.0183 - val_loss: 0.0923\n",
      "Epoch 44/60\n",
      "6s - loss: 0.0190 - val_loss: 0.0935\n",
      "Epoch 45/60\n",
      "7s - loss: 0.0186 - val_loss: 0.0915\n",
      "Epoch 46/60\n",
      "9s - loss: 0.0186 - val_loss: 0.0915\n",
      "Epoch 47/60\n",
      "4s - loss: 0.0186 - val_loss: 0.0925\n",
      "Epoch 48/60\n",
      "7s - loss: 0.0187 - val_loss: 0.0915\n",
      "Epoch 49/60\n",
      "6s - loss: 0.0183 - val_loss: 0.0917\n",
      "Epoch 50/60\n",
      "6s - loss: 0.0186 - val_loss: 0.0935\n",
      "Epoch 51/60\n",
      "6s - loss: 0.0189 - val_loss: 0.0927\n",
      "Epoch 52/60\n",
      "6s - loss: 0.0188 - val_loss: 0.0940\n",
      "Epoch 53/60\n",
      "6s - loss: 0.0180 - val_loss: 0.0922\n",
      "Epoch 54/60\n",
      "6s - loss: 0.0182 - val_loss: 0.0872\n",
      "Epoch 55/60\n",
      "6s - loss: 0.0186 - val_loss: 0.0920\n",
      "Epoch 56/60\n",
      "7s - loss: 0.0182 - val_loss: 0.0908\n",
      "Epoch 57/60\n",
      "7s - loss: 0.0187 - val_loss: 0.0922\n",
      "Epoch 58/60\n",
      "6s - loss: 0.0187 - val_loss: 0.0946\n",
      "Epoch 59/60\n",
      "6s - loss: 0.0189 - val_loss: 0.0911\n",
      "Epoch 60/60\n",
      "6s - loss: 0.0180 - val_loss: 0.0901\n",
      "11) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "6s - loss: 0.0185 - val_loss: 0.0881\n",
      "Epoch 2/60\n",
      "6s - loss: 0.0181 - val_loss: 0.0911\n",
      "Epoch 3/60\n",
      "6s - loss: 0.0182 - val_loss: 0.0915\n",
      "Epoch 4/60\n",
      "6s - loss: 0.0182 - val_loss: 0.0893\n",
      "Epoch 5/60\n",
      "6s - loss: 0.0182 - val_loss: 0.0917\n",
      "Epoch 6/60\n",
      "6s - loss: 0.0183 - val_loss: 0.0929\n",
      "Epoch 7/60\n",
      "6s - loss: 0.0182 - val_loss: 0.0967\n",
      "Epoch 8/60\n",
      "6s - loss: 0.0184 - val_loss: 0.0892\n",
      "Epoch 9/60\n",
      "7s - loss: 0.0182 - val_loss: 0.0927\n",
      "Epoch 10/60\n",
      "6s - loss: 0.0185 - val_loss: 0.0908\n",
      "Epoch 11/60\n",
      "6s - loss: 0.0185 - val_loss: 0.0957\n",
      "Epoch 12/60\n",
      "6s - loss: 0.0182 - val_loss: 0.0890\n",
      "Epoch 13/60\n",
      "6s - loss: 0.0179 - val_loss: 0.0903\n",
      "Epoch 14/60\n",
      "6s - loss: 0.0175 - val_loss: 0.0948\n",
      "Epoch 15/60\n",
      "7s - loss: 0.0182 - val_loss: 0.0934\n",
      "Epoch 16/60\n",
      "6s - loss: 0.0180 - val_loss: 0.0927\n",
      "Epoch 17/60\n",
      "6s - loss: 0.0183 - val_loss: 0.0924\n",
      "Epoch 18/60\n",
      "7s - loss: 0.0180 - val_loss: 0.0907\n",
      "Epoch 19/60\n",
      "6s - loss: 0.0184 - val_loss: 0.0899\n",
      "Epoch 20/60\n",
      "6s - loss: 0.0180 - val_loss: 0.0895\n",
      "Epoch 21/60\n",
      "6s - loss: 0.0178 - val_loss: 0.0901\n",
      "Epoch 22/60\n",
      "6s - loss: 0.0181 - val_loss: 0.0910\n",
      "Epoch 23/60\n",
      "6s - loss: 0.0178 - val_loss: 0.0908\n",
      "Epoch 24/60\n",
      "6s - loss: 0.0181 - val_loss: 0.0873\n",
      "Epoch 25/60\n",
      "6s - loss: 0.0173 - val_loss: 0.0911\n",
      "Epoch 26/60\n",
      "7s - loss: 0.0176 - val_loss: 0.0929\n",
      "Epoch 27/60\n",
      "7s - loss: 0.0181 - val_loss: 0.0935\n",
      "Epoch 28/60\n",
      "6s - loss: 0.0182 - val_loss: 0.0964\n",
      "Epoch 29/60\n",
      "6s - loss: 0.0175 - val_loss: 0.0904\n",
      "Epoch 30/60\n",
      "6s - loss: 0.0180 - val_loss: 0.0920\n",
      "Epoch 31/60\n",
      "6s - loss: 0.0182 - val_loss: 0.0873\n",
      "Epoch 32/60\n",
      "6s - loss: 0.0183 - val_loss: 0.0945\n",
      "Epoch 33/60\n",
      "6s - loss: 0.0176 - val_loss: 0.0935\n",
      "Epoch 34/60\n",
      "6s - loss: 0.0176 - val_loss: 0.0941\n",
      "Epoch 35/60\n",
      "6s - loss: 0.0184 - val_loss: 0.0920\n",
      "Epoch 36/60\n",
      "6s - loss: 0.0173 - val_loss: 0.0923\n",
      "Epoch 37/60\n",
      "6s - loss: 0.0174 - val_loss: 0.0878\n",
      "Epoch 38/60\n",
      "6s - loss: 0.0182 - val_loss: 0.0915\n",
      "Epoch 39/60\n",
      "9s - loss: 0.0186 - val_loss: 0.0916\n",
      "Epoch 40/60\n",
      "2s - loss: 0.0177 - val_loss: 0.0946\n",
      "Epoch 41/60\n",
      "6s - loss: 0.0179 - val_loss: 0.0931\n",
      "Epoch 42/60\n",
      "6s - loss: 0.0182 - val_loss: 0.0899\n",
      "Epoch 43/60\n",
      "6s - loss: 0.0176 - val_loss: 0.0920\n",
      "Epoch 44/60\n",
      "6s - loss: 0.0178 - val_loss: 0.0915\n",
      "Epoch 45/60\n",
      "8s - loss: 0.0177 - val_loss: 0.0863\n",
      "Epoch 46/60\n",
      "6s - loss: 0.0186 - val_loss: 0.0864\n",
      "Epoch 47/60\n",
      "6s - loss: 0.0178 - val_loss: 0.0937\n",
      "Epoch 48/60\n",
      "6s - loss: 0.0176 - val_loss: 0.0913\n",
      "Epoch 49/60\n",
      "7s - loss: 0.0175 - val_loss: 0.0947\n",
      "Epoch 50/60\n",
      "6s - loss: 0.0177 - val_loss: 0.0906\n",
      "Epoch 51/60\n",
      "6s - loss: 0.0179 - val_loss: 0.0900\n",
      "Epoch 52/60\n",
      "6s - loss: 0.0178 - val_loss: 0.0908\n",
      "Epoch 53/60\n",
      "6s - loss: 0.0173 - val_loss: 0.0924\n",
      "Epoch 54/60\n",
      "6s - loss: 0.0180 - val_loss: 0.0905\n",
      "Epoch 55/60\n",
      "6s - loss: 0.0175 - val_loss: 0.0951\n",
      "Epoch 56/60\n",
      "7s - loss: 0.0175 - val_loss: 0.0897\n",
      "Epoch 57/60\n",
      "8s - loss: 0.0175 - val_loss: 0.0897\n",
      "Epoch 58/60\n",
      "7s - loss: 0.0180 - val_loss: 0.0946\n",
      "Epoch 59/60\n",
      "6s - loss: 0.0167 - val_loss: 0.0934\n",
      "Epoch 60/60\n",
      "6s - loss: 0.0177 - val_loss: 0.0903\n",
      "12) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "4s - loss: 0.0173 - val_loss: 0.0925\n",
      "Epoch 2/60\n",
      "7s - loss: 0.0173 - val_loss: 0.0900\n",
      "Epoch 3/60\n",
      "6s - loss: 0.0172 - val_loss: 0.0924\n",
      "Epoch 4/60\n",
      "6s - loss: 0.0178 - val_loss: 0.0918\n",
      "Epoch 5/60\n",
      "6s - loss: 0.0179 - val_loss: 0.0964\n",
      "Epoch 6/60\n",
      "6s - loss: 0.0175 - val_loss: 0.0943\n",
      "Epoch 7/60\n",
      "7s - loss: 0.0176 - val_loss: 0.0910\n",
      "Epoch 8/60\n",
      "6s - loss: 0.0173 - val_loss: 0.0931\n",
      "Epoch 9/60\n",
      "6s - loss: 0.0172 - val_loss: 0.0935\n",
      "Epoch 10/60\n",
      "6s - loss: 0.0179 - val_loss: 0.0892\n",
      "Epoch 11/60\n",
      "6s - loss: 0.0172 - val_loss: 0.0942\n",
      "Epoch 12/60\n",
      "6s - loss: 0.0169 - val_loss: 0.0921\n",
      "Epoch 13/60\n",
      "6s - loss: 0.0177 - val_loss: 0.0937\n",
      "Epoch 14/60\n",
      "6s - loss: 0.0179 - val_loss: 0.0919\n",
      "Epoch 15/60\n",
      "6s - loss: 0.0170 - val_loss: 0.0899\n",
      "Epoch 16/60\n",
      "6s - loss: 0.0172 - val_loss: 0.0985\n",
      "Epoch 17/60\n",
      "6s - loss: 0.0169 - val_loss: 0.0884\n",
      "Epoch 18/60\n",
      "6s - loss: 0.0176 - val_loss: 0.0926\n",
      "Epoch 19/60\n",
      "6s - loss: 0.0168 - val_loss: 0.0965\n",
      "Epoch 20/60\n",
      "6s - loss: 0.0174 - val_loss: 0.0888\n",
      "Epoch 21/60\n",
      "6s - loss: 0.0165 - val_loss: 0.0909\n",
      "Epoch 22/60\n",
      "6s - loss: 0.0170 - val_loss: 0.0897\n",
      "Epoch 23/60\n",
      "6s - loss: 0.0171 - val_loss: 0.0877\n",
      "Epoch 24/60\n",
      "6s - loss: 0.0174 - val_loss: 0.0934\n",
      "Epoch 25/60\n",
      "6s - loss: 0.0173 - val_loss: 0.0912\n",
      "Epoch 26/60\n",
      "7s - loss: 0.0167 - val_loss: 0.0891\n",
      "Epoch 27/60\n",
      "6s - loss: 0.0171 - val_loss: 0.0919\n",
      "Epoch 28/60\n",
      "6s - loss: 0.0167 - val_loss: 0.0920\n",
      "Epoch 29/60\n",
      "6s - loss: 0.0174 - val_loss: 0.0918\n",
      "Epoch 30/60\n",
      "6s - loss: 0.0167 - val_loss: 0.0909\n",
      "Epoch 31/60\n",
      "6s - loss: 0.0173 - val_loss: 0.0903\n",
      "Epoch 32/60\n",
      "7s - loss: 0.0171 - val_loss: 0.0942\n",
      "Epoch 33/60\n",
      "6s - loss: 0.0171 - val_loss: 0.0927\n",
      "Epoch 34/60\n",
      "6s - loss: 0.0168 - val_loss: 0.0882\n",
      "Epoch 35/60\n",
      "6s - loss: 0.0177 - val_loss: 0.0880\n",
      "Epoch 36/60\n",
      "6s - loss: 0.0171 - val_loss: 0.0924\n",
      "Epoch 37/60\n",
      "6s - loss: 0.0169 - val_loss: 0.0887\n",
      "Epoch 38/60\n",
      "6s - loss: 0.0175 - val_loss: 0.0887\n",
      "Epoch 39/60\n",
      "6s - loss: 0.0167 - val_loss: 0.0912\n",
      "Epoch 40/60\n",
      "6s - loss: 0.0166 - val_loss: 0.0930\n",
      "Epoch 41/60\n",
      "6s - loss: 0.0170 - val_loss: 0.0924\n",
      "Epoch 42/60\n",
      "6s - loss: 0.0174 - val_loss: 0.0893\n",
      "Epoch 43/60\n",
      "6s - loss: 0.0163 - val_loss: 0.0907\n",
      "Epoch 44/60\n",
      "6s - loss: 0.0167 - val_loss: 0.0907\n",
      "Epoch 45/60\n",
      "6s - loss: 0.0168 - val_loss: 0.0924\n",
      "Epoch 46/60\n",
      "7s - loss: 0.0168 - val_loss: 0.0880\n",
      "Epoch 47/60\n",
      "6s - loss: 0.0168 - val_loss: 0.0915\n",
      "Epoch 48/60\n",
      "6s - loss: 0.0169 - val_loss: 0.0907\n",
      "Epoch 49/60\n",
      "6s - loss: 0.0167 - val_loss: 0.0928\n",
      "Epoch 50/60\n",
      "6s - loss: 0.0170 - val_loss: 0.0941\n",
      "Epoch 51/60\n",
      "6s - loss: 0.0166 - val_loss: 0.0893\n",
      "Epoch 52/60\n",
      "7s - loss: 0.0170 - val_loss: 0.0930\n",
      "Epoch 53/60\n",
      "7s - loss: 0.0168 - val_loss: 0.0883\n",
      "Epoch 54/60\n",
      "7s - loss: 0.0171 - val_loss: 0.0877\n",
      "Epoch 55/60\n",
      "6s - loss: 0.0168 - val_loss: 0.0919\n",
      "Epoch 56/60\n",
      "6s - loss: 0.0164 - val_loss: 0.0887\n",
      "Epoch 57/60\n",
      "10s - loss: 0.0171 - val_loss: 0.0909\n",
      "Epoch 58/60\n",
      "10s - loss: 0.0170 - val_loss: 0.0863\n",
      "Epoch 59/60\n",
      "10s - loss: 0.0162 - val_loss: 0.0907\n",
      "Epoch 60/60\n",
      "8s - loss: 0.0165 - val_loss: 0.0921\n",
      "13) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "9s - loss: 0.0171 - val_loss: 0.0906\n",
      "Epoch 2/60\n",
      "7s - loss: 0.0167 - val_loss: 0.0857\n",
      "Epoch 3/60\n",
      "6s - loss: 0.0159 - val_loss: 0.0901\n",
      "Epoch 4/60\n",
      "6s - loss: 0.0169 - val_loss: 0.0898\n",
      "Epoch 5/60\n",
      "6s - loss: 0.0167 - val_loss: 0.0898\n",
      "Epoch 6/60\n",
      "6s - loss: 0.0173 - val_loss: 0.0906\n",
      "Epoch 7/60\n",
      "6s - loss: 0.0163 - val_loss: 0.0919\n",
      "Epoch 8/60\n",
      "6s - loss: 0.0169 - val_loss: 0.0936\n",
      "Epoch 9/60\n",
      "6s - loss: 0.0161 - val_loss: 0.0940\n",
      "Epoch 10/60\n",
      "6s - loss: 0.0169 - val_loss: 0.0921\n",
      "Epoch 11/60\n",
      "6s - loss: 0.0163 - val_loss: 0.0888\n",
      "Epoch 12/60\n",
      "7s - loss: 0.0165 - val_loss: 0.0914\n",
      "Epoch 13/60\n",
      "7s - loss: 0.0163 - val_loss: 0.0906\n",
      "Epoch 14/60\n",
      "7s - loss: 0.0170 - val_loss: 0.0879\n",
      "Epoch 15/60\n",
      "6s - loss: 0.0171 - val_loss: 0.0906\n",
      "Epoch 16/60\n",
      "7s - loss: 0.0163 - val_loss: 0.0886\n",
      "Epoch 17/60\n",
      "7s - loss: 0.0162 - val_loss: 0.0928\n",
      "Epoch 18/60\n",
      "7s - loss: 0.0170 - val_loss: 0.0927\n",
      "Epoch 19/60\n",
      "7s - loss: 0.0169 - val_loss: 0.0907\n",
      "Epoch 20/60\n",
      "8s - loss: 0.0156 - val_loss: 0.0923\n",
      "Epoch 21/60\n",
      "9s - loss: 0.0164 - val_loss: 0.0883\n",
      "Epoch 22/60\n",
      "7s - loss: 0.0172 - val_loss: 0.0913\n",
      "Epoch 23/60\n",
      "9s - loss: 0.0161 - val_loss: 0.0905\n",
      "Epoch 24/60\n",
      "9s - loss: 0.0162 - val_loss: 0.0908\n",
      "Epoch 25/60\n",
      "6s - loss: 0.0168 - val_loss: 0.0869\n",
      "Epoch 26/60\n",
      "6s - loss: 0.0163 - val_loss: 0.0916\n",
      "Epoch 27/60\n",
      "7s - loss: 0.0162 - val_loss: 0.0880\n",
      "Epoch 28/60\n",
      "7s - loss: 0.0161 - val_loss: 0.0897\n",
      "Epoch 29/60\n",
      "7s - loss: 0.0168 - val_loss: 0.0920\n",
      "Epoch 30/60\n",
      "7s - loss: 0.0165 - val_loss: 0.0882\n",
      "Epoch 31/60\n",
      "10s - loss: 0.0163 - val_loss: 0.0898\n",
      "Epoch 32/60\n",
      "10s - loss: 0.0164 - val_loss: 0.0931\n",
      "Epoch 33/60\n",
      "9s - loss: 0.0159 - val_loss: 0.0898\n",
      "Epoch 34/60\n",
      "7s - loss: 0.0169 - val_loss: 0.0897\n",
      "Epoch 35/60\n",
      "8s - loss: 0.0161 - val_loss: 0.0926\n",
      "Epoch 36/60\n",
      "7s - loss: 0.0158 - val_loss: 0.0893\n",
      "Epoch 37/60\n",
      "7s - loss: 0.0164 - val_loss: 0.0911\n",
      "Epoch 38/60\n",
      "9s - loss: 0.0163 - val_loss: 0.0898\n",
      "Epoch 39/60\n",
      "8s - loss: 0.0168 - val_loss: 0.0955\n",
      "Epoch 40/60\n",
      "7s - loss: 0.0158 - val_loss: 0.0917\n",
      "Epoch 41/60\n",
      "8s - loss: 0.0159 - val_loss: 0.0905\n",
      "Epoch 42/60\n",
      "9s - loss: 0.0163 - val_loss: 0.0868\n",
      "Epoch 43/60\n",
      "9s - loss: 0.0162 - val_loss: 0.0910\n",
      "Epoch 44/60\n",
      "8s - loss: 0.0166 - val_loss: 0.0890\n",
      "Epoch 45/60\n",
      "9s - loss: 0.0164 - val_loss: 0.0899\n",
      "Epoch 46/60\n",
      "11s - loss: 0.0158 - val_loss: 0.0908\n",
      "Epoch 47/60\n",
      "9s - loss: 0.0163 - val_loss: 0.0922\n",
      "Epoch 48/60\n",
      "8s - loss: 0.0160 - val_loss: 0.0875\n",
      "Epoch 49/60\n",
      "8s - loss: 0.0165 - val_loss: 0.0883\n",
      "Epoch 50/60\n",
      "7s - loss: 0.0163 - val_loss: 0.0875\n",
      "Epoch 51/60\n",
      "7s - loss: 0.0158 - val_loss: 0.0901\n",
      "Epoch 52/60\n",
      "7s - loss: 0.0160 - val_loss: 0.0884\n",
      "Epoch 53/60\n",
      "7s - loss: 0.0158 - val_loss: 0.0905\n",
      "Epoch 54/60\n",
      "7s - loss: 0.0161 - val_loss: 0.0859\n",
      "Epoch 55/60\n",
      "8s - loss: 0.0162 - val_loss: 0.0867\n",
      "Epoch 56/60\n",
      "7s - loss: 0.0163 - val_loss: 0.0880\n",
      "Epoch 57/60\n",
      "7s - loss: 0.0160 - val_loss: 0.0837\n",
      "Epoch 58/60\n",
      "6s - loss: 0.0159 - val_loss: 0.0915\n",
      "Epoch 59/60\n",
      "6s - loss: 0.0160 - val_loss: 0.0929\n",
      "Epoch 60/60\n",
      "7s - loss: 0.0164 - val_loss: 0.0882\n",
      "14) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "6s - loss: 0.0161 - val_loss: 0.0885\n",
      "Epoch 2/60\n",
      "6s - loss: 0.0156 - val_loss: 0.0917\n",
      "Epoch 3/60\n",
      "7s - loss: 0.0156 - val_loss: 0.0928\n",
      "Epoch 4/60\n",
      "6s - loss: 0.0162 - val_loss: 0.0937\n",
      "Epoch 5/60\n",
      "7s - loss: 0.0160 - val_loss: 0.0917\n",
      "Epoch 6/60\n",
      "7s - loss: 0.0165 - val_loss: 0.0928\n",
      "Epoch 7/60\n",
      "7s - loss: 0.0159 - val_loss: 0.0904\n",
      "Epoch 8/60\n",
      "7s - loss: 0.0156 - val_loss: 0.0886\n",
      "Epoch 9/60\n",
      "7s - loss: 0.0158 - val_loss: 0.0918\n",
      "Epoch 10/60\n",
      "10s - loss: 0.0164 - val_loss: 0.0896\n",
      "Epoch 11/60\n",
      "8s - loss: 0.0162 - val_loss: 0.0902\n",
      "Epoch 12/60\n",
      "8s - loss: 0.0161 - val_loss: 0.0888\n",
      "Epoch 13/60\n",
      "6s - loss: 0.0159 - val_loss: 0.0896\n",
      "Epoch 14/60\n",
      "6s - loss: 0.0156 - val_loss: 0.0897\n",
      "Epoch 15/60\n",
      "6s - loss: 0.0159 - val_loss: 0.0885\n",
      "Epoch 16/60\n",
      "6s - loss: 0.0157 - val_loss: 0.0892\n",
      "Epoch 17/60\n",
      "6s - loss: 0.0160 - val_loss: 0.0931\n",
      "Epoch 18/60\n",
      "6s - loss: 0.0158 - val_loss: 0.0916\n",
      "Epoch 19/60\n",
      "6s - loss: 0.0156 - val_loss: 0.0903\n",
      "Epoch 20/60\n",
      "6s - loss: 0.0158 - val_loss: 0.0894\n",
      "Epoch 21/60\n",
      "6s - loss: 0.0155 - val_loss: 0.0880\n",
      "Epoch 22/60\n",
      "6s - loss: 0.0161 - val_loss: 0.0934\n",
      "Epoch 23/60\n",
      "6s - loss: 0.0156 - val_loss: 0.0930\n",
      "Epoch 24/60\n",
      "7s - loss: 0.0157 - val_loss: 0.0927\n",
      "Epoch 25/60\n",
      "8s - loss: 0.0156 - val_loss: 0.0890\n",
      "Epoch 26/60\n",
      "8s - loss: 0.0157 - val_loss: 0.0894\n",
      "Epoch 27/60\n",
      "8s - loss: 0.0156 - val_loss: 0.0873\n",
      "Epoch 28/60\n",
      "8s - loss: 0.0159 - val_loss: 0.0881\n",
      "Epoch 29/60\n",
      "7s - loss: 0.0160 - val_loss: 0.0898\n",
      "Epoch 30/60\n",
      "7s - loss: 0.0151 - val_loss: 0.0914\n",
      "Epoch 31/60\n",
      "10s - loss: 0.0156 - val_loss: 0.0888\n",
      "Epoch 32/60\n",
      "8s - loss: 0.0161 - val_loss: 0.0944\n",
      "Epoch 33/60\n",
      "7s - loss: 0.0158 - val_loss: 0.0899\n",
      "Epoch 34/60\n",
      "7s - loss: 0.0164 - val_loss: 0.0892\n",
      "Epoch 35/60\n",
      "7s - loss: 0.0161 - val_loss: 0.0918\n",
      "Epoch 36/60\n",
      "7s - loss: 0.0149 - val_loss: 0.0928\n",
      "Epoch 37/60\n",
      "9s - loss: 0.0159 - val_loss: 0.0954\n",
      "Epoch 38/60\n",
      "9s - loss: 0.0157 - val_loss: 0.0917\n",
      "Epoch 39/60\n",
      "8s - loss: 0.0157 - val_loss: 0.0926\n",
      "Epoch 40/60\n",
      "8s - loss: 0.0159 - val_loss: 0.0886\n",
      "Epoch 41/60\n",
      "8s - loss: 0.0156 - val_loss: 0.0939\n",
      "Epoch 42/60\n",
      "7s - loss: 0.0156 - val_loss: 0.0914\n",
      "Epoch 43/60\n",
      "7s - loss: 0.0156 - val_loss: 0.0897\n",
      "Epoch 44/60\n",
      "6s - loss: 0.0154 - val_loss: 0.0961\n",
      "Epoch 45/60\n",
      "7s - loss: 0.0158 - val_loss: 0.0922\n",
      "Epoch 46/60\n",
      "6s - loss: 0.0154 - val_loss: 0.0923\n",
      "Epoch 47/60\n",
      "6s - loss: 0.0163 - val_loss: 0.0899\n",
      "Epoch 48/60\n",
      "6s - loss: 0.0152 - val_loss: 0.0885\n",
      "Epoch 49/60\n",
      "6s - loss: 0.0157 - val_loss: 0.0893\n",
      "Epoch 50/60\n",
      "6s - loss: 0.0154 - val_loss: 0.0886\n",
      "Epoch 51/60\n",
      "6s - loss: 0.0155 - val_loss: 0.0900\n",
      "Epoch 52/60\n",
      "7s - loss: 0.0158 - val_loss: 0.0898\n",
      "Epoch 53/60\n",
      "6s - loss: 0.0159 - val_loss: 0.0871\n",
      "Epoch 54/60\n",
      "6s - loss: 0.0151 - val_loss: 0.0925\n",
      "Epoch 55/60\n",
      "6s - loss: 0.0156 - val_loss: 0.0910\n",
      "Epoch 56/60\n",
      "6s - loss: 0.0156 - val_loss: 0.0935\n",
      "Epoch 57/60\n",
      "7s - loss: 0.0155 - val_loss: 0.0904\n",
      "Epoch 58/60\n",
      "7s - loss: 0.0156 - val_loss: 0.0897\n",
      "Epoch 59/60\n",
      "8s - loss: 0.0157 - val_loss: 0.0893\n",
      "Epoch 60/60\n",
      "7s - loss: 0.0154 - val_loss: 0.0896\n",
      "15) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "7s - loss: 0.0155 - val_loss: 0.0882\n",
      "Epoch 2/60\n",
      "6s - loss: 0.0157 - val_loss: 0.0906\n",
      "Epoch 3/60\n",
      "7s - loss: 0.0152 - val_loss: 0.0894\n",
      "Epoch 4/60\n",
      "7s - loss: 0.0152 - val_loss: 0.0907\n",
      "Epoch 5/60\n",
      "6s - loss: 0.0154 - val_loss: 0.0896\n",
      "Epoch 6/60\n",
      "7s - loss: 0.0149 - val_loss: 0.0931\n",
      "Epoch 7/60\n",
      "6s - loss: 0.0152 - val_loss: 0.0894\n",
      "Epoch 8/60\n",
      "6s - loss: 0.0151 - val_loss: 0.0897\n",
      "Epoch 9/60\n",
      "6s - loss: 0.0150 - val_loss: 0.0886\n",
      "Epoch 10/60\n",
      "7s - loss: 0.0153 - val_loss: 0.0902\n",
      "Epoch 11/60\n",
      "7s - loss: 0.0150 - val_loss: 0.0910\n",
      "Epoch 12/60\n",
      "7s - loss: 0.0157 - val_loss: 0.0908\n",
      "Epoch 13/60\n",
      "7s - loss: 0.0151 - val_loss: 0.0940\n",
      "Epoch 14/60\n",
      "7s - loss: 0.0157 - val_loss: 0.0902\n",
      "Epoch 15/60\n",
      "7s - loss: 0.0152 - val_loss: 0.0900\n",
      "Epoch 16/60\n",
      "7s - loss: 0.0144 - val_loss: 0.0918\n",
      "Epoch 17/60\n",
      "7s - loss: 0.0148 - val_loss: 0.0871\n",
      "Epoch 18/60\n",
      "7s - loss: 0.0155 - val_loss: 0.0923\n",
      "Epoch 19/60\n",
      "6s - loss: 0.0152 - val_loss: 0.0963\n",
      "Epoch 20/60\n",
      "7s - loss: 0.0153 - val_loss: 0.0907\n",
      "Epoch 21/60\n",
      "7s - loss: 0.0159 - val_loss: 0.0947\n",
      "Epoch 22/60\n",
      "6s - loss: 0.0154 - val_loss: 0.0897\n",
      "Epoch 23/60\n",
      "9s - loss: 0.0152 - val_loss: 0.0916\n",
      "Epoch 24/60\n",
      "7s - loss: 0.0155 - val_loss: 0.0879\n",
      "Epoch 25/60\n",
      "7s - loss: 0.0150 - val_loss: 0.0899\n",
      "Epoch 26/60\n",
      "6s - loss: 0.0149 - val_loss: 0.0886\n",
      "Epoch 27/60\n",
      "7s - loss: 0.0152 - val_loss: 0.0886\n",
      "Epoch 28/60\n",
      "7s - loss: 0.0155 - val_loss: 0.0912\n",
      "Epoch 29/60\n",
      "7s - loss: 0.0153 - val_loss: 0.0914\n",
      "Epoch 30/60\n",
      "7s - loss: 0.0155 - val_loss: 0.0886\n",
      "Epoch 31/60\n",
      "7s - loss: 0.0153 - val_loss: 0.0911\n",
      "Epoch 32/60\n",
      "7s - loss: 0.0149 - val_loss: 0.0934\n",
      "Epoch 33/60\n",
      "7s - loss: 0.0151 - val_loss: 0.0894\n",
      "Epoch 34/60\n",
      "7s - loss: 0.0150 - val_loss: 0.0911\n",
      "Epoch 35/60\n",
      "7s - loss: 0.0151 - val_loss: 0.0897\n",
      "Epoch 36/60\n",
      "7s - loss: 0.0151 - val_loss: 0.0922\n",
      "Epoch 37/60\n",
      "6s - loss: 0.0153 - val_loss: 0.0924\n",
      "Epoch 38/60\n",
      "6s - loss: 0.0146 - val_loss: 0.0925\n",
      "Epoch 39/60\n",
      "7s - loss: 0.0153 - val_loss: 0.0894\n",
      "Epoch 40/60\n",
      "7s - loss: 0.0151 - val_loss: 0.0912\n",
      "Epoch 41/60\n",
      "7s - loss: 0.0153 - val_loss: 0.0924\n",
      "Epoch 42/60\n",
      "6s - loss: 0.0151 - val_loss: 0.0895\n",
      "Epoch 43/60\n",
      "9s - loss: 0.0158 - val_loss: 0.0920\n",
      "Epoch 44/60\n",
      "6s - loss: 0.0146 - val_loss: 0.0919\n",
      "Epoch 45/60\n",
      "7s - loss: 0.0153 - val_loss: 0.0879\n",
      "Epoch 46/60\n",
      "7s - loss: 0.0146 - val_loss: 0.0867\n",
      "Epoch 47/60\n",
      "4s - loss: 0.0154 - val_loss: 0.0901\n",
      "Epoch 48/60\n",
      "7s - loss: 0.0150 - val_loss: 0.0928\n",
      "Epoch 49/60\n",
      "7s - loss: 0.0150 - val_loss: 0.0890\n",
      "Epoch 50/60\n",
      "7s - loss: 0.0149 - val_loss: 0.0905\n",
      "Epoch 51/60\n",
      "7s - loss: 0.0148 - val_loss: 0.0893\n",
      "Epoch 52/60\n",
      "7s - loss: 0.0150 - val_loss: 0.0892\n",
      "Epoch 53/60\n",
      "7s - loss: 0.0150 - val_loss: 0.0912\n",
      "Epoch 54/60\n",
      "7s - loss: 0.0153 - val_loss: 0.0886\n",
      "Epoch 55/60\n",
      "7s - loss: 0.0149 - val_loss: 0.0900\n",
      "Epoch 56/60\n",
      "6s - loss: 0.0147 - val_loss: 0.0899\n",
      "Epoch 57/60\n",
      "6s - loss: 0.0144 - val_loss: 0.0906\n",
      "Epoch 58/60\n",
      "7s - loss: 0.0151 - val_loss: 0.0889\n",
      "Epoch 59/60\n",
      "7s - loss: 0.0153 - val_loss: 0.0909\n",
      "Epoch 60/60\n",
      "7s - loss: 0.0149 - val_loss: 0.0876\n",
      "16) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "7s - loss: 0.0152 - val_loss: 0.0905\n",
      "Epoch 2/60\n",
      "7s - loss: 0.0147 - val_loss: 0.0870\n",
      "Epoch 3/60\n",
      "7s - loss: 0.0153 - val_loss: 0.0898\n",
      "Epoch 4/60\n",
      "6s - loss: 0.0150 - val_loss: 0.0937\n",
      "Epoch 5/60\n",
      "7s - loss: 0.0149 - val_loss: 0.0913\n",
      "Epoch 6/60\n",
      "7s - loss: 0.0150 - val_loss: 0.0929\n",
      "Epoch 7/60\n",
      "7s - loss: 0.0146 - val_loss: 0.0890\n",
      "Epoch 8/60\n",
      "6s - loss: 0.0149 - val_loss: 0.0900\n",
      "Epoch 9/60\n",
      "9s - loss: 0.0146 - val_loss: 0.0924\n",
      "Epoch 10/60\n",
      "8s - loss: 0.0146 - val_loss: 0.0883\n",
      "Epoch 11/60\n",
      "9s - loss: 0.0143 - val_loss: 0.0908\n",
      "Epoch 12/60\n",
      "6s - loss: 0.0146 - val_loss: 0.0955\n",
      "Epoch 13/60\n",
      "6s - loss: 0.0148 - val_loss: 0.0911\n",
      "Epoch 14/60\n",
      "6s - loss: 0.0148 - val_loss: 0.0899\n",
      "Epoch 15/60\n",
      "6s - loss: 0.0149 - val_loss: 0.0924\n",
      "Epoch 16/60\n",
      "6s - loss: 0.0147 - val_loss: 0.0905\n",
      "Epoch 17/60\n",
      "6s - loss: 0.0145 - val_loss: 0.0920\n",
      "Epoch 18/60\n",
      "6s - loss: 0.0150 - val_loss: 0.0891\n",
      "Epoch 19/60\n",
      "7s - loss: 0.0145 - val_loss: 0.0910\n",
      "Epoch 20/60\n",
      "7s - loss: 0.0148 - val_loss: 0.0911\n",
      "Epoch 21/60\n",
      "6s - loss: 0.0147 - val_loss: 0.0920\n",
      "Epoch 22/60\n",
      "7s - loss: 0.0144 - val_loss: 0.0914\n",
      "Epoch 23/60\n",
      "7s - loss: 0.0149 - val_loss: 0.0942\n",
      "Epoch 24/60\n",
      "7s - loss: 0.0146 - val_loss: 0.0900\n",
      "Epoch 25/60\n",
      "6s - loss: 0.0145 - val_loss: 0.0887\n",
      "Epoch 26/60\n",
      "6s - loss: 0.0151 - val_loss: 0.0895\n",
      "Epoch 27/60\n",
      "7s - loss: 0.0143 - val_loss: 0.0895\n",
      "Epoch 28/60\n",
      "6s - loss: 0.0143 - val_loss: 0.0931\n",
      "Epoch 29/60\n",
      "6s - loss: 0.0149 - val_loss: 0.0912\n",
      "Epoch 30/60\n",
      "7s - loss: 0.0148 - val_loss: 0.0905\n",
      "Epoch 31/60\n",
      "7s - loss: 0.0139 - val_loss: 0.0922\n",
      "Epoch 32/60\n",
      "7s - loss: 0.0143 - val_loss: 0.0934\n",
      "Epoch 33/60\n",
      "7s - loss: 0.0141 - val_loss: 0.0948\n",
      "Epoch 34/60\n",
      "6s - loss: 0.0142 - val_loss: 0.0892\n",
      "Epoch 35/60\n",
      "6s - loss: 0.0151 - val_loss: 0.0922\n",
      "Epoch 36/60\n",
      "6s - loss: 0.0146 - val_loss: 0.0918\n",
      "Epoch 37/60\n",
      "6s - loss: 0.0147 - val_loss: 0.0909\n",
      "Epoch 38/60\n",
      "7s - loss: 0.0143 - val_loss: 0.0932\n",
      "Epoch 39/60\n",
      "7s - loss: 0.0143 - val_loss: 0.0951\n",
      "Epoch 40/60\n",
      "6s - loss: 0.0147 - val_loss: 0.0914\n",
      "Epoch 41/60\n",
      "6s - loss: 0.0140 - val_loss: 0.0919\n",
      "Epoch 42/60\n",
      "7s - loss: 0.0148 - val_loss: 0.0899\n",
      "Epoch 43/60\n",
      "6s - loss: 0.0144 - val_loss: 0.0933\n",
      "Epoch 44/60\n",
      "6s - loss: 0.0147 - val_loss: 0.0943\n",
      "Epoch 45/60\n",
      "6s - loss: 0.0148 - val_loss: 0.0921\n",
      "Epoch 46/60\n",
      "6s - loss: 0.0144 - val_loss: 0.0870\n",
      "Epoch 47/60\n",
      "6s - loss: 0.0146 - val_loss: 0.0906\n",
      "Epoch 48/60\n",
      "7s - loss: 0.0142 - val_loss: 0.0928\n",
      "Epoch 49/60\n",
      "6s - loss: 0.0143 - val_loss: 0.0908\n",
      "Epoch 50/60\n",
      "6s - loss: 0.0139 - val_loss: 0.0951\n",
      "Epoch 51/60\n",
      "6s - loss: 0.0141 - val_loss: 0.0935\n",
      "Epoch 52/60\n",
      "6s - loss: 0.0142 - val_loss: 0.0916\n",
      "Epoch 53/60\n",
      "6s - loss: 0.0143 - val_loss: 0.0924\n",
      "Epoch 54/60\n",
      "6s - loss: 0.0141 - val_loss: 0.0958\n",
      "Epoch 55/60\n",
      "6s - loss: 0.0143 - val_loss: 0.0893\n",
      "Epoch 56/60\n",
      "7s - loss: 0.0152 - val_loss: 0.0904\n",
      "Epoch 57/60\n",
      "6s - loss: 0.0144 - val_loss: 0.0892\n",
      "Epoch 58/60\n",
      "12s - loss: 0.0140 - val_loss: 0.0873\n",
      "Epoch 59/60\n",
      "7s - loss: 0.0137 - val_loss: 0.0906\n",
      "Epoch 60/60\n",
      "7s - loss: 0.0143 - val_loss: 0.0899\n",
      "17) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "7s - loss: 0.0139 - val_loss: 0.0911\n",
      "Epoch 2/60\n",
      "6s - loss: 0.0143 - val_loss: 0.0895\n",
      "Epoch 3/60\n",
      "7s - loss: 0.0142 - val_loss: 0.0901\n",
      "Epoch 4/60\n",
      "7s - loss: 0.0141 - val_loss: 0.0916\n",
      "Epoch 5/60\n",
      "6s - loss: 0.0145 - val_loss: 0.0911\n",
      "Epoch 6/60\n",
      "7s - loss: 0.0144 - val_loss: 0.0934\n",
      "Epoch 7/60\n",
      "7s - loss: 0.0137 - val_loss: 0.0914\n",
      "Epoch 8/60\n",
      "6s - loss: 0.0138 - val_loss: 0.0911\n",
      "Epoch 9/60\n",
      "6s - loss: 0.0142 - val_loss: 0.0922\n",
      "Epoch 10/60\n",
      "7s - loss: 0.0140 - val_loss: 0.0883\n",
      "Epoch 11/60\n",
      "7s - loss: 0.0140 - val_loss: 0.0898\n",
      "Epoch 12/60\n",
      "6s - loss: 0.0136 - val_loss: 0.0911\n",
      "Epoch 13/60\n",
      "7s - loss: 0.0142 - val_loss: 0.0899\n",
      "Epoch 14/60\n",
      "6s - loss: 0.0136 - val_loss: 0.0921\n",
      "Epoch 15/60\n",
      "7s - loss: 0.0138 - val_loss: 0.0908\n",
      "Epoch 16/60\n",
      "7s - loss: 0.0146 - val_loss: 0.0903\n",
      "Epoch 17/60\n",
      "6s - loss: 0.0143 - val_loss: 0.0897\n",
      "Epoch 18/60\n",
      "7s - loss: 0.0137 - val_loss: 0.0904\n",
      "Epoch 19/60\n",
      "7s - loss: 0.0137 - val_loss: 0.0911\n",
      "Epoch 20/60\n",
      "6s - loss: 0.0140 - val_loss: 0.0885\n",
      "Epoch 21/60\n",
      "7s - loss: 0.0140 - val_loss: 0.0945\n",
      "Epoch 22/60\n",
      "7s - loss: 0.0139 - val_loss: 0.0942\n",
      "Epoch 23/60\n",
      "6s - loss: 0.0141 - val_loss: 0.0909\n",
      "Epoch 24/60\n",
      "6s - loss: 0.0141 - val_loss: 0.0932\n",
      "Epoch 25/60\n",
      "6s - loss: 0.0140 - val_loss: 0.0899\n",
      "Epoch 26/60\n",
      "6s - loss: 0.0135 - val_loss: 0.0886\n",
      "Epoch 27/60\n",
      "6s - loss: 0.0139 - val_loss: 0.0891\n",
      "Epoch 28/60\n",
      "6s - loss: 0.0137 - val_loss: 0.0947\n",
      "Epoch 29/60\n",
      "6s - loss: 0.0139 - val_loss: 0.0882\n",
      "Epoch 30/60\n",
      "6s - loss: 0.0139 - val_loss: 0.0908\n",
      "Epoch 31/60\n",
      "6s - loss: 0.0139 - val_loss: 0.0929\n",
      "Epoch 32/60\n",
      "7s - loss: 0.0140 - val_loss: 0.0916\n",
      "Epoch 33/60\n",
      "12s - loss: 0.0141 - val_loss: 0.0887\n",
      "Epoch 34/60\n",
      "19s - loss: 0.0139 - val_loss: 0.0876\n",
      "Epoch 35/60\n",
      "14s - loss: 0.0135 - val_loss: 0.0904\n",
      "Epoch 36/60\n",
      "14s - loss: 0.0140 - val_loss: 0.0884\n",
      "Epoch 37/60\n",
      "14s - loss: 0.0139 - val_loss: 0.0923\n",
      "Epoch 38/60\n",
      "14s - loss: 0.0142 - val_loss: 0.0918\n",
      "Epoch 39/60\n",
      "14s - loss: 0.0139 - val_loss: 0.0916\n",
      "Epoch 40/60\n",
      "14s - loss: 0.0135 - val_loss: 0.0872\n",
      "Epoch 41/60\n",
      "16s - loss: 0.0142 - val_loss: 0.0891\n",
      "Epoch 42/60\n",
      "14s - loss: 0.0140 - val_loss: 0.0918\n",
      "Epoch 43/60\n",
      "15s - loss: 0.0134 - val_loss: 0.0886\n",
      "Epoch 44/60\n",
      "18s - loss: 0.0140 - val_loss: 0.0908\n",
      "Epoch 45/60\n",
      "14s - loss: 0.0136 - val_loss: 0.0925\n",
      "Epoch 46/60\n",
      "13s - loss: 0.0139 - val_loss: 0.0902\n",
      "Epoch 47/60\n",
      "14s - loss: 0.0139 - val_loss: 0.0920\n",
      "Epoch 48/60\n",
      "14s - loss: 0.0133 - val_loss: 0.0912\n",
      "Epoch 49/60\n",
      "13s - loss: 0.0137 - val_loss: 0.0864\n",
      "Epoch 50/60\n",
      "13s - loss: 0.0133 - val_loss: 0.0924\n",
      "Epoch 51/60\n",
      "14s - loss: 0.0138 - val_loss: 0.0891\n",
      "Epoch 52/60\n",
      "14s - loss: 0.0133 - val_loss: 0.0924\n",
      "Epoch 53/60\n",
      "14s - loss: 0.0135 - val_loss: 0.0944\n",
      "Epoch 54/60\n",
      "14s - loss: 0.0139 - val_loss: 0.0951\n",
      "Epoch 55/60\n",
      "14s - loss: 0.0131 - val_loss: 0.0910\n",
      "Epoch 56/60\n",
      "13s - loss: 0.0135 - val_loss: 0.0904\n",
      "Epoch 57/60\n",
      "14s - loss: 0.0135 - val_loss: 0.0930\n",
      "Epoch 58/60\n",
      "14s - loss: 0.0140 - val_loss: 0.0887\n",
      "Epoch 59/60\n",
      "14s - loss: 0.0134 - val_loss: 0.0938\n",
      "Epoch 60/60\n",
      "14s - loss: 0.0140 - val_loss: 0.0900\n",
      "18) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "14s - loss: 0.0136 - val_loss: 0.0910\n",
      "Epoch 2/60\n",
      "14s - loss: 0.0140 - val_loss: 0.0884\n",
      "Epoch 3/60\n",
      "14s - loss: 0.0133 - val_loss: 0.0922\n",
      "Epoch 4/60\n",
      "14s - loss: 0.0135 - val_loss: 0.0941\n",
      "Epoch 5/60\n",
      "15s - loss: 0.0132 - val_loss: 0.0956\n",
      "Epoch 6/60\n",
      "16s - loss: 0.0134 - val_loss: 0.0941\n",
      "Epoch 7/60\n",
      "13s - loss: 0.0134 - val_loss: 0.0906\n",
      "Epoch 8/60\n",
      "13s - loss: 0.0132 - val_loss: 0.0867\n",
      "Epoch 9/60\n",
      "14s - loss: 0.0140 - val_loss: 0.0900\n",
      "Epoch 10/60\n",
      "15s - loss: 0.0134 - val_loss: 0.0887\n",
      "Epoch 11/60\n",
      "14s - loss: 0.0137 - val_loss: 0.0903\n",
      "Epoch 12/60\n",
      "14s - loss: 0.0129 - val_loss: 0.0909\n",
      "Epoch 13/60\n",
      "14s - loss: 0.0138 - val_loss: 0.0957\n",
      "Epoch 14/60\n",
      "13s - loss: 0.0136 - val_loss: 0.0930\n",
      "Epoch 15/60\n",
      "15s - loss: 0.0137 - val_loss: 0.0896\n",
      "Epoch 16/60\n",
      "14s - loss: 0.0131 - val_loss: 0.0897\n",
      "Epoch 17/60\n",
      "14s - loss: 0.0134 - val_loss: 0.0905\n",
      "Epoch 18/60\n",
      "14s - loss: 0.0138 - val_loss: 0.0878\n",
      "Epoch 19/60\n",
      "13s - loss: 0.0136 - val_loss: 0.0951\n",
      "Epoch 20/60\n",
      "15s - loss: 0.0135 - val_loss: 0.0909\n",
      "Epoch 21/60\n",
      "14s - loss: 0.0137 - val_loss: 0.0924\n",
      "Epoch 22/60\n",
      "14s - loss: 0.0137 - val_loss: 0.0917\n",
      "Epoch 23/60\n",
      "14s - loss: 0.0134 - val_loss: 0.0894\n",
      "Epoch 24/60\n",
      "14s - loss: 0.0132 - val_loss: 0.0900\n",
      "Epoch 25/60\n",
      "14s - loss: 0.0132 - val_loss: 0.0899\n",
      "Epoch 26/60\n",
      "14s - loss: 0.0134 - val_loss: 0.0913\n",
      "Epoch 27/60\n",
      "14s - loss: 0.0130 - val_loss: 0.0930\n",
      "Epoch 28/60\n",
      "14s - loss: 0.0132 - val_loss: 0.0916\n",
      "Epoch 29/60\n",
      "14s - loss: 0.0135 - val_loss: 0.0899\n",
      "Epoch 30/60\n",
      "14s - loss: 0.0132 - val_loss: 0.0935\n",
      "Epoch 31/60\n",
      "14s - loss: 0.0136 - val_loss: 0.0886\n",
      "Epoch 32/60\n",
      "14s - loss: 0.0129 - val_loss: 0.0947\n",
      "Epoch 33/60\n",
      "14s - loss: 0.0134 - val_loss: 0.0922\n",
      "Epoch 34/60\n",
      "14s - loss: 0.0130 - val_loss: 0.0943\n",
      "Epoch 35/60\n",
      "14s - loss: 0.0135 - val_loss: 0.0912\n",
      "Epoch 36/60\n",
      "14s - loss: 0.0131 - val_loss: 0.0926\n",
      "Epoch 37/60\n",
      "14s - loss: 0.0135 - val_loss: 0.0947\n",
      "Epoch 38/60\n",
      "17s - loss: 0.0134 - val_loss: 0.0902\n",
      "Epoch 39/60\n",
      "16s - loss: 0.0132 - val_loss: 0.0895\n",
      "Epoch 40/60\n",
      "14s - loss: 0.0126 - val_loss: 0.0880\n",
      "Epoch 41/60\n",
      "14s - loss: 0.0133 - val_loss: 0.0926\n",
      "Epoch 42/60\n",
      "13s - loss: 0.0135 - val_loss: 0.0915\n",
      "Epoch 43/60\n",
      "14s - loss: 0.0132 - val_loss: 0.0881\n",
      "Epoch 44/60\n",
      "14s - loss: 0.0133 - val_loss: 0.0915\n",
      "Epoch 45/60\n",
      "15s - loss: 0.0130 - val_loss: 0.0906\n",
      "Epoch 46/60\n",
      "14s - loss: 0.0131 - val_loss: 0.0917\n",
      "Epoch 47/60\n",
      "14s - loss: 0.0127 - val_loss: 0.0895\n",
      "Epoch 48/60\n",
      "14s - loss: 0.0134 - val_loss: 0.0902\n",
      "Epoch 49/60\n",
      "15s - loss: 0.0131 - val_loss: 0.0911\n",
      "Epoch 50/60\n",
      "15s - loss: 0.0134 - val_loss: 0.0895\n",
      "Epoch 51/60\n",
      "13s - loss: 0.0129 - val_loss: 0.0898\n",
      "Epoch 52/60\n",
      "16s - loss: 0.0129 - val_loss: 0.0902\n",
      "Epoch 53/60\n",
      "15s - loss: 0.0136 - val_loss: 0.0892\n",
      "Epoch 54/60\n",
      "14s - loss: 0.0127 - val_loss: 0.0920\n",
      "Epoch 55/60\n",
      "15s - loss: 0.0132 - val_loss: 0.0904\n",
      "Epoch 56/60\n",
      "14s - loss: 0.0129 - val_loss: 0.0933\n",
      "Epoch 57/60\n",
      "14s - loss: 0.0129 - val_loss: 0.0924\n",
      "Epoch 58/60\n",
      "14s - loss: 0.0135 - val_loss: 0.0877\n",
      "Epoch 59/60\n",
      "15s - loss: 0.0129 - val_loss: 0.0918\n",
      "Epoch 60/60\n",
      "14s - loss: 0.0128 - val_loss: 0.0874\n",
      "19) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "14s - loss: 0.0126 - val_loss: 0.0870\n",
      "Epoch 2/60\n",
      "15s - loss: 0.0131 - val_loss: 0.0909\n",
      "Epoch 3/60\n",
      "16s - loss: 0.0128 - val_loss: 0.0868\n",
      "Epoch 4/60\n",
      "15s - loss: 0.0129 - val_loss: 0.0929\n",
      "Epoch 5/60\n",
      "15s - loss: 0.0133 - val_loss: 0.0883\n",
      "Epoch 6/60\n",
      "14s - loss: 0.0132 - val_loss: 0.0881\n",
      "Epoch 7/60\n",
      "14s - loss: 0.0131 - val_loss: 0.0889\n",
      "Epoch 8/60\n",
      "15s - loss: 0.0130 - val_loss: 0.0869\n",
      "Epoch 9/60\n",
      "15s - loss: 0.0128 - val_loss: 0.0915\n",
      "Epoch 10/60\n",
      "14s - loss: 0.0130 - val_loss: 0.0882\n",
      "Epoch 11/60\n",
      "14s - loss: 0.0127 - val_loss: 0.0901\n",
      "Epoch 12/60\n",
      "15s - loss: 0.0129 - val_loss: 0.0904\n",
      "Epoch 13/60\n",
      "14s - loss: 0.0131 - val_loss: 0.0928\n",
      "Epoch 14/60\n",
      "15s - loss: 0.0127 - val_loss: 0.0872\n",
      "Epoch 15/60\n",
      "17s - loss: 0.0126 - val_loss: 0.0891\n",
      "Epoch 16/60\n",
      "15s - loss: 0.0128 - val_loss: 0.0911\n",
      "Epoch 17/60\n",
      "15s - loss: 0.0130 - val_loss: 0.0897\n",
      "Epoch 18/60\n",
      "14s - loss: 0.0127 - val_loss: 0.0916\n",
      "Epoch 19/60\n",
      "15s - loss: 0.0128 - val_loss: 0.0915\n",
      "Epoch 20/60\n",
      "14s - loss: 0.0126 - val_loss: 0.0909\n",
      "Epoch 21/60\n",
      "17s - loss: 0.0130 - val_loss: 0.0876\n",
      "Epoch 22/60\n",
      "12s - loss: 0.0130 - val_loss: 0.0894\n",
      "Epoch 23/60\n",
      "14s - loss: 0.0127 - val_loss: 0.0881\n",
      "Epoch 24/60\n",
      "14s - loss: 0.0126 - val_loss: 0.0901\n",
      "Epoch 25/60\n",
      "14s - loss: 0.0127 - val_loss: 0.0886\n",
      "Epoch 26/60\n",
      "14s - loss: 0.0129 - val_loss: 0.0905\n",
      "Epoch 27/60\n",
      "15s - loss: 0.0127 - val_loss: 0.0862\n",
      "Epoch 28/60\n",
      "14s - loss: 0.0126 - val_loss: 0.0897\n",
      "Epoch 29/60\n",
      "14s - loss: 0.0125 - val_loss: 0.0914\n",
      "Epoch 30/60\n",
      "14s - loss: 0.0130 - val_loss: 0.0886\n",
      "Epoch 31/60\n",
      "14s - loss: 0.0126 - val_loss: 0.0897\n",
      "Epoch 32/60\n",
      "15s - loss: 0.0127 - val_loss: 0.0863\n",
      "Epoch 33/60\n",
      "15s - loss: 0.0125 - val_loss: 0.0929\n",
      "Epoch 34/60\n",
      "14s - loss: 0.0130 - val_loss: 0.0874\n",
      "Epoch 35/60\n",
      "15s - loss: 0.0132 - val_loss: 0.0897\n",
      "Epoch 36/60\n",
      "14s - loss: 0.0123 - val_loss: 0.0884\n",
      "Epoch 37/60\n",
      "14s - loss: 0.0128 - val_loss: 0.0940\n",
      "Epoch 38/60\n",
      "14s - loss: 0.0131 - val_loss: 0.0851\n",
      "Epoch 39/60\n",
      "14s - loss: 0.0133 - val_loss: 0.0862\n",
      "Epoch 40/60\n",
      "14s - loss: 0.0129 - val_loss: 0.0888\n",
      "Epoch 41/60\n",
      "14s - loss: 0.0130 - val_loss: 0.0869\n",
      "Epoch 42/60\n",
      "15s - loss: 0.0125 - val_loss: 0.0908\n",
      "Epoch 43/60\n",
      "14s - loss: 0.0133 - val_loss: 0.0881\n",
      "Epoch 44/60\n",
      "14s - loss: 0.0127 - val_loss: 0.0883\n",
      "Epoch 45/60\n",
      "14s - loss: 0.0128 - val_loss: 0.0879\n",
      "Epoch 46/60\n",
      "15s - loss: 0.0125 - val_loss: 0.0907\n",
      "Epoch 47/60\n",
      "18s - loss: 0.0127 - val_loss: 0.0876\n",
      "Epoch 48/60\n",
      "15s - loss: 0.0130 - val_loss: 0.0866\n",
      "Epoch 49/60\n",
      "15s - loss: 0.0122 - val_loss: 0.0891\n",
      "Epoch 50/60\n",
      "14s - loss: 0.0128 - val_loss: 0.0849\n",
      "Epoch 51/60\n",
      "15s - loss: 0.0132 - val_loss: 0.0896\n",
      "Epoch 52/60\n",
      "15s - loss: 0.0124 - val_loss: 0.0933\n",
      "Epoch 53/60\n",
      "14s - loss: 0.0129 - val_loss: 0.0875\n",
      "Epoch 54/60\n",
      "15s - loss: 0.0124 - val_loss: 0.0885\n",
      "Epoch 55/60\n",
      "15s - loss: 0.0127 - val_loss: 0.0869\n",
      "Epoch 56/60\n",
      "15s - loss: 0.0123 - val_loss: 0.0873\n",
      "Epoch 57/60\n",
      "14s - loss: 0.0127 - val_loss: 0.0884\n",
      "Epoch 58/60\n",
      "14s - loss: 0.0125 - val_loss: 0.0861\n",
      "Epoch 59/60\n",
      "15s - loss: 0.0125 - val_loss: 0.0881\n",
      "Epoch 60/60\n",
      "14s - loss: 0.0127 - val_loss: 0.0895\n",
      "20) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "14s - loss: 0.0122 - val_loss: 0.0879\n",
      "Epoch 2/60\n",
      "15s - loss: 0.0127 - val_loss: 0.0895\n",
      "Epoch 3/60\n",
      "15s - loss: 0.0125 - val_loss: 0.0894\n",
      "Epoch 4/60\n",
      "14s - loss: 0.0129 - val_loss: 0.0865\n",
      "Epoch 5/60\n",
      "15s - loss: 0.0123 - val_loss: 0.0874\n",
      "Epoch 6/60\n",
      "15s - loss: 0.0125 - val_loss: 0.0876\n",
      "Epoch 7/60\n",
      "15s - loss: 0.0124 - val_loss: 0.0858\n",
      "Epoch 8/60\n",
      "15s - loss: 0.0123 - val_loss: 0.0890\n",
      "Epoch 9/60\n",
      "20s - loss: 0.0125 - val_loss: 0.0911\n",
      "Epoch 10/60\n",
      "16s - loss: 0.0123 - val_loss: 0.0866\n",
      "Epoch 11/60\n",
      "11s - loss: 0.0125 - val_loss: 0.0855\n",
      "Epoch 12/60\n",
      "1157s - loss: 0.0132 - val_loss: 0.0865\n",
      "Epoch 13/60\n",
      "12s - loss: 0.0127 - val_loss: 0.0902\n",
      "Epoch 14/60\n",
      "10s - loss: 0.0125 - val_loss: 0.0872\n",
      "Epoch 15/60\n",
      "5s - loss: 0.0124 - val_loss: 0.0875\n",
      "Epoch 16/60\n",
      "7s - loss: 0.0127 - val_loss: 0.0899\n",
      "Epoch 17/60\n",
      "7s - loss: 0.0124 - val_loss: 0.0885\n",
      "Epoch 18/60\n",
      "7s - loss: 0.0132 - val_loss: 0.0895\n",
      "Epoch 19/60\n",
      "7s - loss: 0.0121 - val_loss: 0.0913\n",
      "Epoch 20/60\n",
      "7s - loss: 0.0127 - val_loss: 0.0911\n",
      "Epoch 21/60\n",
      "7s - loss: 0.0124 - val_loss: 0.0866\n",
      "Epoch 22/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0904\n",
      "Epoch 23/60\n",
      "6s - loss: 0.0122 - val_loss: 0.0865\n",
      "Epoch 24/60\n",
      "6s - loss: 0.0129 - val_loss: 0.0902\n",
      "Epoch 25/60\n",
      "6s - loss: 0.0122 - val_loss: 0.0894\n",
      "Epoch 26/60\n",
      "6s - loss: 0.0126 - val_loss: 0.0866\n",
      "Epoch 27/60\n",
      "6s - loss: 0.0126 - val_loss: 0.0867\n",
      "Epoch 28/60\n",
      "6s - loss: 0.0132 - val_loss: 0.0886\n",
      "Epoch 29/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0881\n",
      "Epoch 30/60\n",
      "6s - loss: 0.0125 - val_loss: 0.0859\n",
      "Epoch 31/60\n",
      "6s - loss: 0.0126 - val_loss: 0.0936\n",
      "Epoch 32/60\n",
      "6s - loss: 0.0125 - val_loss: 0.0877\n",
      "Epoch 33/60\n",
      "6s - loss: 0.0125 - val_loss: 0.0906\n",
      "Epoch 34/60\n",
      "6s - loss: 0.0124 - val_loss: 0.0878\n",
      "Epoch 35/60\n",
      "6s - loss: 0.0131 - val_loss: 0.0880\n",
      "Epoch 36/60\n",
      "6s - loss: 0.0116 - val_loss: 0.0901\n",
      "Epoch 37/60\n",
      "6s - loss: 0.0121 - val_loss: 0.0889\n",
      "Epoch 38/60\n",
      "6s - loss: 0.0121 - val_loss: 0.0856\n",
      "Epoch 39/60\n",
      "6s - loss: 0.0125 - val_loss: 0.0865\n",
      "Epoch 40/60\n",
      "6s - loss: 0.0127 - val_loss: 0.0863\n",
      "Epoch 41/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0855\n",
      "Epoch 42/60\n",
      "6s - loss: 0.0121 - val_loss: 0.0860\n",
      "Epoch 43/60\n",
      "6s - loss: 0.0127 - val_loss: 0.0892\n",
      "Epoch 44/60\n",
      "6s - loss: 0.0128 - val_loss: 0.0883\n",
      "Epoch 45/60\n",
      "6s - loss: 0.0126 - val_loss: 0.0848\n",
      "Epoch 46/60\n",
      "6s - loss: 0.0124 - val_loss: 0.0883\n",
      "Epoch 47/60\n",
      "6s - loss: 0.0129 - val_loss: 0.0865\n",
      "Epoch 48/60\n",
      "6s - loss: 0.0122 - val_loss: 0.0874\n",
      "Epoch 49/60\n",
      "6s - loss: 0.0125 - val_loss: 0.0868\n",
      "Epoch 50/60\n",
      "6s - loss: 0.0122 - val_loss: 0.0876\n",
      "Epoch 51/60\n",
      "6s - loss: 0.0121 - val_loss: 0.0890\n",
      "Epoch 52/60\n",
      "6s - loss: 0.0126 - val_loss: 0.0889\n",
      "Epoch 53/60\n",
      "6s - loss: 0.0121 - val_loss: 0.0887\n",
      "Epoch 54/60\n",
      "6s - loss: 0.0126 - val_loss: 0.0892\n",
      "Epoch 55/60\n",
      "7s - loss: 0.0122 - val_loss: 0.0885\n",
      "Epoch 56/60\n",
      "6s - loss: 0.0128 - val_loss: 0.0878\n",
      "Epoch 57/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0881\n",
      "Epoch 58/60\n",
      "6s - loss: 0.0124 - val_loss: 0.0865\n",
      "Epoch 59/60\n",
      "6s - loss: 0.0123 - val_loss: 0.0881\n",
      "Epoch 60/60\n",
      "6s - loss: 0.0123 - val_loss: 0.0876\n",
      "21) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "8s - loss: 0.0129 - val_loss: 0.0858\n",
      "Epoch 2/60\n",
      "10s - loss: 0.0118 - val_loss: 0.0852\n",
      "Epoch 3/60\n",
      "6s - loss: 0.0125 - val_loss: 0.0878\n",
      "Epoch 4/60\n",
      "6s - loss: 0.0121 - val_loss: 0.0871\n",
      "Epoch 5/60\n",
      "6s - loss: 0.0122 - val_loss: 0.0869\n",
      "Epoch 6/60\n",
      "6s - loss: 0.0123 - val_loss: 0.0910\n",
      "Epoch 7/60\n",
      "6s - loss: 0.0117 - val_loss: 0.0850\n",
      "Epoch 8/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0861\n",
      "Epoch 9/60\n",
      "6s - loss: 0.0124 - val_loss: 0.0860\n",
      "Epoch 10/60\n",
      "6s - loss: 0.0117 - val_loss: 0.0874\n",
      "Epoch 11/60\n",
      "6s - loss: 0.0123 - val_loss: 0.0889\n",
      "Epoch 12/60\n",
      "6s - loss: 0.0126 - val_loss: 0.0887\n",
      "Epoch 13/60\n",
      "6s - loss: 0.0122 - val_loss: 0.0860\n",
      "Epoch 14/60\n",
      "6s - loss: 0.0125 - val_loss: 0.0869\n",
      "Epoch 15/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0853\n",
      "Epoch 16/60\n",
      "6s - loss: 0.0126 - val_loss: 0.0882\n",
      "Epoch 17/60\n",
      "6s - loss: 0.0123 - val_loss: 0.0859\n",
      "Epoch 18/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0884\n",
      "Epoch 19/60\n",
      "6s - loss: 0.0125 - val_loss: 0.0846\n",
      "Epoch 20/60\n",
      "6s - loss: 0.0120 - val_loss: 0.0882\n",
      "Epoch 21/60\n",
      "6s - loss: 0.0124 - val_loss: 0.0875\n",
      "Epoch 22/60\n",
      "6s - loss: 0.0124 - val_loss: 0.0889\n",
      "Epoch 23/60\n",
      "6s - loss: 0.0122 - val_loss: 0.0867\n",
      "Epoch 24/60\n",
      "6s - loss: 0.0120 - val_loss: 0.0871\n",
      "Epoch 25/60\n",
      "6s - loss: 0.0123 - val_loss: 0.0906\n",
      "Epoch 26/60\n",
      "6s - loss: 0.0121 - val_loss: 0.0875\n",
      "Epoch 27/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0867\n",
      "Epoch 28/60\n",
      "6s - loss: 0.0122 - val_loss: 0.0842\n",
      "Epoch 29/60\n",
      "6s - loss: 0.0128 - val_loss: 0.0863\n",
      "Epoch 30/60\n",
      "6s - loss: 0.0116 - val_loss: 0.0875\n",
      "Epoch 31/60\n",
      "6s - loss: 0.0123 - val_loss: 0.0858\n",
      "Epoch 32/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0866\n",
      "Epoch 33/60\n",
      "6s - loss: 0.0121 - val_loss: 0.0846\n",
      "Epoch 34/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0870\n",
      "Epoch 35/60\n",
      "6s - loss: 0.0121 - val_loss: 0.0857\n",
      "Epoch 36/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0849\n",
      "Epoch 37/60\n",
      "6s - loss: 0.0121 - val_loss: 0.0863\n",
      "Epoch 38/60\n",
      "6s - loss: 0.0120 - val_loss: 0.0856\n",
      "Epoch 39/60\n",
      "6s - loss: 0.0116 - val_loss: 0.0851\n",
      "Epoch 40/60\n",
      "6s - loss: 0.0123 - val_loss: 0.0863\n",
      "Epoch 41/60\n",
      "6s - loss: 0.0117 - val_loss: 0.0864\n",
      "Epoch 42/60\n",
      "6s - loss: 0.0120 - val_loss: 0.0858\n",
      "Epoch 43/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0849\n",
      "Epoch 44/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0897\n",
      "Epoch 45/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0872\n",
      "Epoch 46/60\n",
      "6s - loss: 0.0114 - val_loss: 0.0888\n",
      "Epoch 47/60\n",
      "6s - loss: 0.0122 - val_loss: 0.0880\n",
      "Epoch 48/60\n",
      "6s - loss: 0.0120 - val_loss: 0.0886\n",
      "Epoch 49/60\n",
      "6s - loss: 0.0121 - val_loss: 0.0887\n",
      "Epoch 50/60\n",
      "6s - loss: 0.0120 - val_loss: 0.0874\n",
      "Epoch 51/60\n",
      "6s - loss: 0.0120 - val_loss: 0.0871\n",
      "Epoch 52/60\n",
      "6s - loss: 0.0122 - val_loss: 0.0869\n",
      "Epoch 53/60\n",
      "6s - loss: 0.0121 - val_loss: 0.0894\n",
      "Epoch 54/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0877\n",
      "Epoch 55/60\n",
      "6s - loss: 0.0122 - val_loss: 0.0854\n",
      "Epoch 56/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0853\n",
      "Epoch 57/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0860\n",
      "Epoch 58/60\n",
      "6s - loss: 0.0116 - val_loss: 0.0874\n",
      "Epoch 59/60\n",
      "6s - loss: 0.0123 - val_loss: 0.0864\n",
      "Epoch 60/60\n",
      "6s - loss: 0.0124 - val_loss: 0.0868\n",
      "22) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0864\n",
      "Epoch 2/60\n",
      "6s - loss: 0.0117 - val_loss: 0.0855\n",
      "Epoch 3/60\n",
      "6s - loss: 0.0120 - val_loss: 0.0901\n",
      "Epoch 4/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0913\n",
      "Epoch 5/60\n",
      "6s - loss: 0.0123 - val_loss: 0.0861\n",
      "Epoch 6/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0863\n",
      "Epoch 7/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0866\n",
      "Epoch 8/60\n",
      "6s - loss: 0.0121 - val_loss: 0.0903\n",
      "Epoch 9/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0863\n",
      "Epoch 10/60\n",
      "6s - loss: 0.0117 - val_loss: 0.0839\n",
      "Epoch 11/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0880\n",
      "Epoch 12/60\n",
      "6s - loss: 0.0123 - val_loss: 0.0852\n",
      "Epoch 13/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0905\n",
      "Epoch 14/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0873\n",
      "Epoch 15/60\n",
      "6s - loss: 0.0121 - val_loss: 0.0868\n",
      "Epoch 16/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0874\n",
      "Epoch 17/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0918\n",
      "Epoch 18/60\n",
      "6s - loss: 0.0125 - val_loss: 0.0893\n",
      "Epoch 19/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0860\n",
      "Epoch 20/60\n",
      "6s - loss: 0.0111 - val_loss: 0.0900\n",
      "Epoch 21/60\n",
      "6s - loss: 0.0123 - val_loss: 0.0878\n",
      "Epoch 22/60\n",
      "6s - loss: 0.0121 - val_loss: 0.0878\n",
      "Epoch 23/60\n",
      "6s - loss: 0.0117 - val_loss: 0.0876\n",
      "Epoch 24/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0877\n",
      "Epoch 25/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0866\n",
      "Epoch 26/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0889\n",
      "Epoch 27/60\n",
      "6s - loss: 0.0113 - val_loss: 0.0879\n",
      "Epoch 28/60\n",
      "6s - loss: 0.0117 - val_loss: 0.0865\n",
      "Epoch 29/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0880\n",
      "Epoch 30/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0867\n",
      "Epoch 31/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0870\n",
      "Epoch 32/60\n",
      "6s - loss: 0.0120 - val_loss: 0.0842\n",
      "Epoch 33/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0853\n",
      "Epoch 34/60\n",
      "6s - loss: 0.0117 - val_loss: 0.0883\n",
      "Epoch 35/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0879\n",
      "Epoch 36/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0825\n",
      "Epoch 37/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0867\n",
      "Epoch 38/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0853\n",
      "Epoch 39/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0898\n",
      "Epoch 40/60\n",
      "6s - loss: 0.0114 - val_loss: 0.0837\n",
      "Epoch 41/60\n",
      "6s - loss: 0.0115 - val_loss: 0.0868\n",
      "Epoch 42/60\n",
      "6s - loss: 0.0120 - val_loss: 0.0904\n",
      "Epoch 43/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0880\n",
      "Epoch 44/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0890\n",
      "Epoch 45/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0871\n",
      "Epoch 46/60\n",
      "6s - loss: 0.0116 - val_loss: 0.0875\n",
      "Epoch 47/60\n",
      "6s - loss: 0.0122 - val_loss: 0.0893\n",
      "Epoch 48/60\n",
      "6s - loss: 0.0115 - val_loss: 0.0883\n",
      "Epoch 49/60\n",
      "6s - loss: 0.0120 - val_loss: 0.0856\n",
      "Epoch 50/60\n",
      "6s - loss: 0.0116 - val_loss: 0.0884\n",
      "Epoch 51/60\n",
      "6s - loss: 0.0114 - val_loss: 0.0887\n",
      "Epoch 52/60\n",
      "6s - loss: 0.0115 - val_loss: 0.0871\n",
      "Epoch 53/60\n",
      "6s - loss: 0.0116 - val_loss: 0.0896\n",
      "Epoch 54/60\n",
      "9s - loss: 0.0120 - val_loss: 0.0857\n",
      "Epoch 55/60\n",
      "3s - loss: 0.0116 - val_loss: 0.0852\n",
      "Epoch 56/60\n",
      "6s - loss: 0.0114 - val_loss: 0.0873\n",
      "Epoch 57/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0894\n",
      "Epoch 58/60\n",
      "6s - loss: 0.0117 - val_loss: 0.0882\n",
      "Epoch 59/60\n",
      "6s - loss: 0.0115 - val_loss: 0.0906\n",
      "Epoch 60/60\n",
      "6s - loss: 0.0120 - val_loss: 0.0859\n",
      "23) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "6s - loss: 0.0111 - val_loss: 0.0887\n",
      "Epoch 2/60\n",
      "6s - loss: 0.0115 - val_loss: 0.0884\n",
      "Epoch 3/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0895\n",
      "Epoch 4/60\n",
      "6s - loss: 0.0116 - val_loss: 0.0901\n",
      "Epoch 5/60\n",
      "6s - loss: 0.0115 - val_loss: 0.0898\n",
      "Epoch 6/60\n",
      "6s - loss: 0.0120 - val_loss: 0.0858\n",
      "Epoch 7/60\n",
      "6s - loss: 0.0117 - val_loss: 0.0850\n",
      "Epoch 8/60\n",
      "6s - loss: 0.0113 - val_loss: 0.0888\n",
      "Epoch 9/60\n",
      "6s - loss: 0.0113 - val_loss: 0.0858\n",
      "Epoch 10/60\n",
      "6s - loss: 0.0116 - val_loss: 0.0826\n",
      "Epoch 11/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0881\n",
      "Epoch 12/60\n",
      "6s - loss: 0.0116 - val_loss: 0.0847\n",
      "Epoch 13/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0839\n",
      "Epoch 14/60\n",
      "6s - loss: 0.0114 - val_loss: 0.0857\n",
      "Epoch 15/60\n",
      "6s - loss: 0.0116 - val_loss: 0.0874\n",
      "Epoch 16/60\n",
      "6s - loss: 0.0111 - val_loss: 0.0887\n",
      "Epoch 17/60\n",
      "7s - loss: 0.0122 - val_loss: 0.0872\n",
      "Epoch 18/60\n",
      "6s - loss: 0.0115 - val_loss: 0.0850\n",
      "Epoch 19/60\n",
      "6s - loss: 0.0113 - val_loss: 0.0874\n",
      "Epoch 20/60\n",
      "6s - loss: 0.0116 - val_loss: 0.0872\n",
      "Epoch 21/60\n",
      "6s - loss: 0.0111 - val_loss: 0.0864\n",
      "Epoch 22/60\n",
      "6s - loss: 0.0112 - val_loss: 0.0849\n",
      "Epoch 23/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0876\n",
      "Epoch 24/60\n",
      "6s - loss: 0.0114 - val_loss: 0.0885\n",
      "Epoch 25/60\n",
      "6s - loss: 0.0115 - val_loss: 0.0867\n",
      "Epoch 26/60\n",
      "6s - loss: 0.0115 - val_loss: 0.0880\n",
      "Epoch 27/60\n",
      "6s - loss: 0.0116 - val_loss: 0.0850\n",
      "Epoch 28/60\n",
      "6s - loss: 0.0115 - val_loss: 0.0865\n",
      "Epoch 29/60\n",
      "6s - loss: 0.0117 - val_loss: 0.0864\n",
      "Epoch 30/60\n",
      "6s - loss: 0.0112 - val_loss: 0.0896\n",
      "Epoch 31/60\n",
      "6s - loss: 0.0116 - val_loss: 0.0873\n",
      "Epoch 32/60\n",
      "6s - loss: 0.0115 - val_loss: 0.0904\n",
      "Epoch 33/60\n",
      "6s - loss: 0.0115 - val_loss: 0.0862\n",
      "Epoch 34/60\n",
      "6s - loss: 0.0116 - val_loss: 0.0898\n",
      "Epoch 35/60\n",
      "6s - loss: 0.0113 - val_loss: 0.0890\n",
      "Epoch 36/60\n",
      "6s - loss: 0.0116 - val_loss: 0.0893\n",
      "Epoch 37/60\n",
      "6s - loss: 0.0120 - val_loss: 0.0900\n",
      "Epoch 38/60\n",
      "6s - loss: 0.0116 - val_loss: 0.0883\n",
      "Epoch 39/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0906\n",
      "Epoch 40/60\n",
      "6s - loss: 0.0116 - val_loss: 0.0873\n",
      "Epoch 41/60\n",
      "6s - loss: 0.0114 - val_loss: 0.0874\n",
      "Epoch 42/60\n",
      "6s - loss: 0.0116 - val_loss: 0.0869\n",
      "Epoch 43/60\n",
      "6s - loss: 0.0117 - val_loss: 0.0901\n",
      "Epoch 44/60\n",
      "6s - loss: 0.0112 - val_loss: 0.0873\n",
      "Epoch 45/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0839\n",
      "Epoch 46/60\n",
      "6s - loss: 0.0112 - val_loss: 0.0881\n",
      "Epoch 47/60\n",
      "6s - loss: 0.0112 - val_loss: 0.0880\n",
      "Epoch 48/60\n",
      "6s - loss: 0.0115 - val_loss: 0.0870\n",
      "Epoch 49/60\n",
      "6s - loss: 0.0114 - val_loss: 0.0858\n",
      "Epoch 50/60\n",
      "6s - loss: 0.0115 - val_loss: 0.0858\n",
      "Epoch 51/60\n",
      "6s - loss: 0.0112 - val_loss: 0.0874\n",
      "Epoch 52/60\n",
      "6s - loss: 0.0114 - val_loss: 0.0864\n",
      "Epoch 53/60\n",
      "6s - loss: 0.0113 - val_loss: 0.0848\n",
      "Epoch 54/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0873\n",
      "Epoch 55/60\n",
      "6s - loss: 0.0111 - val_loss: 0.0843\n",
      "Epoch 56/60\n",
      "6s - loss: 0.0116 - val_loss: 0.0867\n",
      "Epoch 57/60\n",
      "6s - loss: 0.0112 - val_loss: 0.0883\n",
      "Epoch 58/60\n",
      "6s - loss: 0.0115 - val_loss: 0.0855\n",
      "Epoch 59/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0845\n",
      "Epoch 60/60\n",
      "6s - loss: 0.0111 - val_loss: 0.0855\n",
      "24) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "6s - loss: 0.0113 - val_loss: 0.0885\n",
      "Epoch 2/60\n",
      "6s - loss: 0.0110 - val_loss: 0.0888\n",
      "Epoch 3/60\n",
      "6s - loss: 0.0112 - val_loss: 0.0889\n",
      "Epoch 4/60\n",
      "6s - loss: 0.0114 - val_loss: 0.0861\n",
      "Epoch 5/60\n",
      "6s - loss: 0.0116 - val_loss: 0.0840\n",
      "Epoch 6/60\n",
      "6s - loss: 0.0115 - val_loss: 0.0849\n",
      "Epoch 7/60\n",
      "6s - loss: 0.0110 - val_loss: 0.0866\n",
      "Epoch 8/60\n",
      "6s - loss: 0.0115 - val_loss: 0.0849\n",
      "Epoch 9/60\n",
      "6s - loss: 0.0111 - val_loss: 0.0862\n",
      "Epoch 10/60\n",
      "7s - loss: 0.0111 - val_loss: 0.0878\n",
      "Epoch 11/60\n",
      "6s - loss: 0.0110 - val_loss: 0.0858\n",
      "Epoch 12/60\n",
      "6s - loss: 0.0114 - val_loss: 0.0857\n",
      "Epoch 13/60\n",
      "6s - loss: 0.0115 - val_loss: 0.0869\n",
      "Epoch 14/60\n",
      "6s - loss: 0.0113 - val_loss: 0.0877\n",
      "Epoch 15/60\n",
      "6s - loss: 0.0113 - val_loss: 0.0833\n",
      "Epoch 16/60\n",
      "6s - loss: 0.0108 - val_loss: 0.0874\n",
      "Epoch 17/60\n",
      "6s - loss: 0.0117 - val_loss: 0.0889\n",
      "Epoch 18/60\n",
      "6s - loss: 0.0111 - val_loss: 0.0849\n",
      "Epoch 19/60\n",
      "6s - loss: 0.0114 - val_loss: 0.0869\n",
      "Epoch 20/60\n",
      "6s - loss: 0.0113 - val_loss: 0.0880\n",
      "Epoch 21/60\n",
      "6s - loss: 0.0110 - val_loss: 0.0867\n",
      "Epoch 22/60\n",
      "7s - loss: 0.0113 - val_loss: 0.0878\n",
      "Epoch 23/60\n",
      "6s - loss: 0.0115 - val_loss: 0.0846\n",
      "Epoch 24/60\n",
      "6s - loss: 0.0115 - val_loss: 0.0868\n",
      "Epoch 25/60\n",
      "6s - loss: 0.0113 - val_loss: 0.0842\n",
      "Epoch 26/60\n",
      "6s - loss: 0.0112 - val_loss: 0.0837\n",
      "Epoch 27/60\n",
      "6s - loss: 0.0115 - val_loss: 0.0838\n",
      "Epoch 28/60\n",
      "6s - loss: 0.0109 - val_loss: 0.0856\n",
      "Epoch 29/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0830\n",
      "Epoch 30/60\n",
      "6s - loss: 0.0116 - val_loss: 0.0854\n",
      "Epoch 31/60\n",
      "6s - loss: 0.0113 - val_loss: 0.0880\n",
      "Epoch 32/60\n",
      "6s - loss: 0.0115 - val_loss: 0.0839\n",
      "Epoch 33/60\n",
      "6s - loss: 0.0111 - val_loss: 0.0853\n",
      "Epoch 34/60\n",
      "6s - loss: 0.0111 - val_loss: 0.0854\n",
      "Epoch 35/60\n",
      "6s - loss: 0.0113 - val_loss: 0.0873\n",
      "Epoch 36/60\n",
      "6s - loss: 0.0110 - val_loss: 0.0875\n",
      "Epoch 37/60\n",
      "6s - loss: 0.0112 - val_loss: 0.0876\n",
      "Epoch 38/60\n",
      "6s - loss: 0.0110 - val_loss: 0.0886\n",
      "Epoch 39/60\n",
      "6s - loss: 0.0112 - val_loss: 0.0853\n",
      "Epoch 40/60\n",
      "6s - loss: 0.0112 - val_loss: 0.0858\n",
      "Epoch 41/60\n",
      "6s - loss: 0.0112 - val_loss: 0.0844\n",
      "Epoch 42/60\n",
      "6s - loss: 0.0115 - val_loss: 0.0851\n",
      "Epoch 43/60\n",
      "6s - loss: 0.0111 - val_loss: 0.0863\n",
      "Epoch 44/60\n",
      "6s - loss: 0.0113 - val_loss: 0.0840\n",
      "Epoch 45/60\n",
      "6s - loss: 0.0114 - val_loss: 0.0895\n",
      "Epoch 46/60\n",
      "6s - loss: 0.0110 - val_loss: 0.0864\n",
      "Epoch 47/60\n",
      "6s - loss: 0.0111 - val_loss: 0.0857\n",
      "Epoch 48/60\n",
      "6s - loss: 0.0109 - val_loss: 0.0839\n",
      "Epoch 49/60\n",
      "6s - loss: 0.0114 - val_loss: 0.0865\n",
      "Epoch 50/60\n",
      "6s - loss: 0.0112 - val_loss: 0.0863\n",
      "Epoch 51/60\n",
      "6s - loss: 0.0119 - val_loss: 0.0860\n",
      "Epoch 52/60\n",
      "7s - loss: 0.0111 - val_loss: 0.0867\n",
      "Epoch 53/60\n",
      "6s - loss: 0.0108 - val_loss: 0.0878\n",
      "Epoch 54/60\n",
      "6s - loss: 0.0111 - val_loss: 0.0841\n",
      "Epoch 55/60\n",
      "6s - loss: 0.0114 - val_loss: 0.0863\n",
      "Epoch 56/60\n",
      "6s - loss: 0.0114 - val_loss: 0.0836\n",
      "Epoch 57/60\n",
      "6s - loss: 0.0112 - val_loss: 0.0847\n",
      "Epoch 58/60\n",
      "6s - loss: 0.0110 - val_loss: 0.0870\n",
      "Epoch 59/60\n",
      "6s - loss: 0.0113 - val_loss: 0.0827\n",
      "Epoch 60/60\n",
      "6s - loss: 0.0114 - val_loss: 0.0846\n",
      "25) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "6s - loss: 0.0115 - val_loss: 0.0862\n",
      "Epoch 2/60\n",
      "6s - loss: 0.0118 - val_loss: 0.0834\n",
      "Epoch 3/60\n",
      "6s - loss: 0.0110 - val_loss: 0.0847\n",
      "Epoch 4/60\n",
      "6s - loss: 0.0109 - val_loss: 0.0853\n",
      "Epoch 5/60\n",
      "6s - loss: 0.0112 - val_loss: 0.0842\n",
      "Epoch 6/60\n",
      "6s - loss: 0.0112 - val_loss: 0.0845\n",
      "Epoch 7/60\n",
      "6s - loss: 0.0111 - val_loss: 0.0828\n",
      "Epoch 8/60\n",
      "6s - loss: 0.0106 - val_loss: 0.0850\n",
      "Epoch 9/60\n",
      "7s - loss: 0.0108 - val_loss: 0.0834\n",
      "Epoch 10/60\n",
      "1341s - loss: 0.0117 - val_loss: 0.0853\n",
      "Epoch 11/60\n",
      "15s - loss: 0.0115 - val_loss: 0.0853\n",
      "Epoch 12/60\n",
      "12s - loss: 0.0114 - val_loss: 0.0854\n",
      "Epoch 13/60\n",
      "8s - loss: 0.0111 - val_loss: 0.0868\n",
      "Epoch 14/60\n",
      "6s - loss: 0.0111 - val_loss: 0.0880\n",
      "Epoch 15/60\n",
      "6s - loss: 0.0113 - val_loss: 0.0883\n",
      "Epoch 16/60\n",
      "5s - loss: 0.0107 - val_loss: 0.0861\n",
      "Epoch 17/60\n",
      "10s - loss: 0.0113 - val_loss: 0.0881\n",
      "Epoch 18/60\n",
      "11s - loss: 0.0112 - val_loss: 0.0874\n",
      "Epoch 19/60\n",
      "11s - loss: 0.0114 - val_loss: 0.0846\n",
      "Epoch 20/60\n",
      "8s - loss: 0.0113 - val_loss: 0.0858\n",
      "Epoch 21/60\n",
      "8s - loss: 0.0108 - val_loss: 0.0848\n",
      "Epoch 22/60\n",
      "8s - loss: 0.0113 - val_loss: 0.0833\n",
      "Epoch 23/60\n",
      "7s - loss: 0.0110 - val_loss: 0.0867\n",
      "Epoch 24/60\n",
      "8s - loss: 0.0110 - val_loss: 0.0897\n",
      "Epoch 25/60\n",
      "9s - loss: 0.0115 - val_loss: 0.0857\n",
      "Epoch 26/60\n",
      "13s - loss: 0.0111 - val_loss: 0.0858\n",
      "Epoch 27/60\n",
      "12s - loss: 0.0114 - val_loss: 0.0909\n",
      "Epoch 28/60\n",
      "11s - loss: 0.0109 - val_loss: 0.0887\n",
      "Epoch 29/60\n",
      "9s - loss: 0.0111 - val_loss: 0.0862\n",
      "Epoch 30/60\n",
      "10s - loss: 0.0111 - val_loss: 0.0829\n",
      "Epoch 31/60\n",
      "7s - loss: 0.0109 - val_loss: 0.0896\n",
      "Epoch 32/60\n",
      "9s - loss: 0.0110 - val_loss: 0.0844\n",
      "Epoch 33/60\n",
      "8s - loss: 0.0113 - val_loss: 0.0856\n",
      "Epoch 34/60\n",
      "9s - loss: 0.0114 - val_loss: 0.0876\n",
      "Epoch 35/60\n",
      "6s - loss: 0.0107 - val_loss: 0.0873\n",
      "Epoch 36/60\n",
      "8s - loss: 0.0110 - val_loss: 0.0871\n",
      "Epoch 37/60\n",
      "8s - loss: 0.0108 - val_loss: 0.0828\n",
      "Epoch 38/60\n",
      "7s - loss: 0.0110 - val_loss: 0.0869\n",
      "Epoch 39/60\n",
      "7s - loss: 0.0111 - val_loss: 0.0897\n",
      "Epoch 40/60\n",
      "9s - loss: 0.0112 - val_loss: 0.0852\n",
      "Epoch 41/60\n",
      "17s - loss: 0.0108 - val_loss: 0.0872\n",
      "Epoch 42/60\n",
      "8s - loss: 0.0113 - val_loss: 0.0884\n",
      "Epoch 43/60\n",
      "11s - loss: 0.0113 - val_loss: 0.0845\n",
      "Epoch 44/60\n",
      "10s - loss: 0.0112 - val_loss: 0.0844\n",
      "Epoch 45/60\n",
      "8s - loss: 0.0113 - val_loss: 0.0872\n",
      "Epoch 46/60\n",
      "8s - loss: 0.0106 - val_loss: 0.0862\n",
      "Epoch 47/60\n",
      "8s - loss: 0.0109 - val_loss: 0.0867\n",
      "Epoch 48/60\n",
      "8s - loss: 0.0109 - val_loss: 0.0831\n",
      "Epoch 49/60\n",
      "8s - loss: 0.0108 - val_loss: 0.0837\n",
      "Epoch 50/60\n",
      "8s - loss: 0.0110 - val_loss: 0.0828\n",
      "Epoch 51/60\n",
      "6s - loss: 0.0112 - val_loss: 0.0871\n",
      "Epoch 52/60\n",
      "7s - loss: 0.0113 - val_loss: 0.0860\n",
      "Epoch 53/60\n",
      "7s - loss: 0.0111 - val_loss: 0.0841\n",
      "Epoch 54/60\n",
      "7s - loss: 0.0109 - val_loss: 0.0829\n",
      "Epoch 55/60\n",
      "7s - loss: 0.0108 - val_loss: 0.0858\n",
      "Epoch 56/60\n",
      "8s - loss: 0.0108 - val_loss: 0.0857\n",
      "Epoch 57/60\n",
      "7s - loss: 0.0109 - val_loss: 0.0848\n",
      "Epoch 58/60\n",
      "7s - loss: 0.0108 - val_loss: 0.0845\n",
      "Epoch 59/60\n",
      "7s - loss: 0.0110 - val_loss: 0.0834\n",
      "Epoch 60/60\n",
      "7s - loss: 0.0109 - val_loss: 0.0847\n",
      "26) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "7s - loss: 0.0105 - val_loss: 0.0826\n",
      "Epoch 2/60\n",
      "6s - loss: 0.0114 - val_loss: 0.0853\n",
      "Epoch 3/60\n",
      "8s - loss: 0.0105 - val_loss: 0.0865\n",
      "Epoch 4/60\n",
      "10s - loss: 0.0111 - val_loss: 0.0843\n",
      "Epoch 5/60\n",
      "8s - loss: 0.0108 - val_loss: 0.0829\n",
      "Epoch 6/60\n",
      "8s - loss: 0.0106 - val_loss: 0.0836\n",
      "Epoch 7/60\n",
      "6s - loss: 0.0104 - val_loss: 0.0874\n",
      "Epoch 8/60\n",
      "7s - loss: 0.0111 - val_loss: 0.0849\n",
      "Epoch 9/60\n",
      "7s - loss: 0.0109 - val_loss: 0.0834\n",
      "Epoch 10/60\n",
      "7s - loss: 0.0109 - val_loss: 0.0848\n",
      "Epoch 11/60\n",
      "7s - loss: 0.0105 - val_loss: 0.0859\n",
      "Epoch 12/60\n",
      "7s - loss: 0.0108 - val_loss: 0.0837\n",
      "Epoch 13/60\n",
      "7s - loss: 0.0109 - val_loss: 0.0845\n",
      "Epoch 14/60\n",
      "7s - loss: 0.0111 - val_loss: 0.0837\n",
      "Epoch 15/60\n",
      "7s - loss: 0.0111 - val_loss: 0.0840\n",
      "Epoch 16/60\n",
      "7s - loss: 0.0110 - val_loss: 0.0855\n",
      "Epoch 17/60\n",
      "7s - loss: 0.0109 - val_loss: 0.0848\n",
      "Epoch 18/60\n",
      "9s - loss: 0.0108 - val_loss: 0.0858\n",
      "Epoch 19/60\n",
      "5s - loss: 0.0111 - val_loss: 0.0837\n",
      "Epoch 20/60\n",
      "6s - loss: 0.0112 - val_loss: 0.0839\n",
      "Epoch 21/60\n",
      "6s - loss: 0.0107 - val_loss: 0.0867\n",
      "Epoch 22/60\n",
      "6s - loss: 0.0107 - val_loss: 0.0860\n",
      "Epoch 23/60\n",
      "7s - loss: 0.0111 - val_loss: 0.0866\n",
      "Epoch 24/60\n",
      "7s - loss: 0.0114 - val_loss: 0.0854\n",
      "Epoch 25/60\n",
      "6s - loss: 0.0109 - val_loss: 0.0850\n",
      "Epoch 26/60\n",
      "12s - loss: 0.0108 - val_loss: 0.0869\n",
      "Epoch 27/60\n",
      "6s - loss: 0.0110 - val_loss: 0.0885\n",
      "Epoch 28/60\n",
      "6s - loss: 0.0110 - val_loss: 0.0843\n",
      "Epoch 29/60\n",
      "8s - loss: 0.0108 - val_loss: 0.0836\n",
      "Epoch 30/60\n",
      "9s - loss: 0.0110 - val_loss: 0.0851\n",
      "Epoch 31/60\n",
      "7s - loss: 0.0108 - val_loss: 0.0845\n",
      "Epoch 32/60\n",
      "7s - loss: 0.0109 - val_loss: 0.0861\n",
      "Epoch 33/60\n",
      "7s - loss: 0.0107 - val_loss: 0.0846\n",
      "Epoch 34/60\n",
      "7s - loss: 0.0112 - val_loss: 0.0871\n",
      "Epoch 35/60\n",
      "7s - loss: 0.0109 - val_loss: 0.0850\n",
      "Epoch 36/60\n",
      "6s - loss: 0.0107 - val_loss: 0.0838\n",
      "Epoch 37/60\n",
      "7s - loss: 0.0108 - val_loss: 0.0831\n",
      "Epoch 38/60\n",
      "7s - loss: 0.0102 - val_loss: 0.0833\n",
      "Epoch 39/60\n",
      "9s - loss: 0.0109 - val_loss: 0.0846\n",
      "Epoch 40/60\n",
      "14s - loss: 0.0106 - val_loss: 0.0824\n",
      "Epoch 41/60\n",
      "8s - loss: 0.0106 - val_loss: 0.0837\n",
      "Epoch 42/60\n",
      "12s - loss: 0.0109 - val_loss: 0.0841\n",
      "Epoch 43/60\n",
      "9s - loss: 0.0107 - val_loss: 0.0814\n",
      "Epoch 44/60\n",
      "10s - loss: 0.0109 - val_loss: 0.0847\n",
      "Epoch 45/60\n",
      "10s - loss: 0.0104 - val_loss: 0.0836\n",
      "Epoch 46/60\n",
      "7s - loss: 0.0108 - val_loss: 0.0865\n",
      "Epoch 47/60\n",
      "9s - loss: 0.0106 - val_loss: 0.0864\n",
      "Epoch 48/60\n",
      "7s - loss: 0.0110 - val_loss: 0.0815\n",
      "Epoch 49/60\n",
      "7s - loss: 0.0110 - val_loss: 0.0846\n",
      "Epoch 50/60\n",
      "6s - loss: 0.0112 - val_loss: 0.0835\n",
      "Epoch 51/60\n",
      "7s - loss: 0.0108 - val_loss: 0.0859\n",
      "Epoch 52/60\n",
      "6s - loss: 0.0108 - val_loss: 0.0845\n",
      "Epoch 53/60\n",
      "7s - loss: 0.0110 - val_loss: 0.0836\n",
      "Epoch 54/60\n",
      "7s - loss: 0.0106 - val_loss: 0.0858\n",
      "Epoch 55/60\n",
      "7s - loss: 0.0107 - val_loss: 0.0884\n",
      "Epoch 56/60\n",
      "7s - loss: 0.0104 - val_loss: 0.0839\n",
      "Epoch 57/60\n",
      "7s - loss: 0.0108 - val_loss: 0.0859\n",
      "Epoch 58/60\n",
      "9s - loss: 0.0107 - val_loss: 0.0847\n",
      "Epoch 59/60\n",
      "8s - loss: 0.0100 - val_loss: 0.0836\n",
      "Epoch 60/60\n",
      "8s - loss: 0.0104 - val_loss: 0.0847\n",
      "27) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "7s - loss: 0.0110 - val_loss: 0.0840\n",
      "Epoch 2/60\n",
      "8s - loss: 0.0109 - val_loss: 0.0840\n",
      "Epoch 3/60\n",
      "7s - loss: 0.0104 - val_loss: 0.0843\n",
      "Epoch 4/60\n",
      "7s - loss: 0.0107 - val_loss: 0.0832\n",
      "Epoch 5/60\n",
      "8s - loss: 0.0107 - val_loss: 0.0829\n",
      "Epoch 6/60\n",
      "7s - loss: 0.0103 - val_loss: 0.0848\n",
      "Epoch 7/60\n",
      "7s - loss: 0.0112 - val_loss: 0.0841\n",
      "Epoch 8/60\n",
      "7s - loss: 0.0109 - val_loss: 0.0853\n",
      "Epoch 9/60\n",
      "7s - loss: 0.0107 - val_loss: 0.0855\n",
      "Epoch 10/60\n",
      "7s - loss: 0.0105 - val_loss: 0.0829\n",
      "Epoch 11/60\n",
      "8s - loss: 0.0107 - val_loss: 0.0857\n",
      "Epoch 12/60\n",
      "7s - loss: 0.0106 - val_loss: 0.0861\n",
      "Epoch 13/60\n",
      "12s - loss: 0.0106 - val_loss: 0.0844\n",
      "Epoch 14/60\n",
      "8s - loss: 0.0106 - val_loss: 0.0851\n",
      "Epoch 15/60\n",
      "8s - loss: 0.0106 - val_loss: 0.0828\n",
      "Epoch 16/60\n",
      "8s - loss: 0.0106 - val_loss: 0.0833\n",
      "Epoch 17/60\n",
      "9s - loss: 0.0104 - val_loss: 0.0854\n",
      "Epoch 18/60\n",
      "8s - loss: 0.0110 - val_loss: 0.0812\n",
      "Epoch 19/60\n",
      "8s - loss: 0.0105 - val_loss: 0.0858\n",
      "Epoch 20/60\n",
      "7s - loss: 0.0106 - val_loss: 0.0860\n",
      "Epoch 21/60\n",
      "7s - loss: 0.0105 - val_loss: 0.0842\n",
      "Epoch 22/60\n",
      "7s - loss: 0.0108 - val_loss: 0.0850\n",
      "Epoch 23/60\n",
      "7s - loss: 0.0106 - val_loss: 0.0842\n",
      "Epoch 24/60\n",
      "8s - loss: 0.0111 - val_loss: 0.0848\n",
      "Epoch 25/60\n",
      "9s - loss: 0.0107 - val_loss: 0.0831\n",
      "Epoch 26/60\n",
      "7s - loss: 0.0105 - val_loss: 0.0841\n",
      "Epoch 27/60\n",
      "9s - loss: 0.0105 - val_loss: 0.0848\n",
      "Epoch 28/60\n",
      "8s - loss: 0.0104 - val_loss: 0.0848\n",
      "Epoch 29/60\n",
      "8s - loss: 0.0111 - val_loss: 0.0836\n",
      "Epoch 30/60\n",
      "9s - loss: 0.0108 - val_loss: 0.0834\n",
      "Epoch 31/60\n",
      "8s - loss: 0.0108 - val_loss: 0.0830\n",
      "Epoch 32/60\n",
      "11s - loss: 0.0107 - val_loss: 0.0826\n",
      "Epoch 33/60\n",
      "8s - loss: 0.0105 - val_loss: 0.0827\n",
      "Epoch 34/60\n",
      "9s - loss: 0.0107 - val_loss: 0.0837\n",
      "Epoch 35/60\n",
      "7s - loss: 0.0104 - val_loss: 0.0832\n",
      "Epoch 36/60\n",
      "8s - loss: 0.0111 - val_loss: 0.0820\n",
      "Epoch 37/60\n",
      "9s - loss: 0.0102 - val_loss: 0.0838\n",
      "Epoch 38/60\n",
      "7s - loss: 0.0108 - val_loss: 0.0826\n",
      "Epoch 39/60\n",
      "9s - loss: 0.0104 - val_loss: 0.0846\n",
      "Epoch 40/60\n",
      "9s - loss: 0.0108 - val_loss: 0.0832\n",
      "Epoch 41/60\n",
      "7s - loss: 0.0104 - val_loss: 0.0834\n",
      "Epoch 42/60\n",
      "7s - loss: 0.0105 - val_loss: 0.0821\n",
      "Epoch 43/60\n",
      "7s - loss: 0.0107 - val_loss: 0.0858\n",
      "Epoch 44/60\n",
      "7s - loss: 0.0103 - val_loss: 0.0834\n",
      "Epoch 45/60\n",
      "7s - loss: 0.0108 - val_loss: 0.0835\n",
      "Epoch 46/60\n",
      "8s - loss: 0.0105 - val_loss: 0.0834\n",
      "Epoch 47/60\n",
      "8s - loss: 0.0103 - val_loss: 0.0829\n",
      "Epoch 48/60\n",
      "7s - loss: 0.0102 - val_loss: 0.0839\n",
      "Epoch 49/60\n",
      "7s - loss: 0.0110 - val_loss: 0.0837\n",
      "Epoch 50/60\n",
      "8s - loss: 0.0110 - val_loss: 0.0835\n",
      "Epoch 51/60\n",
      "6s - loss: 0.0108 - val_loss: 0.0855\n",
      "Epoch 52/60\n",
      "7s - loss: 0.0106 - val_loss: 0.0843\n",
      "Epoch 53/60\n",
      "11s - loss: 0.0103 - val_loss: 0.0812\n",
      "Epoch 54/60\n",
      "7s - loss: 0.0105 - val_loss: 0.0829\n",
      "Epoch 55/60\n",
      "9s - loss: 0.0102 - val_loss: 0.0847\n",
      "Epoch 56/60\n",
      "7s - loss: 0.0107 - val_loss: 0.0836\n",
      "Epoch 57/60\n",
      "6s - loss: 0.0105 - val_loss: 0.0859\n",
      "Epoch 58/60\n",
      "6s - loss: 0.0103 - val_loss: 0.0848\n",
      "Epoch 59/60\n",
      "6s - loss: 0.0104 - val_loss: 0.0838\n",
      "Epoch 60/60\n",
      "7s - loss: 0.0104 - val_loss: 0.0841\n",
      "28) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "7s - loss: 0.0108 - val_loss: 0.0833\n",
      "Epoch 2/60\n",
      "6s - loss: 0.0104 - val_loss: 0.0838\n",
      "Epoch 3/60\n",
      "6s - loss: 0.0103 - val_loss: 0.0844\n",
      "Epoch 4/60\n",
      "6s - loss: 0.0104 - val_loss: 0.0840\n",
      "Epoch 5/60\n",
      "6s - loss: 0.0105 - val_loss: 0.0824\n",
      "Epoch 6/60\n",
      "6s - loss: 0.0106 - val_loss: 0.0818\n",
      "Epoch 7/60\n",
      "6s - loss: 0.0104 - val_loss: 0.0833\n",
      "Epoch 8/60\n",
      "7s - loss: 0.0106 - val_loss: 0.0861\n",
      "Epoch 9/60\n",
      "6s - loss: 0.0102 - val_loss: 0.0847\n",
      "Epoch 10/60\n",
      "7s - loss: 0.0100 - val_loss: 0.0857\n",
      "Epoch 11/60\n",
      "6s - loss: 0.0105 - val_loss: 0.0839\n",
      "Epoch 12/60\n",
      "6s - loss: 0.0105 - val_loss: 0.0831\n",
      "Epoch 13/60\n",
      "6s - loss: 0.0104 - val_loss: 0.0841\n",
      "Epoch 14/60\n",
      "6s - loss: 0.0104 - val_loss: 0.0832\n",
      "Epoch 15/60\n",
      "7s - loss: 0.0106 - val_loss: 0.0841\n",
      "Epoch 16/60\n",
      "6s - loss: 0.0105 - val_loss: 0.0850\n",
      "Epoch 17/60\n",
      "6s - loss: 0.0102 - val_loss: 0.0841\n",
      "Epoch 18/60\n",
      "6s - loss: 0.0104 - val_loss: 0.0835\n",
      "Epoch 19/60\n",
      "6s - loss: 0.0103 - val_loss: 0.0838\n",
      "Epoch 20/60\n",
      "6s - loss: 0.0109 - val_loss: 0.0842\n",
      "Epoch 21/60\n",
      "6s - loss: 0.0103 - val_loss: 0.0851\n",
      "Epoch 22/60\n",
      "6s - loss: 0.0108 - val_loss: 0.0851\n",
      "Epoch 23/60\n",
      "6s - loss: 0.0103 - val_loss: 0.0848\n",
      "Epoch 24/60\n",
      "6s - loss: 0.0102 - val_loss: 0.0847\n",
      "Epoch 25/60\n",
      "9s - loss: 0.0105 - val_loss: 0.0827\n",
      "Epoch 26/60\n",
      "7s - loss: 0.0102 - val_loss: 0.0841\n",
      "Epoch 27/60\n",
      "6s - loss: 0.0106 - val_loss: 0.0818\n",
      "Epoch 28/60\n",
      "6s - loss: 0.0102 - val_loss: 0.0833\n",
      "Epoch 29/60\n",
      "6s - loss: 0.0106 - val_loss: 0.0826\n",
      "Epoch 30/60\n",
      "6s - loss: 0.0107 - val_loss: 0.0822\n",
      "Epoch 31/60\n",
      "6s - loss: 0.0105 - val_loss: 0.0851\n",
      "Epoch 32/60\n",
      "6s - loss: 0.0101 - val_loss: 0.0835\n",
      "Epoch 33/60\n",
      "7s - loss: 0.0104 - val_loss: 0.0834\n",
      "Epoch 34/60\n",
      "6s - loss: 0.0105 - val_loss: 0.0816\n",
      "Epoch 35/60\n",
      "6s - loss: 0.0108 - val_loss: 0.0827\n",
      "Epoch 36/60\n",
      "6s - loss: 0.0101 - val_loss: 0.0847\n",
      "Epoch 37/60\n",
      "7s - loss: 0.0107 - val_loss: 0.0813\n",
      "Epoch 38/60\n",
      "7s - loss: 0.0103 - val_loss: 0.0812\n",
      "Epoch 39/60\n",
      "6s - loss: 0.0104 - val_loss: 0.0842\n",
      "Epoch 40/60\n",
      "6s - loss: 0.0104 - val_loss: 0.0842\n",
      "Epoch 41/60\n",
      "6s - loss: 0.0105 - val_loss: 0.0837\n",
      "Epoch 42/60\n",
      "6s - loss: 0.0101 - val_loss: 0.0848\n",
      "Epoch 43/60\n",
      "6s - loss: 0.0105 - val_loss: 0.0827\n",
      "Epoch 44/60\n",
      "6s - loss: 0.0102 - val_loss: 0.0835\n",
      "Epoch 45/60\n",
      "7s - loss: 0.0105 - val_loss: 0.0843\n",
      "Epoch 46/60\n",
      "7s - loss: 0.0103 - val_loss: 0.0840\n",
      "Epoch 47/60\n",
      "7s - loss: 0.0105 - val_loss: 0.0829\n",
      "Epoch 48/60\n",
      "6s - loss: 0.0100 - val_loss: 0.0829\n",
      "Epoch 49/60\n",
      "10s - loss: 0.0103 - val_loss: 0.0837\n",
      "Epoch 50/60\n",
      "8s - loss: 0.0102 - val_loss: 0.0814\n",
      "Epoch 51/60\n",
      "9s - loss: 0.0102 - val_loss: 0.0838\n",
      "Epoch 52/60\n",
      "7s - loss: 0.0108 - val_loss: 0.0810\n",
      "Epoch 53/60\n",
      "8s - loss: 0.0103 - val_loss: 0.0813\n",
      "Epoch 54/60\n",
      "7s - loss: 0.0107 - val_loss: 0.0834\n",
      "Epoch 55/60\n",
      "7s - loss: 0.0100 - val_loss: 0.0847\n",
      "Epoch 56/60\n",
      "6s - loss: 0.0103 - val_loss: 0.0819\n",
      "Epoch 57/60\n",
      "7s - loss: 0.0106 - val_loss: 0.0829\n",
      "Epoch 58/60\n",
      "7s - loss: 0.0101 - val_loss: 0.0850\n",
      "Epoch 59/60\n",
      "7s - loss: 0.0103 - val_loss: 0.0837\n",
      "Epoch 60/60\n",
      "7s - loss: 0.0102 - val_loss: 0.0831\n",
      "29) Test RMSE: 0.000\n",
      "Train on 1100 samples, validate on 4396 samples\n",
      "Epoch 1/60\n",
      "7s - loss: 0.0102 - val_loss: 0.0832\n",
      "Epoch 2/60\n",
      "8s - loss: 0.0102 - val_loss: 0.0831\n",
      "Epoch 3/60\n",
      "7s - loss: 0.0108 - val_loss: 0.0821\n",
      "Epoch 4/60\n",
      "7s - loss: 0.0103 - val_loss: 0.0828\n",
      "Epoch 5/60\n",
      "7s - loss: 0.0099 - val_loss: 0.0842\n",
      "Epoch 6/60\n",
      "7s - loss: 0.0106 - val_loss: 0.0845\n",
      "Epoch 7/60\n",
      "7s - loss: 0.0103 - val_loss: 0.0838\n",
      "Epoch 8/60\n",
      "10s - loss: 0.0106 - val_loss: 0.0845\n",
      "Epoch 9/60\n",
      "10s - loss: 0.0101 - val_loss: 0.0844\n",
      "Epoch 10/60\n",
      "10s - loss: 0.0102 - val_loss: 0.0836\n",
      "Epoch 11/60\n",
      "9s - loss: 0.0105 - val_loss: 0.0844\n",
      "Epoch 12/60\n",
      "7s - loss: 0.0104 - val_loss: 0.0859\n",
      "Epoch 13/60\n",
      "6s - loss: 0.0105 - val_loss: 0.0830\n",
      "Epoch 14/60\n",
      "6s - loss: 0.0102 - val_loss: 0.0844\n",
      "Epoch 15/60\n",
      "8s - loss: 0.0103 - val_loss: 0.0826\n",
      "Epoch 16/60\n",
      "6s - loss: 0.0104 - val_loss: 0.0837\n",
      "Epoch 17/60\n",
      "6s - loss: 0.0100 - val_loss: 0.0859\n",
      "Epoch 18/60\n",
      "6s - loss: 0.0110 - val_loss: 0.0844\n",
      "Epoch 19/60\n",
      "6s - loss: 0.0104 - val_loss: 0.0828\n",
      "Epoch 20/60\n",
      "4s - loss: 0.0101 - val_loss: 0.0843\n",
      "Epoch 21/60\n",
      "6s - loss: 0.0105 - val_loss: 0.0831\n",
      "Epoch 22/60\n",
      "6s - loss: 0.0101 - val_loss: 0.0853\n",
      "Epoch 23/60\n",
      "6s - loss: 0.0102 - val_loss: 0.0824\n",
      "Epoch 24/60\n",
      "7s - loss: 0.0104 - val_loss: 0.0831\n",
      "Epoch 25/60\n",
      "6s - loss: 0.0102 - val_loss: 0.0837\n",
      "Epoch 26/60\n",
      "6s - loss: 0.0107 - val_loss: 0.0834\n",
      "Epoch 27/60\n",
      "6s - loss: 0.0105 - val_loss: 0.0843\n",
      "Epoch 28/60\n",
      "6s - loss: 0.0100 - val_loss: 0.0831\n",
      "Epoch 29/60\n",
      "6s - loss: 0.0101 - val_loss: 0.0858\n",
      "Epoch 30/60\n",
      "7s - loss: 0.0104 - val_loss: 0.0829\n",
      "Epoch 31/60\n",
      "7s - loss: 0.0107 - val_loss: 0.0827\n",
      "Epoch 32/60\n",
      "9s - loss: 0.0102 - val_loss: 0.0849\n",
      "Epoch 33/60\n",
      "4s - loss: 0.0102 - val_loss: 0.0826\n",
      "Epoch 34/60\n",
      "7s - loss: 0.0104 - val_loss: 0.0840\n",
      "Epoch 35/60\n",
      "7s - loss: 0.0101 - val_loss: 0.0843\n",
      "Epoch 36/60\n",
      "6s - loss: 0.0101 - val_loss: 0.0858\n",
      "Epoch 37/60\n",
      "7s - loss: 0.0103 - val_loss: 0.0828\n",
      "Epoch 38/60\n",
      "7s - loss: 0.0103 - val_loss: 0.0846\n",
      "Epoch 39/60\n",
      "7s - loss: 0.0098 - val_loss: 0.0866\n",
      "Epoch 40/60\n",
      "6s - loss: 0.0107 - val_loss: 0.0860\n",
      "Epoch 41/60\n",
      "6s - loss: 0.0102 - val_loss: 0.0833\n",
      "Epoch 42/60\n",
      "7s - loss: 0.0104 - val_loss: 0.0829\n",
      "Epoch 43/60\n",
      "7s - loss: 0.0102 - val_loss: 0.0831\n",
      "Epoch 44/60\n",
      "7s - loss: 0.0105 - val_loss: 0.0869\n",
      "Epoch 45/60\n",
      "7s - loss: 0.0099 - val_loss: 0.0845\n",
      "Epoch 46/60\n",
      "6s - loss: 0.0099 - val_loss: 0.0818\n",
      "Epoch 47/60\n",
      "7s - loss: 0.0102 - val_loss: 0.0822\n",
      "Epoch 48/60\n",
      "6s - loss: 0.0102 - val_loss: 0.0832\n",
      "Epoch 49/60\n",
      "6s - loss: 0.0106 - val_loss: 0.0842\n",
      "Epoch 50/60\n",
      "6s - loss: 0.0103 - val_loss: 0.0833\n",
      "Epoch 51/60\n",
      "7s - loss: 0.0101 - val_loss: 0.0832\n",
      "Epoch 52/60\n",
      "6s - loss: 0.0097 - val_loss: 0.0832\n",
      "Epoch 53/60\n",
      "7s - loss: 0.0101 - val_loss: 0.0829\n",
      "Epoch 54/60\n",
      "6s - loss: 0.0103 - val_loss: 0.0840\n",
      "Epoch 55/60\n",
      "6s - loss: 0.0100 - val_loss: 0.0830\n",
      "Epoch 56/60\n",
      "7s - loss: 0.0101 - val_loss: 0.0853\n",
      "Epoch 57/60\n",
      "6s - loss: 0.0100 - val_loss: 0.0842\n",
      "Epoch 58/60\n",
      "6s - loss: 0.0101 - val_loss: 0.0836\n",
      "Epoch 59/60\n",
      "6s - loss: 0.0102 - val_loss: 0.0830\n",
      "Epoch 60/60\n",
      "7s - loss: 0.0099 - val_loss: 0.0822\n",
      "30) Test RMSE: 0.000\n"
     ]
    }
   ],
   "source": [
    "# repeat experiment\n",
    "repeats = 30\n",
    "error_scores = list()\n",
    "for r in range(repeats):\n",
    "    # fit the model\n",
    "    history = model.fit(train_X, train_y, epochs=60 ,batch_size=1, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "    yhat = model.predict(test_X)\n",
    "    # walk-forward validation on the test data\n",
    "    predictions = list()\n",
    "    \n",
    "    # invert scaling for forecas\n",
    "    # combine original scaled data and predicted answer, set the predicted answer to the \n",
    "    # original position\n",
    "    original_test = original_data.iloc[train_data_number:]\n",
    "    before = [(\"var%d(t)\"%i)for i in range(1,11)]\n",
    "    after = [(\"var%d(t)\"%i)for i in range(12,n_features+1)]\n",
    "    inv_yhat = concatenate((original_test[before],yhat,original_test[after]),axis=1)\n",
    "    inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "    inv_yhat = inv_yhat[:,11]\n",
    "    # invert scaling for actual\n",
    "    original_test = original_data.iloc[train_data_number:]\n",
    "    original_recover = scaler.inverse_transform(original_test)\n",
    "    inv_y = original_recover[:,11]\n",
    "    # invert differencing\n",
    "    rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "    print('%d) Test RMSE: %.3f' % (r+1, rmse))\n",
    "    error_scores.append(rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       rmse\n",
      "count  30.0\n",
      "mean    0.0\n",
      "std     0.0\n",
      "min     0.0\n",
      "25%     0.0\n",
      "50%     0.0\n",
      "75%     0.0\n",
      "max     0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:5: FutureWarning: \n",
      "The default value for 'return_type' will change to 'axes' in a future release.\n",
      " To use the future behavior now, set return_type='axes'.\n",
      " To keep the previous behavior and silence this warning, set return_type='dict'.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhUAAAFkCAYAAACXcsmHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3X2UXXV97/H3V/DhjgpYsZk+mAX4ALS3IjNFSdtlbamh\nhJUjbdU0liKJ1aUk0RVLwu2qyySw7sKJFYQkFJdJi1zNBEtr9NLaRGgtpCK2M4q1ZvRWHiJqIqNU\nWkaUwvf+cXZYZyZzZpLufbL34Pu11lnM+Z3f3vn8Fg/zYT+dyEwkSZLKelrdASRJ0lODpUKSJFXC\nUiFJkiphqZAkSZWwVEiSpEpYKiRJUiUsFZIkqRKWCkmSVAlLhSRJqoSlQpIkVaLnpSIiVkTEvRHx\ng4j4XEScNcv8V0fESEQ8GhFfi4g3TTPn+IjYEhHfKuaNRcRv9m4VkiRpNj0tFRGxBHg/sA44E7gb\n2BURJ3aZfxJwC3AbcAZwDbA1Il7TMefpwK3AfOC3gZcCbwG+2at1SJKk2UUvv1AsIj4H3JWZ7yze\nB/AN4NrM3DjN/CHgvMx8WcfYMHB8Zi4q3r8N+EPgtMx8vGfhJUnSEenZkYriiMIg7aMOAGS7wdwK\nLOiy2dnF5512TZm/GLgTuC4i9kfEv0TEH0WE14dIklSjY3u47xOBY4ADU8YPAKd22aa/y/zjIuKZ\nmflD4BTg14GPAOcBLwb+lPZarphupxHxfOBc4D7g0SNdiCRJP8aeBZwE7MrM7840sZeloleeRrto\nvLU48vGFiPhZ4FK6lAraheKjRymfJElPRb8HbJ9pQi9LxTjwODBvyvg8YH+XbfZ3mf9wcZQC4NvA\nj3LyxSB7gf6IODYz/2ua/d4H8JGPfITTTz/98Fcg6ahZvXo1V199dd0xJE2xd+9eLrzwQih+l86k\nZ6UiMx+LiBHgHOCT8OSFmucA13bZ7E7apzQ6LSzGD/pHYOmUOacC3+5SKKA45XH66aczMDBw2GuQ\ndPQcf/zx/vspNduslw/0+uLGq4C3RMRFEXEacD3QB9wAEBFXRsSHO+ZfD5wSEUMRcWpEXAK8rtjP\nQX8K/EREXBsRL4mI84E/Ajb3eC2Semj//m4HMCXNFT29piIzP1Y8k+Jy2qcxvgicm5kPFlP6gRd2\nzL+vKAlXA+8AHgDenJm3dsx5ICLOLebcTfv5FFcDh9yiKmnu+OY3fdSMNNf1/ELNzLwOuK7LZ8um\nGbud9q2oM+3zLuCXKgkoqREGB2f8117SHOCzHSQ1wtKlUy+VkjTXWCokNYKlQpr7LBWSJKkSlgpJ\njbBs2SGXWEmaYywVkhph4cKFdUeQVJKlQlIjeE2FNPdZKiRJUiUsFZIkqRKWCkmNsGfPnrojSCrJ\nUiGpETZu9En70lxnqZDUCDt27Kg7gqSSLBWSGqGvr6/uCJJKslRIkqRKWCokSVIlLBWSGmHNmjV1\nR5BUkqVCUiPMnz+/7giSSrJUSGqEVatW1R1BUkmWCkmSVAlLhSRJqoSlQlIjjI2N1R1BUkmWCkmN\nsHbt2rojSCrJUiGpETZv3lx3BEklWSokNYK3lEpzn6VCkiRVwlIhSZIqYamQ1AhDQ0N1R5BUkqVC\nUiNMTEzUHUFSSZYKSY2wYcOGuiNIKslSIUmSKmGpkCRJlbBUSGqE8fHxuiNIKslSIakRli9fXncE\nSSVZKiQ1wvr16+uOIKkkS4WkRhgYGKg7gqSSLBWSJKkSlgpJklQJS4WkRti2bVvdESSVZKmQ1Aij\no6N1R5BUkqVCUiNs2bKl7giSSrJUSJKkSlgqJElSJXpeKiJiRUTcGxE/iIjPRcRZs8x/dUSMRMSj\nEfG1iHjTDHN/NyKeiIi/qj65JEk6Ej0tFRGxBHg/sA44E7gb2BURJ3aZfxJwC3AbcAZwDbA1Il7T\nZe77gNurTy7paGu1WnVHkFRSr49UrAY+mJk3ZuYY8DZgAuj2kP+3A/dk5trM/GpmbgFuLvbzpIh4\nGvAR4D3AvT1LL+moWblyZd0RJJXUs1IREU8HBmkfdQAgMxO4FVjQZbOzi8877Zpm/jrgQGb+eTVp\nJdVt4cKFdUeQVNKxPdz3icAxwIEp4weAU7ts099l/nER8czM/GFE/AqwjPbpEUmS1BBz6u6PiHgO\ncCPwlsx86Ei3X7RoEa1Wa9JrwYIF7Ny5c9K83bt3T3t+d8WKFYc89W90dJRWq8X4+Pik8XXr1jE0\nNDRpbN++fbRaLcbGxiaNb9q0iTVr1kwam5iYoNVqsWfPnknjw8PDLFu27JBsS5YscR2uw3W4Dtfh\nOkqtY3h4+Mnfjf39/bRaLVavXn3INt1E+4xE9YrTHxPA72TmJzvGbwCOz8zfmmabfwBGMvNdHWMX\nA1dn5vMi4gxgFHgciGLKwWL0OHBqZh5yjUVEDAAjIyMjfhOi1FA7d+7kggsuqDuGpClGR0cZHBwE\nGMzMGR9927MjFZn5GDACnHNwLCKieP/ZLpvd2Tm/sLAYBxgDfgF4Oe3TH2cAnwT+rvj5GxXFl3SU\nDQ8P1x1BUkm9vKYC4CrghogYAT5P+y6OPuAGgIi4EvjpzDz4LIrrgRURMQT8Ge2C8TpgEUBm/hD4\nSucfEBH/3v4o9/Z4LZJ66Kabbqo7gqSSeloqMvNjxTMpLgfmAV8Ezs3MB4sp/cALO+bfFxHnA1cD\n7wAeAN6cmVPvCJEkSQ3T6yMVZOZ1wHVdPjvkipHMvJ32raiHu/9DrzqRJElH3Zy6+0OSJDWXpUJS\nI0x3q5ukucVSIakRfKKmNPdZKiQ1wtKlS+uOIKkkS4UkSaqEpUKSJFXCUiGpEaZ+T4GkucdSIakR\nNm7cWHcESSVZKiQ1wo4dO+qOIKkkS4WkRujr66s7gqSSLBWSJKkSlgpJklQJS4WkRlizZk3dESSV\nZKmQ1Ajz58+vO4KkkiwVkhph1apVdUeQVJKlQpIkVcJSIUmSKmGpkNQIY2NjdUeQVJKlQlIjrF27\ntu4IkkqyVEhqhM2bN9cdQVJJlgpJjeAtpdLcZ6mQJEmVsFRIkqRKWCokNcLQ0FDdESSVZKmQ1AgT\nExN1R5BUkqVCUiNs2LCh7giSSrJUSJKkSlgqJElSJSwVkhphfHy87giSSrJUSGqE5cuX1x1BUkmW\nCkmNsH79+rojSCrJUiGpEQYGBuqOIKkkS4UkSaqEpUKSJFXCUiGpEbZt21Z3BEklWSokNcLo6Gjd\nESSVZKmQ1AhbtmypO4KkkiwVkiSpEpYKSZJUCUuFJEmqRM9LRUSsiIh7I+IHEfG5iDhrlvmvjoiR\niHg0Ir4WEW+a8vkfRMTtEfG94vXp2fYpqflarVbdESSV1NNSERFLgPcD64AzgbuBXRFxYpf5JwG3\nALcBZwDXAFsj4jUd034V2A68Gjgb+AawOyJ+qieLkHRUrFy5su4Ikkrq9ZGK1cAHM/PGzBwD3gZM\nAN2+OejtwD2ZuTYzv5qZW4Cbi/0AkJm/n5nXZ+aXMvNrwB/QXsc5PV2JpJ5auHBh3REkldSzUhER\nTwcGaR91ACAzE7gVWNBls7OLzzvtmmE+wLOBpwPf+2+HlSRJpfXySMWJwDHAgSnjB4D+Ltv0d5l/\nXEQ8s8s2Q8A3ObSMSJKko2hO3/0REf8LeANwQWb+qO48kv77du7cWXcESSX1slSMA48D86aMzwP2\nd9lmf5f5D2fmDzsHI+JSYC3wmsz818MJtGjRIlqt1qTXggULDvmP2e7du6e9En3FihWHfD/B6Ogo\nrVaL8fHxSePr1q1jaGho0ti+fftotVqMjY1NGt+0aRNr1qyZNDYxMUGr1WLPnj2TxoeHh1m2bNkh\n2ZYsWeI6XMecXsfWrVufEut4qvz9cB0/nusYHh5+8ndjf38/rVaL1atXH7JNN9G+zKE3IuJzwF2Z\n+c7ifQD7gGsz833TzH8vcF5mntExth04ITMXdYytBf4IWJiZ/3QYOQaAkZGREQYGBsouS5KkHxuj\no6MMDg4CDGbmjF/S0+vTH1cBb4mIiyLiNOB6oA+4ASAiroyID3fMvx44JSKGIuLUiLgEeF2xH4pt\nLgMup30Hyb6ImFe8nt3jtUiSpBkc28udZ+bHimdSXE77NMYXgXMz88FiSj/wwo7590XE+cDVwDuA\nB4A3Z2bnRZhvo323x81T/rgNxZ8jSZJq0NNSAZCZ1wHXdfnskJM7mXk77VtRu+3v5OrSSZKkqszp\nuz8kPXVMdwGZpLnFUiGpEXyipjT3WSokNcLSpUvrjiCpJEuFJEmqhKVCkiRVwlIhqRGmPv1P0txj\nqZDUCBs3bqw7gqSSLBWSGmHHjh11R5BUkqVCUiP09fXVHUFSSZYKSZJUCUuFJEmqhKVCUiOsWbOm\n7giSSrJUSGqE+fPn1x1BUkmWCkmNsGrVqrojSCrJUiFJkiphqZAkSZWwVEhqhLGxsbojSCrJUiGp\nEdauXVt3BEklWSokNcLmzZvrjiCpJEuFpEbwllJp7rNUSJKkSlgqJElSJSwVkhphaGio7giSSrJU\nSGqEiYmJuiNIKslSIakRNmzYUHcESSVZKiRJUiUsFZIkqRKWCkmNMD4+XncESSVZKiQ1wvLly+uO\nIKkkS4WkRli/fn3dESSVZKmQ1AgDAwN1R5BUkqVCkiRVwlIhSZIqYamQ1Ajbtm2rO4KkkiwVkhph\ndHS07giSSrJUSGqELVu21B1BUkmWCkmSVAlLhSRJqoSlQpIkVcJSIakRWq1W3REklWSpkNQIK1eu\nrDuCpJJ6XioiYkVE3BsRP4iIz0XEWbPMf3VEjETEoxHxtYh40zRzXh8Re4t93h0R5/VuBZKOhoUL\nF9YdQVJJPS0VEbEEeD+wDjgTuBvYFREndpl/EnALcBtwBnANsDUiXtMx55eA7cCHgJcDnwB2RsTP\n9WwhkiRpVr0+UrEa+GBm3piZY8DbgAmg23ccvx24JzPXZuZXM3MLcHOxn4PeAXwqM68q5rwHGAU8\ndipJUo16Vioi4unAIO2jDgBkZgK3Agu6bHZ28XmnXVPmLziMOZLmmJ07d9YdQVJJx/Zw3ycCxwAH\npowfAE7tsk1/l/nHRcQzM/OHM8zpLxdX+vEyvm+COz40VmofExMP8fWv31lJno/900186YYvl97P\ni160gL6+55Xax8/8DLziotOgr690HunHSmb25AX8FPAE8Mop40PAnV22+Spw2ZSx84DHgWcW738I\nLJky5+3At2fIMgDkvHnzcvHixZNeZ599dn784x/PTrt27crFixfnVJdccklu3bp10tjIyEguXrw4\nH3zwwUnj73nPe/K9733vpLH7778/Fy9enHv37p00fu211+all146aeyRRx7JxYsX5x133DFpfPv2\n7XnxxRcfku0Nb3iD63AdR7SOv3r3SCZkQm6HvLj4ufP1BsiPTxnbBbl4mrmXQG6dMjZSzH1wyvh7\nIN87Zez+Yu7eKePXQl46ZeyRYu4dU8arXMc9N48c1b8fnebyP1euY26vY/v27U/+bjz4O/NVr3pV\nAgkM5Cy/+yPbv3QrV5z+mAB+JzM/2TF+A3B8Zv7WNNv8AzCSme/qGLsYuDozn1e8vx94f2Ze2zFn\nPfDazDyzS5YBYGRkZISBgYEKVifNfU07UlEVj1RI1RodHWVwcBBgMDNn/Oa/np3+yMzHImIEOAf4\nJEBERPH+2i6b3Un7yESnhcV455yp+3jNlDmSZnHi/D5+64oqSvY5FexD0lNBr+/+uAp4S0RcFBGn\nAdcDfcANABFxZUR8uGP+9cApETEUEadGxCXA64r9HHQN8JsR8a5iznraF4Ru7vFaJEnSDHpaKjLz\nY8ClwOXAF4CXAedm5oPFlH7ghR3z7wPOB34D+CLtW0nfnJm3dsy5E3gj8NZizm/TPvXxlV6uRVJv\nLVu2rO4Ikkrq5d0fAGTmdcB1XT475L8imXk77SMPM+3zL4G/rCSgpEbwiZrS3Od3f0hqhKVLl9Yd\nQVJJlgpJklQJS4UkSaqEpUJSI+zZs6fuCJJKslRIaoSNGzfWHUFSSZYKSY2wY8eOuiNIKslSIakR\n+nwktjTnWSokSVIlLBWSJKkSlgpJjbBmzZq6I0gqyVIhqRHmz59fdwRJJVkqJDXCqlWr6o4gqSRL\nhSRJqoSlQpIkVcJSIakRxsbG6o4gqSRLhaRGWLt2bd0RJJVkqZDUCJs3b647gqSSLBWSGsFbSqW5\nz1IhSZIqYamQJEmVsFRIaoShoaG6I0gqyVIhqREmJibqjiCpJEuFpEbYsGFD3REklWSpkCRJlbBU\nSJKkSlgqJDXC+Ph43REklWSpkNQIy5cvrzuCpJIsFZIaYf369XVHkFSSpUJSIwwMDNQdQVJJlgpJ\nklQJS4UkSaqEpUJSI2zbtq3uCJJKslRIaoTR0dG6I0gqyVIhqRG2bNlSdwRJJVkqJElSJSwVkiSp\nEpYKSZJUCUuFpEZotVp1R5BUkqVCUiOsXLmy7giSSrJUSGqEhQsX1h1BUkmWCkmSVImelYqIeF5E\nfDQivh8RD0XE1oh49mFsd3lEfCsiJiLi0xHx4in7vDYixorP74+IayLiuF6tQ5IkHZ5eHqnYDpwO\nnAOcD7wK+OBMG0TEZcBK4K3AK4BHgF0R8Yxiyk8DPwW8C/h54E3AbwJbe5Bf0lG0c+fOuiNIKqkn\npSIiTgPOBd6cmf+cmZ8FVgG/GxH9M2z6TuCKzLwlM78MXES7SFwAkJn/mpmvz8y/ycx7M/MzwB8D\niyPCUznSHDY8PFx3BEkl9eoX8QLgocz8QsfYrUACr5xug4g4GegHbjs4lpkPA3cV++vmBODhzHyi\nbGhJ9bnpppvqjiCppF6Vin7gO50Dmfk48L3is27bJHBgyviBbttExInAu5nltIokSeq9IyoVEXFl\nRDwxw+vxiHhpr8JOyfJc4K+BLwMbDmebRYsW0Wq1Jr0WLFhwyLnc3bt3T/sgnhUrVhzy9cyjo6O0\nWi3Gx8cnja9bt46hoaFJY/v27aPVajE2NjZpfNOmTaxZs2bS2MTEBK1Wiz179kwaHx4eZtmyZYdk\nW7JkietwHa7DdbgO11FqHcPDw0/+buzv76fVarF69epDtukmMvPwJ0c8H3j+LNPuAX4f+JPMfHJu\nRBwDPAq8LjM/Mc2+Twa+Drw8M7/UMf4Z4AuZubpj7DnAbuA/gMWZ+aNZcg8AIyMjIwwMDMwSX5Ik\nHTQ6Osrg4CDAYGaOzjT3iI5UZOZ3M/Nrs7z+C7gTOCEizuzY/BwgaF8jMd2+7wX2F/MAKG4VfSXw\n2Y6x59IuFD8AWrMVCklzw3T/ByVpbunJNRWZOQbsAj4UEWdFxC8Dm4DhzNx/cF7xvInXdmz6AeDd\nEbE4In4BuBF4APhEMf+5wKeBPuAPaBeXecXLuz+kOcwnakpz37E93Pcbgc207/p4AriZ9i2jnV4C\nHH/wTWZujIg+2hdengDcAZzXcTRiADir+Pnfir8G7Qs8Twb2Vb8MSUfD0qVL644gqaSelYrM/Hfg\nwlnmHDPN2HpgfZf5/wAcso0kSaqfpwwkSVIlLBWSGmHq7W+S5h5LhaRG2LhxY90RJJVkqZDUCDt2\n7Kg7gqSSLBWSGqGvr6/uCJJKslRIkqRKWCokSVIlLBWSGmHqlyJJmnssFZIaYf78+XVHkFSSpUJS\nI6xataruCJJKslRIkqRKWCokSVIlLBWSGmFsbKzuCJJKslRIaoS1a9fWHUFSSZYKSY2wefPmuiNI\nKslSIakRvKVUmvssFZIkqRKWCkmSVAlLhaRGGBoaqjuCpJIsFZIaYWJiou4IkkqyVEhqhA0bNtQd\nQVJJlgpJklQJS4UkSaqEpUJSI4yPj9cdQVJJlgpJjbB8+fK6I0gqyVIhqRHWr19fdwRJJVkqJDXC\nwMBA3REklWSpkCRJlbBUSJKkSlgqJDXCtm3b6o4gqSRLhaRGGB0drTuCpJIsFZIaYcuWLXVHkFSS\npUKSJFXCUiFJkiphqZAkSZWwVEhqhFarVXcESSVZKiQ1wsqVK+uOIKkkS4WkRli4cGHdESSVZKmQ\nJEmVsFRIkqRK9KxURMTzIuKjEfH9iHgoIrZGxLMPY7vLI+JbETEREZ+OiBfPMPdTEfFERHiFlzTH\n7dy5s+4Ikkrq5ZGK7cDpwDnA+cCrgA/OtEFEXAasBN4KvAJ4BNgVEc+YZu5q4HEgq40tqQ7Dw8N1\nR5BUUk9KRUScBpwLvDkz/zkzPwusAn43Ivpn2PSdwBWZeUtmfhm4CPhp4IIp+385sBpYDkQv1iDp\n6LrpppvqjiCppF4dqVgAPJSZX+gYu5X2UYVXTrdBRJwM9AO3HRzLzIeBu4r9HZz3P4CPApdk5neq\njy5Jkv47elUq+oFJv/Az83Hge8Vn3bZJ4MCU8QNTtrka2JOZt1QTVZIkVeGISkVEXFlcGNnt9XhE\nvLRXYYsLMn+d9qkPSZLUIEd6pOJPgNNmeJ0O3APsB36yc8OIOAb4ieKz6eynfX3EvCnj8zq2+TXg\nFOD7EfFYRDxWjP9VRPzdbOEXLVpEq9Wa9FqwYMEhV53v3r172kcGr1ixgm3btk0aGx0dpdVqMT4+\nPml83bp1DA0NTRrbt28frVaLsbGxSeObNm1izZo1k8YmJiZotVrs2bNn0vjw8DDLli07JNuSJUtc\nh+uY0+t4/etf/5RYx1Pl74fr+PFcx/Dw8JO/G/v7+2m1Wqxeffj/Hx+Z1d88UVyo+a/ALx68riIi\nFgJ/A/xsZk5bLCLiW8D7MvPq4v1xtE9/XJSZfxERPwmcOGWzL9O+CPSWzLy/y34HgJGRkREGBgbK\nL1BS5YaHh1m6dGndMSRNMTo6yuDgIMBgZo7ONPfYXgTIzLGI2AV8KCLeDjwD2AQMdxaKiBgDLsvM\nTxRDHwDeHRH/BtwHXAE8AHyi2O93mHKtRkQAfKNboZA0N1gopLmvJ6Wi8EZgM+27Pp4AbqZ9y2in\nlwDHH3yTmRsjoo/28yxOAO4AzsvMH83w5/icCkmSGqBnpSIz/x24cJY5x0wzth5YfwR/ziH7kCRJ\nR5/f/SGpEaZeVCZp7rFUSGqEjRs31h1BUkmWCkmNsGPHjrojSCrJUiGpEfr6+uqOIKkkS4UkSaqE\npUKSJFXCUiGpEaY+aljS3GOpkNQI8+fPrzuCpJIsFZIaYdWqVXVHkFSSpUKSJFXCUiFJkiphqZDU\nCGNjY3VHkFSSpUJSI6xdu7buCJJKslRIaoTNmzfXHUFSSZYKSY3gLaXS3GepkCRJlbBUSJKkSlgq\nJDXC0NBQ3REklWSpkNQIExMTdUeQVJKlQlIjbNiwoe4IkkqyVEiSpEpYKiRJUiUsFZIaYXx8vO4I\nkkqyVEhqhOXLl9cdQVJJlgpJjbB+/fq6I0gqyVIhqREGBgbqjiCpJEuFJEmqhKVCkiRVwlIhqRG2\nbdtWdwRJJVkqJDXC6Oho3REklWSpkNQIW7ZsqTuCpJIsFZIkqRKWCkmSVAlLhSRJqoSlQlIjtFqt\nuiNIKslSIakRVq5cWXcESSVZKiQ1wsKFC+uOIKkkS4UkSaqEpUKSJFXCUiGpEXbu3Fl3BEklWSok\nNcLQ0FDdESSV1LNSERHPi4iPRsT3I+KhiNgaEc8+jO0uj4hvRcRERHw6Il48zZwFEXFbRPxnsf/P\nRMQze7MSSUfDC17wgrojSCqpl0cqtgOnA+cA5wOvAj440wYRcRmwEngr8ArgEWBXRDyjY84C4FPA\n3wK/WLw2A09UvwRJknS4ju3FTiPiNOBcYDAzv1CMrQL+OiIuzcz9XTZ9J3BFZt5SbHMRcAC4APhY\nMecq4AOZ+b6O7f5fD5YhSZKOQK+OVCwAHjpYKAq3Agm8croNIuJkoB+47eBYZj4M3FXsj4h4QbH9\neET8Y0TsL059/HJvliFJkg5XT45U0C4H3+kcyMzHI+J7xWfdtknaRyY6HejY5pTir+uAPwTuBt4E\n3BYRP5+ZX++y72cB7N2790jWIOko+vznP8/o6GjdMSRN0fG781mzzT2iUhERVwKXzTAlaV9H0SsH\nj6xcn5k3Fj+/KyLOAZYDf9xlu5MALrzwwh5Gk1TW4OBg3REkdXcS8NmZJhzpkYo/Af58ljn3APuB\nn+wcjIhjgJ8oPpvOfiCAeUw+WjEPOHga5dvFX6cectgLzJ8h0y7g94D7gEdnTC9Jkjo9i3ah2DXb\nxCMqFZn5XeC7s82LiDuBEyLizI7rKs6hXRru6rLveyNifzHvS8V+jqN9DcWWYs59EfEt4NQpm78U\n+JtZcm+fLbckSZrWjEcoDurJhZqZOUa70XwoIs4qLqTcBAx33vkREWMR8dqOTT8AvDsiFkfELwA3\nAg8An+iY8z7gHRHxOxHxooi4gnbJ2NaLtUiSpMPTqws1Ad5I+/kRt9J+hsTNtG8Z7fQS4PiDbzJz\nY0T00X6exQnAHcB5mfmjjjnXFA+6uor26ZS7gd/IzHt7uBZJkjSLyMy6M0iSpKcAv/tDkiRVwlIh\nSZIqYamQJEmVsFRIqlxEPL3uDJKOPkuFpNIi4u8jYlNEXB0RD9L+duEnIuKtEfF/I+KRiPhKRJxd\n3Ar+9xHxn8V3+JzcsZ+XRcTfRcTDEfH9iPiniBjo+PxXIuL2iJiIiPsj4prijjFJDWCpkFSVi4Af\n0v4CwLcVY+8GbgDOoP3k2+3A9cD/BgZpPxBvc8c+Pgp8o/hsAHgv8BhARLwI+BTwF8D/BJYAB5+B\nI6kBvKVUUmkR8ffAczPzFzvGngAuz8z1xftXAncCyzLzw8XYEuDPMvPZxfvvAysz8/9M82d8CPiv\nzHx7x9ivAJ8B+jqfZyOpHh6pkFSVkWnG/qXj54Pf6fPlKWPPiojnFO+vArZFxKcj4rKIOKVj7hnA\nxRHxHwdfwN8Wn52MpNpZKiRV5ZFpxh7r+DlnGHsaQGZuAH4OuAX4deArHY/yfw7tp+2+jHbBOKP4\n+aXA1yvIL6mkXj6mW5KmmvV8a2b+G3ANcE1EbAeW0f7+n1Hg53wkv9RcHqmQdDRFt7GIeFZxB8mv\nRsT84osIzwK+UswbAn6pmHNGRLw4Il4bEV6oKTWERyokVWG6IxBHOvY48Hzgw8A8YBz4S2A9QGb+\nS0T8Ku0lMSbZAAAAXElEQVQ7R26nXUa+DtxUJrik6nj3hyRJqoSnPyRJUiUsFZIkqRKWCkmSVAlL\nhSRJqoSlQpIkVcJSIUmSKmGpkCRJlbBUSJKkSlgqJElSJSwVkiSpEpYKSZJUif8PviCdoMzinusA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f95a3451908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize results\n",
    "results = DataFrame()\n",
    "results['rmse'] = error_scores\n",
    "print(results.describe())\n",
    "results.boxplot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
