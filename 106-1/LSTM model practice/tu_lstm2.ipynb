{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "from numpy import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpu_ghz</th>\n",
       "      <th>cpu_usage</th>\n",
       "      <th>cpu_idle</th>\n",
       "      <th>cpu_total</th>\n",
       "      <th>memory_free_mb</th>\n",
       "      <th>memory_usage</th>\n",
       "      <th>memory_total</th>\n",
       "      <th>cpu_usage_tag</th>\n",
       "      <th>period</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ts</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-04 07:09:00</th>\n",
       "      <td>1.622994</td>\n",
       "      <td>0.058949</td>\n",
       "      <td>7229.349138</td>\n",
       "      <td>7626.006979</td>\n",
       "      <td>73703.339671</td>\n",
       "      <td>0.171460</td>\n",
       "      <td>85762.997397</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 07:10:00</th>\n",
       "      <td>1.565744</td>\n",
       "      <td>0.051145</td>\n",
       "      <td>7436.343501</td>\n",
       "      <td>7808.899014</td>\n",
       "      <td>73678.012357</td>\n",
       "      <td>0.171868</td>\n",
       "      <td>85762.997397</td>\n",
       "      <td>-1</td>\n",
       "      <td>night</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 07:11:00</th>\n",
       "      <td>1.532764</td>\n",
       "      <td>0.050431</td>\n",
       "      <td>7266.985222</td>\n",
       "      <td>7628.050287</td>\n",
       "      <td>73679.538946</td>\n",
       "      <td>0.171852</td>\n",
       "      <td>85762.997397</td>\n",
       "      <td>-1</td>\n",
       "      <td>night</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 07:12:00</th>\n",
       "      <td>1.537919</td>\n",
       "      <td>0.055125</td>\n",
       "      <td>7251.151273</td>\n",
       "      <td>7645.735222</td>\n",
       "      <td>73662.632567</td>\n",
       "      <td>0.171941</td>\n",
       "      <td>85762.997397</td>\n",
       "      <td>-1</td>\n",
       "      <td>night</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04 07:13:00</th>\n",
       "      <td>1.535036</td>\n",
       "      <td>0.049197</td>\n",
       "      <td>7272.412151</td>\n",
       "      <td>7618.750821</td>\n",
       "      <td>73644.415185</td>\n",
       "      <td>0.172063</td>\n",
       "      <td>85762.997397</td>\n",
       "      <td>-1</td>\n",
       "      <td>night</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      cpu_ghz  cpu_usage     cpu_idle    cpu_total  \\\n",
       "ts                                                                   \n",
       "2017-08-04 07:09:00  1.622994   0.058949  7229.349138  7626.006979   \n",
       "2017-08-04 07:10:00  1.565744   0.051145  7436.343501  7808.899014   \n",
       "2017-08-04 07:11:00  1.532764   0.050431  7266.985222  7628.050287   \n",
       "2017-08-04 07:12:00  1.537919   0.055125  7251.151273  7645.735222   \n",
       "2017-08-04 07:13:00  1.535036   0.049197  7272.412151  7618.750821   \n",
       "\n",
       "                     memory_free_mb  memory_usage  memory_total  \\\n",
       "ts                                                                \n",
       "2017-08-04 07:09:00    73703.339671      0.171460  85762.997397   \n",
       "2017-08-04 07:10:00    73678.012357      0.171868  85762.997397   \n",
       "2017-08-04 07:11:00    73679.538946      0.171852  85762.997397   \n",
       "2017-08-04 07:12:00    73662.632567      0.171941  85762.997397   \n",
       "2017-08-04 07:13:00    73644.415185      0.172063  85762.997397   \n",
       "\n",
       "                     cpu_usage_tag period  weekday  \n",
       "ts                                                  \n",
       "2017-08-04 07:09:00              0  night        6  \n",
       "2017-08-04 07:10:00             -1  night        6  \n",
       "2017-08-04 07:11:00             -1  night        6  \n",
       "2017-08-04 07:12:00             -1  night        6  \n",
       "2017-08-04 07:13:00             -1  night        6  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_csv('cm_all.csv', header=0, index_col=1, squeeze=True)\n",
    "df = df.drop(df.columns[0],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# integer encode direction\n",
    "# tu: transform all your tag \n",
    "encoder = LabelEncoder()\n",
    "values[:,-1] = encoder.fit_transform(values[:,-1])\n",
    "values[:,-2] = encoder.fit_transform(values[:,-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ensure all data is float\n",
    "values = values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify the number of lag hours\n",
    "# tu : n_min =set time lag how earlier data will you use to predict current data\n",
    "n_min = 3\n",
    "n_features = len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5496, 40)\n"
     ]
    }
   ],
   "source": [
    "# frame as supervised learning\n",
    "# series_to_supervised function is used to produce earlier data\n",
    "reframed = series_to_supervised(scaled, n_min, 1)\n",
    "print(reframed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-3)</th>\n",
       "      <th>var2(t-3)</th>\n",
       "      <th>var3(t-3)</th>\n",
       "      <th>var4(t-3)</th>\n",
       "      <th>var5(t-3)</th>\n",
       "      <th>var6(t-3)</th>\n",
       "      <th>var7(t-3)</th>\n",
       "      <th>var8(t-3)</th>\n",
       "      <th>var9(t-3)</th>\n",
       "      <th>var10(t-3)</th>\n",
       "      <th>...</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var2(t)</th>\n",
       "      <th>var3(t)</th>\n",
       "      <th>var4(t)</th>\n",
       "      <th>var5(t)</th>\n",
       "      <th>var6(t)</th>\n",
       "      <th>var7(t)</th>\n",
       "      <th>var8(t)</th>\n",
       "      <th>var9(t)</th>\n",
       "      <th>var10(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.675438</td>\n",
       "      <td>0.178166</td>\n",
       "      <td>0.746099</td>\n",
       "      <td>0.141518</td>\n",
       "      <td>0.824924</td>\n",
       "      <td>0.226678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242970</td>\n",
       "      <td>0.125575</td>\n",
       "      <td>0.771196</td>\n",
       "      <td>0.216026</td>\n",
       "      <td>0.810045</td>\n",
       "      <td>0.243593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.384414</td>\n",
       "      <td>0.070833</td>\n",
       "      <td>0.984388</td>\n",
       "      <td>0.832260</td>\n",
       "      <td>0.815670</td>\n",
       "      <td>0.241034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228314</td>\n",
       "      <td>0.044047</td>\n",
       "      <td>0.795671</td>\n",
       "      <td>0.114113</td>\n",
       "      <td>0.803387</td>\n",
       "      <td>0.247914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.216763</td>\n",
       "      <td>0.061021</td>\n",
       "      <td>0.789425</td>\n",
       "      <td>0.149235</td>\n",
       "      <td>0.816225</td>\n",
       "      <td>0.240459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228037</td>\n",
       "      <td>0.050427</td>\n",
       "      <td>0.792730</td>\n",
       "      <td>0.112547</td>\n",
       "      <td>0.806696</td>\n",
       "      <td>0.244091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.242970</td>\n",
       "      <td>0.125575</td>\n",
       "      <td>0.771196</td>\n",
       "      <td>0.216026</td>\n",
       "      <td>0.810045</td>\n",
       "      <td>0.243593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494092</td>\n",
       "      <td>0.175683</td>\n",
       "      <td>0.710845</td>\n",
       "      <td>0.128136</td>\n",
       "      <td>0.811136</td>\n",
       "      <td>0.238269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.228314</td>\n",
       "      <td>0.044047</td>\n",
       "      <td>0.795671</td>\n",
       "      <td>0.114113</td>\n",
       "      <td>0.803387</td>\n",
       "      <td>0.247914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627787</td>\n",
       "      <td>0.182516</td>\n",
       "      <td>0.687066</td>\n",
       "      <td>0.091911</td>\n",
       "      <td>0.807299</td>\n",
       "      <td>0.240543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-3)  var2(t-3)  var3(t-3)  var4(t-3)  var5(t-3)  var6(t-3)  \\\n",
       "3   0.675438   0.178166   0.746099   0.141518   0.824924   0.226678   \n",
       "4   0.384414   0.070833   0.984388   0.832260   0.815670   0.241034   \n",
       "5   0.216763   0.061021   0.789425   0.149235   0.816225   0.240459   \n",
       "6   0.242970   0.125575   0.771196   0.216026   0.810045   0.243593   \n",
       "7   0.228314   0.044047   0.795671   0.114113   0.803387   0.247914   \n",
       "\n",
       "   var7(t-3)  var8(t-3)  var9(t-3)  var10(t-3)    ...      var1(t)   var2(t)  \\\n",
       "3        0.0        0.2       0.75        0.75    ...     0.242970  0.125575   \n",
       "4        0.0        0.0       0.75        0.75    ...     0.228314  0.044047   \n",
       "5        0.0        0.0       0.75        0.75    ...     0.228037  0.050427   \n",
       "6        0.0        0.0       0.75        0.75    ...     0.494092  0.175683   \n",
       "7        0.0        0.0       0.75        0.75    ...     0.627787  0.182516   \n",
       "\n",
       "    var3(t)   var4(t)   var5(t)   var6(t)  var7(t)  var8(t)  var9(t)  var10(t)  \n",
       "3  0.771196  0.216026  0.810045  0.243593      0.0      0.0     0.75      0.75  \n",
       "4  0.795671  0.114113  0.803387  0.247914      0.0      0.0     0.75      0.75  \n",
       "5  0.792730  0.112547  0.806696  0.244091      0.0      0.0     0.75      0.75  \n",
       "6  0.710845  0.128136  0.811136  0.238269      0.0      0.2     0.75      0.75  \n",
       "7  0.687066  0.091911  0.807299  0.240543      0.0      0.2     0.75      0.75  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check dataframe processed by series_to_supervised function\n",
    "reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preserve original data, this dataframe will be used to calculate RMSE \n",
    "#between y_prediction and y_realdata in the last two code cells\n",
    "\n",
    "original_data = reframed[reframed.columns[30:40]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set list used to preserve only data what you want to predict\n",
    "# what to predict is the remove one is this list\n",
    "\n",
    "unused_col = [(\"var%d(t)\"%i) for i in range(1,11)]\n",
    "unused_col.remove('var8(t)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-3)</th>\n",
       "      <th>var2(t-3)</th>\n",
       "      <th>var3(t-3)</th>\n",
       "      <th>var4(t-3)</th>\n",
       "      <th>var5(t-3)</th>\n",
       "      <th>var6(t-3)</th>\n",
       "      <th>var7(t-3)</th>\n",
       "      <th>var8(t-3)</th>\n",
       "      <th>var9(t-3)</th>\n",
       "      <th>var10(t-3)</th>\n",
       "      <th>...</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var8(t-1)</th>\n",
       "      <th>var9(t-1)</th>\n",
       "      <th>var10(t-1)</th>\n",
       "      <th>var8(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.675438</td>\n",
       "      <td>0.178166</td>\n",
       "      <td>0.746099</td>\n",
       "      <td>0.141518</td>\n",
       "      <td>0.824924</td>\n",
       "      <td>0.226678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061021</td>\n",
       "      <td>0.789425</td>\n",
       "      <td>0.149235</td>\n",
       "      <td>0.816225</td>\n",
       "      <td>0.240459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.384414</td>\n",
       "      <td>0.070833</td>\n",
       "      <td>0.984388</td>\n",
       "      <td>0.832260</td>\n",
       "      <td>0.815670</td>\n",
       "      <td>0.241034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125575</td>\n",
       "      <td>0.771196</td>\n",
       "      <td>0.216026</td>\n",
       "      <td>0.810045</td>\n",
       "      <td>0.243593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.216763</td>\n",
       "      <td>0.061021</td>\n",
       "      <td>0.789425</td>\n",
       "      <td>0.149235</td>\n",
       "      <td>0.816225</td>\n",
       "      <td>0.240459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044047</td>\n",
       "      <td>0.795671</td>\n",
       "      <td>0.114113</td>\n",
       "      <td>0.803387</td>\n",
       "      <td>0.247914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.242970</td>\n",
       "      <td>0.125575</td>\n",
       "      <td>0.771196</td>\n",
       "      <td>0.216026</td>\n",
       "      <td>0.810045</td>\n",
       "      <td>0.243593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050427</td>\n",
       "      <td>0.792730</td>\n",
       "      <td>0.112547</td>\n",
       "      <td>0.806696</td>\n",
       "      <td>0.244091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.228314</td>\n",
       "      <td>0.044047</td>\n",
       "      <td>0.795671</td>\n",
       "      <td>0.114113</td>\n",
       "      <td>0.803387</td>\n",
       "      <td>0.247914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175683</td>\n",
       "      <td>0.710845</td>\n",
       "      <td>0.128136</td>\n",
       "      <td>0.811136</td>\n",
       "      <td>0.238269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-3)  var2(t-3)  var3(t-3)  var4(t-3)  var5(t-3)  var6(t-3)  \\\n",
       "3   0.675438   0.178166   0.746099   0.141518   0.824924   0.226678   \n",
       "4   0.384414   0.070833   0.984388   0.832260   0.815670   0.241034   \n",
       "5   0.216763   0.061021   0.789425   0.149235   0.816225   0.240459   \n",
       "6   0.242970   0.125575   0.771196   0.216026   0.810045   0.243593   \n",
       "7   0.228314   0.044047   0.795671   0.114113   0.803387   0.247914   \n",
       "\n",
       "   var7(t-3)  var8(t-3)  var9(t-3)  var10(t-3)   ...     var2(t-1)  var3(t-1)  \\\n",
       "3        0.0        0.2       0.75        0.75   ...      0.061021   0.789425   \n",
       "4        0.0        0.0       0.75        0.75   ...      0.125575   0.771196   \n",
       "5        0.0        0.0       0.75        0.75   ...      0.044047   0.795671   \n",
       "6        0.0        0.0       0.75        0.75   ...      0.050427   0.792730   \n",
       "7        0.0        0.0       0.75        0.75   ...      0.175683   0.710845   \n",
       "\n",
       "   var4(t-1)  var5(t-1)  var6(t-1)  var7(t-1)  var8(t-1)  var9(t-1)  \\\n",
       "3   0.149235   0.816225   0.240459        0.0        0.0       0.75   \n",
       "4   0.216026   0.810045   0.243593        0.0        0.0       0.75   \n",
       "5   0.114113   0.803387   0.247914        0.0        0.0       0.75   \n",
       "6   0.112547   0.806696   0.244091        0.0        0.0       0.75   \n",
       "7   0.128136   0.811136   0.238269        0.0        0.2       0.75   \n",
       "\n",
       "   var10(t-1)  var8(t)  \n",
       "3        0.75      0.0  \n",
       "4        0.75      0.0  \n",
       "5        0.75      0.0  \n",
       "6        0.75      0.2  \n",
       "7        0.75      0.2  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use drop code to delete other current data except what you want to predict\n",
    "reframed1 = reframed.drop(unused_col,axis =1)\n",
    "reframed1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_min =  1200\n",
    "train = values[:n_train_min, :]\n",
    "test = values[n_train_min:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 30) 1200 (1200, 10)\n"
     ]
    }
   ],
   "source": [
    "n_obs = n_min * n_features\n",
    "train_X, train_y = train[:, :n_obs], train[:,n_obs:]\n",
    "test_X, test_y = test[:, :n_obs], test[:,n_obs:]\n",
    "print(train_X.shape, len(train_X), train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 3, 10) (1200, 10) (4296, 3, 10) (4296, 10)\n"
     ]
    }
   ],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_min, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_min, n_features))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">>> input = Variable(torch.randn(1200, 1, 40))\n",
    ">>> rnn = nn.LSTM(1, 40, 2)\n",
    ">>> h0 = Variable(torch.randn(2, 1, 20))\n",
    ">>> c0 = Variable(torch.randn(2, 1, 20))\n",
    ">>> output, hn = rnn(input, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(10))\n",
    "model.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1200 samples, validate on 4296 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a0530059a1dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/tu/anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/tu/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/home/tu/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1195\u001b[0m                             val_outs = self._test_loop(val_f, val_ins,\n\u001b[1;32m   1196\u001b[0m                                                        \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m                                                        verbose=0)\n\u001b[0m\u001b[1;32m   1198\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m                                 \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tu/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_test_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1337\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1339\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1340\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tu/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/tu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tu/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_X, train_y, epochs=10, batch_size=1, validation_data=(test_X, test_y), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhsAAAFkCAYAAACJu/k0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIiIJOr/AGpVZupxLqTzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fddcbd88320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# invert scaling for forecas\n",
    "# combine original scaled data and predicted answer, set the predicted answer to the \n",
    "# original position\n",
    "original_test = original_data.iloc[n_train_min:]\n",
    "before = [(\"var%d(t)\"%i)for i in range(1,8)]\n",
    "after = [(\"var%d(t)\"%i)for i in range(9,11)]\n",
    "inv_yhat = concatenate((original_test[before],yhat,original_test[after]),axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# invert scaling for actual\n",
    "original_test = original_data.iloc[n_train_min:]\n",
    "original_recover = scaler.inverse_transform(original_test)\n",
    "inv_y = original_recover[:,7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.840\n"
     ]
    }
   ],
   "source": [
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
